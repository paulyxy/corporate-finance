.chapter1<-function(i){
" i  Chapter 1: Introduction 
  -  -------------------------------------
  1  R installation/one line R-code for this course
  2  About the book by Iov Welch 
  3  Read on-line or Order a printed copy 
  4  Percentage grades to letter grades 
  5  Preface download and FAQ
  6  Download chapters (pdf)
  7  Download slides (pdf or pptx)
  8  Abetaumption #1: A typical investor is rational  
  9  Abetaumption #2: Stock market is efficient
 10  Abetaumption #3: No Arbitrage opportunities
 11  Abetaumption #4: The law of one price 
 12  Opportunity cost 
 13  Bond vs. Stock (debt vs. equity)
 14  Stakeholders for a corporation 
 15  Separation of ownership and management (control)
 16  Ethical dilemmas 
 17  Corporate responsibility index 
 18  Data sets 
 19  YouTube
 20  Links

 Example #1:>.c1    # see the above list
 Example #2:>.c1(1) # see the first explanation

";.chapter1_(i)}

.n1chapter<-20
.chapter1_<-function(i){
    .printEachQ(1,i,.n1chapter)
}
.c1<-.chapter1



.C1EXPLAIN0000<-"Survey results 
///////////////////////////////////////////////////
Q1: Major         Q2:Minor             Q3 Excel           Q4: Career          
----------------  ------------------   ---------------    --------------------- 
Businebeta Adm 11   Finance          1   Excellent    1     Master                     3
Math          1   Data Analytics   1   Good         3     Sales                      2
                  None             3   Good/Average 4     Not sure yet               2
                  Marketing        4   Average      4     Abetaet/portfolio management 1
                  Acturial science 1   Poor               Hospital Administration    1
                  MA               1                      Businebeta management        1
                  Economics        1                      Marketing                  1
                                                          Advertisement              1
                                                          Teaching                   1  
                                                          Acturary                   1
                                                          Teaching certificate       1
 Freshman
 Sophomore   2
 Junior      7
 Senior      1
                                                          
///////////////////////////////////////////////////
"


.C1EXPLAIN1<-"R installation 
///////////////////////////////////////////////////
To install R, we have the following steps:

  Step 1: go to http://r-project.org
  Step 2: click \"CRAN\" on the left
  Step 3: choose a server nearby
  Step 4: choose appropriate type such as Windows, Mac
  Step 5: download \"Base\"

 How to download and install R (6m39s) [for windows)
    https://www.youtube.com/watch?v=ZoPJGmpYJzw

 Programming in R - Getting Started - Installing R and RStudio on a Mac (5m59s)
    https://www.youtube.com/watch?v=Ywj6yNfc5nM

 One line for this course: 
   source('http://datayyy.com/cf.txt')

   or

   source(\"http://datayyy.com/cf.txt\")

///////////////////////////////////////////////////
"

.C1EXPLAIN2<-"Corporate Finance (5th ed.) by Ivo Welch)
///////////////////////////////////////////////////
Corporate Finance (5th edition, 2022) by Ivo Welch)

  Read online
      http://book.ivo-welch.info/read/

  Order a printed version 
      https://www.amazon.com/dp/0984004904

  Preface 
     https://book.ivo-welch.info/read/source5.mba/00-preface.pdf

  FAQ 
     https://book.ivo-welch.info/faq/

///////////////////////////////////////////////////
"

.C1EXPLAIN3<-"Read on-line or Order a printed copy 
////////////////////////////////
 Read online
 ---------------------
      http://book.ivo-welch.info/read/

 Order a printed copy 
 ---------------------
      https://www.amazon.com/dp/0984004904

///////////////////////////////
"

.C1EXPLAIN4<-"Percentage grades to letter grades 
////////////////////////////////

  Percentage grade     Letter grade
  ------------------   -------------
       >= 90%              A
       >= 85%              A-
       >= 80%              B+
       >= 75%              B
       >= 70%              B-
       >= 65%              C+
       >= 60%              C
       >= 55%              C-
       <= 50%              F
       
///////////////////////////////
"

.C1EXPLAIN5<-"Preface and FAQ 
////////////////////////////////
 Preface 
     http://book.ivo-welch.info/read/source.mba/preface.pdf
     
 FAQ 
     http://book.ivo-welch.info/faq/

///////////////////////////////
"


.C1EXPLAIN6<-" Download chapters (pdf)
////////////////////////////////
Method 1: manually download it
---------------------------------
         Step 1: http://book.ivo-welch.info/read/source.mba/
         step 2: choose your chapter, such as chap01.pdf

Method 2: using .chapter function 
----------------------------------
         >.chapter(1)
           The file called  chap01.pdf      was downloaded 
           and it is saved under  c:/temp/ 

          The short-cut for .chapter function 
           .cc(1)

          To download all the chapers, 
          .cc(0)
///////////////////////////////
"

.C1EXPLAIN7<-" Download slides (pdf or pptx)
////////////////////////////////
Method 1: manually download
---------------------------------
         Step 1: https://book.ivo-welch.info/slides/
         step 2: choose your chapter, such as c02-tvm-1.pdf

Method 2: using .slides function 
----------------------------------
         >.slides(2)
           Files called  c02-tvm-1.pdf, c02-tvm-2.pdf 
             are under  c:/temp 

         >.ds(4)    # .ds is a short-cut: downloadSlides
           File called  c04-capbudgrules.pdf 
           is under  c:/temp 

         >.ds(2,2)  # the second input is not 1
           Files called  c02-tvm-1.pptx, c02-tvm-2.pptx 
           are under  c:/temp 
///////////////////////////////
"
.C1EXPLAIN8<-"Abetaumption #1: A typical investor is rational  
////////////////////////////////
Abetaumption #1
--------------
   When learning finance, there are many importand abetaumptions. 
 
  One of the most important abetaumptions is:
 
    a) a typical investor is rational, or
 
    b) most investors are rational. 

///////////////////////////////
"

.C1EXPLAIN9<-"Abetaumption #2 
////////////////////////////////
Abetaumption #2: Market Efficient Hypothesis
------------------------
This another very important abetaumption:
the stock markets are efficient. 

///////////////////////////////
"

.C1EXPLAIN10<-"Abetaumption #3: No Arbitrage opportunities
////////////////////////////////
Abetaumption #3: No Arbitrage 
---------------------------
Arbitrage opportunity means that we have a chance to buy 
and sell the same product with different prices at the same
 time. 

In other words, we could earn a profit without 
incurring any cost (risk).

///////////////////////////////
"

.C1EXPLAIN11<-"Abetaumption #4 : the law of one price 
////////////////////////////////
The law of one price 
--------------------
The same produce should sell at the same price. 

///////////////////////////////
"
.C1EXPLAIN12<-"Opportunity cost
////////////////////////////////
 Opportunity cost is defined as the best return with an 
    alternative usage of the capital/facility/commodity/etc. 

///////////////////////////////
"

.C1EXPLAIN13<-"Bond vs. Stock (debt vs. equity)
////////////////////////////////
Bond holders (debt holders)
   1) They lent money to the company 
   2) They are not the owner of the firm
   3) They claim reward/return before stock (equity holders)

Equity holders 
   1) They invest money with a specific company 
   2) They are owner of the firm
   3) They are the last to claim the reward (return)

///////////////////////////////
"


.C1EXPLAIN14<-"Stakeholders for a corporation 
////////////////////////////////
For a company, there are several stakeholders:

   owners (equity holders)

   debt holder (bond holders)

   employees

   government

   investors

   community

   Regulation agency

   Accouting/auditing firms

   etc. 

////////////////////////////////
"

.C1EXPLAIN15<-"Separation of ownership and management (control)
////////////////////////////////

  Owners is the equity holders

  They elect a board of directors. 

  The board of director will choose CEO or management team. 

  The management team will manage the businebeta. 

///////////////////////////////
"

.C1EXPLAIN16<-"Ethical dilemmas 
////////////////////////////////
What Is an Ethical Dilemma?
   There are three conditions that must be present for a situation to be
   considered an ethical dilemma.

   The first condition occurs in situations when an individual, 
   called the \"agent,\" must make a decision about which
   course of action is best. Situations that are uncomfortable but that 
   don't require a choice, are not ethical dilemmas. For example, students
   in their internships are required to be under the supervision of an 
   appropriately credentialed social work field instructor. Therefore, 
   because there is no choice in the matter, there is no ethical violation
   or breach of confidentiality when a student discubetaes a case with the 
   supervisor. 

   The second condition for ethical dilemma is that there must be different
   courses of action to choose from. 

   Third, in an ethical dilemma, no matter what course of action is taken,
   some ethical principle is compromised. In other words, there is no perfect solution.

   In determining what constitutes an ethical dilemma, it is necebetaary to 
   make a distinction between ethics, values, morals, and laws and policies.
   Ethics are prepositional statements (standards) that are used by members 
   of a profebetaion or group to determine what the right course of action in 
   a situation is. Ethics rely on logical and rational criteria to reach a 
   decision, an ebetaentially cognitive procebeta (Congrebeta, 1999; Dolgoff, 
   Loewenberg, & Harrington, 2009; Reamer, 1995; Robison & Reeser, 2002).
   Values, on the other hand, describe ideas that we value or prize. 
   To value something means that we hold it dear and feel it has worth
   to us. As such, there is often a feeling or affective component abetaociated
    with values (Allen & Friedman, 2010). Often, values are ideas that we 
   aspire to achieve, like equality and social justice. Morals describe a 
   behavioral code of conduct to which an individual ascribes. They are used
    to negotiate, support, and strengthen our relationships with others 
   (Dolgoff, Loewenberg, & Harrington, 2009).

    Finally, laws and agency policies are often involved in complex cases, 
    and social workers are often legally obligated to take a particular course
    of action. Standard 1.07j of the Code of Ethics (NASW, 1996) recognizes 
    that legal obligations may require social workers to share confidential 
    information (such as in cases of reporting child abuse) but requires 
    that we protect confidentiality to the \"extent permitted by law.\" 
    Although our profebetaion ultimately recognizes the rule of law, we 
    are also obligated to work to change unfair and discriminatory laws.
    There is considerably lebeta recognition of the supremacy of agency policy
    in the Code, and Ethical Standard 3.09d states that we must not allow 
    agency policies to interfere with our ethical practice of social work.

    It is also ebetaential that the distinction be made between personal
    and profebetaional ethics and values (Congrebeta, 1999; Wilshere, 1997).
    Conflicts between personal and profebetaional values should not be 
    considered ethical dilemmas for a number of reasons. Because values
    involve feelings and are personal, the rational procebeta used for 
    resolving ethical dilemmas cannot be applied to values conflicts.
    Further, when an individual elects to become a member of a profebetaion,
    he or she is agreeing to comply with the standards of the profebetaion, 
    including its Code of Ethics and values. Recent court cases have 
    supported a profebetaion's right to expect its members to adhere to
    profebetaional values and ethics. (See, for example, the Jennifer Keeton
    case at Augusta State University and the Julea Ward case at Eastern 
    Michigan University.) The Council on Social Work Education states that 
    students should 'recognize and manage personal values in a way that allows
    profebetaional values to guide practice' (EPAS 1.1). Therefore, although they
    can be difficult and uncomfortable, conflicts involving personal values 
    should not be considered ethical dilemmas.

 Two Types of Dilemmas    
    An \"absolute\" or \"pure\" ethical dilemma only occurs when two 
    (or more) ethical standards apply to a situation but are in 
    conflict with each other. For example, a social worker in a
    rural community with limited mental health care services is 
    consulted on a client with agoraphobia, an anxiety disorder 
    involving a fear of open and public spaces. Although this problem
    is outside of the clinician's general competence, the limited options
    for treatment, coupled with the client`s discomfort in being too far 
    from home, would likely mean the client might not receive any services
    if the clinician declined on the basis of a lack of competence (Ethical
    Standard 1.04). Denying to see the patient then would be potentially in 
    conflict with our commitment to promote the well-being of clients (Ethical
     Standard 1.01). This is a pure ethical dilemma because two ethical standards
     conflict. It can be resolved by looking at Ethical Standard 4.01, which states 
    that social workers should only accept employment (or in this case, a client) 
   on the basis of existing competence or with 'the intention to acquire the necebetaary
     competence.' The social worker can accept the case, discubetaing the present limits 
   of her expertise with the client and following through on her obligation to seek 
    training or supervision in this area.

   However, there are some complicated situations that require a decision but may 
   also involve conflicts between values, laws, and policies. Although these are not
   absolute ethical dilemmas, we can think of them as 'approximate' dilemmas. For 
   example, an approximate dilemma occurs when a social worker is legally obligated
   to make a report of child or domestic abuse and has concerns about the releasing 
   of information. The social worker may experience tension between the legal 
   requirement to report and the desire to respect confidentiality. However, 
   because the NASW Code of Ethics acknowledges our obligation to follow legal 
   requirements and to intervene to protect the vulnerable, technically, there is
   no absolute ethical dilemma present. However, the social worker experiences this 
   as a dilemma of some kind and needs to reach some kind of resolution. Breaking 
   the situation down and identifying the ethics, morals, values, legal ibetaues, 
   and policies involved as well as distinguishing between personal and profebetaional
    dimensions can help with the decision-making procebeta in approximate dilemmas. 
   Table 1 (at beginning of this article) is an illustration of how these factors 
   might be considered.
     https://www.socialworker.com/feature-articles/ethics-articles/What_Is_an_Ethical_Dilemma%3F/

///////////////////////////////
"

.C1EXPLAIN17<-"Corporate responsibility index 
////////////////////////////////
 Sawhny,Vidya,2008,Analyzing Corporate Social Responsibility Measurement Parameters
      https://www.instituteforpr.org//wp-content/uploads/SawhnyKEPRRA_Award.pdf

Corporate Responsibility Highlights of Grainger's environmental,
    social and governance practices
    www.GraingerESG.com

   https://www.graingercsr.com/download-report-pdf/
   https://www.graingeresg.com/csrdownload/indirect/Grainger_2021_Corporate_Responsibility.pdf

   https://www.asahigroup-holdings.com/en/ir/sri/
   https://www.graingercsr.com/2016/csrdownload/indirect/Grainger_2019_Corporate_Responsibility_Update.pdf
   https://www.usbank.com/corporate-responsibility/annual-report/2018/downloads.html
   https://www.researchgate.net/post/how_to_measure_corporate_social_responsibility_index

///////////////////////////////
"

.C1EXPLAIN18<-"Data sets 
///////////////////////////////
  type the following code

   .getdata

///////////////////////////////
"
.C1EXPLAIN19<-"Youtube
////////////////////////////////
 1) Tutorlol, 2010, How to download and install R [for windows)
   (v141k,s4k,t6:39)
    https://www.youtube.com/watch?v=ZoPJGmpYJzw

 2) Easy Data Science,2014,Programming in R - Getting Started - Installing R and RStudio on a Mac
   (v42k,s,t5:59)
    https://www.youtube.com/watch?v=Ywj6yNfc5nM

 3) FNCE311, chapter 1: introduction 
    https://youtu.be/jHkkmbVEpYQ

  v: stands for viewership
  s: number of subscribers
  t: time, t1:23 stands for 1 minute 23 second

///////////////////////////////
"
.C1EXPLAIN20<-"Links 
////////////////////////////////
Corporate Finance (4th edition, 2017) by Ivo Welch)
  Read online
      http://book.ivo-welch.info/read/

  Order a printed version 
     http://www.lulu.com/shop/ivo-welch/corporate-finance-fourth-edition/paperback/product-23192069.html

  Inclusion in SRI Indexes
      https://www.asahigroup-holdings.com/en/ir/sri/
  
Optional
   Presidential Addrebeta: Corporate Finance and Reality 
   John R. Graham,      102 Pages Posted: 10 Jan 2022
   Duke University; National Bureau of Economic Research (NBER)
       https://papers.betarn.com/sol3/papers.cfm?abstract_id=3994848
   video: 
       https://www.youtube.com/watch?v=henjrUBi22g

///////////////////////////////
"

#        http://www.sustainability-indexes.com/

.chapter10<-function(i){
" i  Chapter 10: CAPM (Capital Abetaet Pricing Model)
  -  -------------------------------------
  1  If 'Data analysis' is not available 
  2  General one-factor linear model 
  3  Formulae for CAPM
  4  3 types of risks/manually download data 
  5  Market index (S&P500)
  6  closing price vs. adjusted closing price 
  7  Yahoo!finance to get data 
  8  .getDaily/.getMonthly for just a few stocks
  9  Collect the S&P500 historical data
 10  Fama-French market and risk-free rate 
 11  Sorting your data 
 12  Merging your data sets
 13  How to run a linear regrebetaion?
 14  T-value and P value, R2 and adjusted R2
 15  Adjusted beta/portfolio beta 
 16  CAPM an absurd model 
 17  one-line comments on 'CAPM: an absurd model' 
 18  More comments     on 'CAPM: an absurd model' 
 19  YouTubes
 20  Links (references and YouTube) 

 Example #1:>.c10     # find out the above list 
 Example #2:>.c10(1)  # see the first explanation

";.chapter10_(i)}

.n10chapter<-20
.chapter10_<-function(i){
     .printEachQ(10,i,.n10chapter)
}

.c10<-.chapter10

.C10EXPLAIN1<-"If \"Data Analysis\" is not available on your menu bar
/////////////////////////////////
 After clicking 'Data' on the menu bar, you cannot find 'Data analysis'. 

Windows users
---------------
   Step 1: click 'File', 
   Step 2: click 'Add-ins' 
   Step 3: click 'Go' 'Manage Excel Add-ins' 
   Step 4: Activate 'Analysis ToolPack' and click 'OK'

Mac users
--------------
  Step 1: Open Excel for Mac 2019
  Step 2: Go to the Tools menu, select \"Add-ins\"
  Step 3: Check \"Solver Add-in\" and \"Analysis ToolPak\" then click OK
  Step 4: Select the \"Data\" tab, then select \"Solver\" or \"Data Analysis\"

/////////////////////////////////
"

.C10EXPLAIN2<-"General one-factor linear model 
/////////////////////////////////
1-factor linear model has the following form:
  
    y= alpha + beta *x

  where y   is the dependent variable
        x   is the independent variable
      alpha is the intercept
      beta  is the slope

  We try to use x to explain y

  1-factor: since we have just one independent variable
 
  linear : a) if we draw a graph based on y and x, 
              it is a straingt line

           b) the power of the independent variable, i.e., 
              x is one.

/////////////////////////////////
"

.C10EXPLAIN3<-"Formulae for CAPM
/////////////////////////////////
CAPM
      E[R(i)] = Rf + beta *[R(m)-Rf]                (1)

   where E[]    is the expectation 
         R(i)   is for stock i's return 
         Rf     is the risk-free rate 
         beta   is the market risk (slope)
         R(m)   is the market return

To estimate beta, we run the following regrebetaion 

    R(i,t) = Rf(t) + beta *[R(m,t)-Rf(t)] + e(t)    (2)

   where R(i,t) is the stock i's return at time t
         Rf(t)  is the risk-free rate at time t
         beta   is the market risk (slope)
         R(m,t) is the market return at time t
         e(t)   is a random factor
 
For example, for IBM, we have the following form. 
    to make our notation clear, we drop the notation of t

    R(IBM)  = alpha + beta *[R(m)-Rf] + e           (3)
    
Sometime, we write the following way:

     R(IBM)- Rf = alpha + beta *[R(m)0 - Rf]        (4)

  The interpretation of Equation (4) is clearer. 
      The left-hand side is the risk premium for IBM
      It is the product of two factors: 
                 a) market risk of IBM, and 
                 b) the market risk premium
  
/////////////////////////////////
"

.C10EXPLAIN4<-"market risk, firm specific risk, total risk/manually download data  
/////////////////////////////////
 Total risk = market risk + firm specific risk
      sigma: total risk 
      beta : market risk

manually download historical data from Yahoo!Finance
----------------------------
   Step 1: go to finance.yahoo.com
 
   Step 2: enter a ticker, such as ibm
   
   step 3: click \"historical data\" 
 
   step 4: choose beginning and ending dates
           frequency 

   Step 5: click \"Apply\"

   Step 6: download to your spreadsheet

/////////////////////////////////
"

.C10EXPLAIN5<-"Market Index
/////////////////////////////////
For the S&P500 index, its ticker (symbol) is ^GSPC

 Example #`1: get daily data for S&P500
           > x=getDailyPrice(\"^gspc\")
           > saveYan(x,\"c:/temp/sp500.csv\")
            [1] \"Your saved file is ==>c:/temp/sp500.csv\"

/////////////////////////////////
"

.C10EXPLAIN6<-"closing price vs. adjusted closing price 
/////////////////////////////////
When we download daily data from Yahoo!finance, we have the 
following format:

Date,Open,High,Low,Close,Volume,Adj.Close
2017-03-09,179.149994,179.25,175.880005,177.179993,5413100,177.179993
2017-03-08,180.75,180.949997,179.300003,179.449997,3520000,179.449997
2017-03-07,180.710007,181.289993,180.199997,180.380005,2930800,180.380005
2017-03-06,179.720001,180.990005,179.570007,180.470001,3180900,180.470001

There are two closing price: close and adjusted close. 

The close is the observed closing price while the adj.Close is the 
   adjusted closing price which considering stock split, dividend 
   and other distributions. 

To estimate our returns, we have to use the adjusted close. 

 Here is an example. Abetaume that there is no information or no trading. 
 John bought one share at $10. At the end of his investing horizon, he sold it at $10. 
   $10                                 $10
   |------------------------------------|
   0                                    1

 His return is zero since (10-10)/10 = 0

 Abetaume that the company announced a 2-for-1 split

   $10                                 $5
   |------------------------------------|
   0                                    1

  What is John's return?
        Still zero since (2*5-10)/10=0

  What happen if we use closing price to estimate 
        instead of the adjusted close?

/////////////////////////////////
"

.C10EXPLAIN7<-"From Yahoo!finance to get data 
/////////////////////////////////
 Below, we use 'ibm' as example to download its 
        historical monthly data. 

 Step 1: go to https://finance.yahoo.com
 
 Step 2: enter 'ibm'    
 
 Step 3: click 'Historical Data'

 Step 4: For the 'Time Period', choose your starting 
         and ending date,e.g., Max

 Step 5: For the frequency 'Monthly'

 Step 6: Click 'Apply'
 
 Step 7: Click 'Download'

/////////////////////////////////
"

.C10EXPLAIN8<-"use .getDaily() and .getMonthly functions   
/////////////////////////////////
just type .getMonthly or .getDaily 


 Example #1: getting the monthly historical for IBM
           > .getMonthly(\"ibm\")
             Windows users: launch Excel and paste


 Example #1: get daily data for IBM
           > .getDaily(\"ibm\")
            Windows users: launch Excel and paste

/////////////////////////////////
"

.C10EXPLAIN9<-"Download the S&P500 monthly data 
/////////////////////////////////

 Step 1: go to https://finance.yahoo.com
 
 Step 2: enter '^GSPC'        # for S&P500
 
 Step 3: click 'Historical Data'

 Step 4: For the 'Time Period', choose your starting 
         and ending date,e.g., Max

 Step 5: For the frequency 'Monthly'

 Step 6: Copy-and-paste data to Excel 
         Note: there is no 'download' botton
  
/////////////////////////////////
"

.C10EXPLAIN10<-"use Fama-French market and risk-free rate 
/////////////////////////////////
We could use the excebeta market risk premium and risk-free rate
from Prof. French's factor time series

 Example #`1:>.show_ff3Monthly()
                DATE MKT_RF    SMB     HML     RF
            1 1926-07-01 0.0296 -0.023 -0.0287 0.0022
            2 1926-08-01 0.0264 -0.014  0.0419 0.0025

 Example #`2: .show_ff3Daily(0)


/////////////////////////////////
"
.C10EXPLAIN11<-"sort your data 
/////////////////////////////////
Sometimes, different data sets are sorted differently. 
For example, if you download data from Yahoo!Fiance, the data set is sorted from the newest to the oldest. 

 Example #`1: sorted from the newest to the oldest
             > x=getDailyPrice(\"ibm\")
             > head(x)
                 Date   Open   High    Low  Close  Volume Adj.Close
          1 2017-03-09 179.15 179.25 175.88 177.18 5413100    177.18
          2 2017-03-08 180.75 180.95 179.30 179.45 3520000    179.45
          3 2017-03-07 180.71 181.29 180.20 180.38 2930800    180.38
          4 2017-03-06 179.72 180.99 179.57 180.47 3180900    180.47
          5 2017-03-03 180.53 181.32 179.76 180.05 1822000    180.05
          6 2017-03-02 181.88 181.88 180.43 180.53 2913600    180.53

 However, for ohters time series, they are sorted from the oldest to the newest. 

 Example #`2: sorted from the oldest to the newest
             > showffMonthly(5)
                DATE  MKT_RF     SMB     HML     RF
           1 1926-07-01  0.0296 -0.0230 -0.0287 0.0022
           2 1926-08-01  0.0264 -0.0140  0.0419 0.0025
           3 1926-09-01  0.0036 -0.0132  0.0001 0.0023
           4 1926-10-01 -0.0324  0.0004  0.0051 0.0032
           5 1926-11-01  0.0253 -0.0020 -0.0035 0.0031

  When putting those two types of data together, 
    we have to sort them with the same orders first. 

/////////////////////////////////
"
.C10EXPLAIN12<-"merge your data sets
/////////////////////////////////
Most of times, we have merge our data set according to date. 

Thus generate a good \"True\" date variable is vital important. 

/////////////////////////////////
"

.C10EXPLAIN13<-"How to run a linear regrebetaion?
/////////////////////////////////
Abetaume that we have two clumns of y and x

   data -> data analysis -> regrebetaion -> ...

/////////////////////////////////
"

.C10EXPLAIN14<-"T-value,P value, R2 and adjusted R2
/////////////////////////////////
  For a variable, we could use T-value to tell whether 
      the variable is statistically significant. 

  For example, we could use the following rule
        T (value) > T-critical value --> Reject the null Hypothesis
        T (value) < T-critical value --> Accept the null Hypothesis

       A simple way, we could use a critival T-value of 2. 
        T (value) > 2 --> Reject the Null Hypothesis
        T (value) < 2 --> Accept the Null Hypothesis

  For a variable, we could use p-value to tell whether 
      the variable is statistically significant. 

        p-value > critical p-value --> Reject the null Hypothesis
        p-value < critical p-value --> Accept he null Hypothesis

      A simple way, we could use a critival p-value of 0.05. 
           p-value > 0.05 --> Accept the null Hypothesis
           p-value < 0.05 --> Reject the null Hypothesis
R2 and adjusted R2
------------------
  R^2 is the percentage could be explained. 

  In statistics, the coefficient of determination, denoted R2 or r2 and 
  pronounced \"R squared\", is the proportion of the variance in the 
  dependent variable that is predictable from the independent variable(s).
     https://en.wikipedia.org/wiki/Coefficient_of_determination
/////////////////////////////////
"
.C10EXPLAIN15<-"adjusted beta/portfolio beta 
/////////////////////////////////
The formula is used to adjust our estimated beta. 
                    2         1   
    adjusted Beta= ---*beta + --
                    3         3 
    where beta is our estimated beta

 The underlying logic is that beta has a meaning reverting property. 
     The mean is about 1. This means that if our estimated beta this 
     year is above 1, there is a good chance that its next year's beta 
     would be smaller. The opposite is true: if this year's beta is 
     lebeta than 1, there is a good chance that the next year's beta 
     is higher, i.e., closer to 1. 

Portfolio beta is the weighted individual stock beta. 
--------------
   beta(portfolio) = w1*beta1 + w2*beta2 + ... + wn*betan

  where beta(portfolio) is the portfolio's beta
        w1    is the weight for stock 1
        beta1 is the beta   for stock 1

            investment for stock 1
      w1=  -------------------------
             total investment 

/////////////////////////////////
"


.C10EXPLAIN16<-"CAPM: an absurd model
/////////////////////////////////
Pablo Fernandez, Profebetaor of Finance. IESE Businebeta School, University of Navarra 
e-mail: fernandezpa@iese.edu. Camino del Cerro del Aguila 3. 28023 Madrid, SpainNovember 3, 2014 

On October 2014, I sent the article \"CAPM: an absurd model\" to several profebetaors, profebetaionals and Ph.D. students, 
telling them that \"I will appreciate very much your opinion and criticism\". I thank very much all that answered the about 300 
interesting comments and criticism that follow. I have learned a lot reading (and thinking about) all of them because are real 
opinions of real persons that know finance and have thought about it. 

The CAPM is about expected return. If you find a formula that works well in the real markets, would you 
publish it? Before or after becoming a billionaire? 

The CAPM is an absurd model because not only its abetaumptions but also its predictions/conclusions have no 
basis in the real world. (Absurd means 1. ridiculously unreasonable, unsound, or incongruous <an absurd argument>. 2: 
having no rational or orderly relationship to human life. Meaninglebeta. utterly or obviously senselebeta, illogical, or untrue; 
contrary to all reason or common sense; laughably foolish or false. (Source: http://www.merriamwebster.
com/dictionary/absurd) 

With the vast amount of information and research that we have, it is quite clear that the CAPM is neither a 
theory nor a model because it does not \"explain facts or events\", nor does it \"describe the past, present, or 
future state of something\". 

The use of CAPM is also a source of litigation. Users of the CAPM make many illogical errors valuing 
companies, accepting/rejecting investment projects, evaluating fund performance, pricing goods and services in 
regulated markets, calculating value creation ...

It is important to differentiate between a fact (something that truly exists or happens: something that has 
actual existence; a true piece of information) and an opinion (what someone thinks about a particular thing). 
The CAPM could be described as an uninformed opinion, and not as a sensible opinion. 

We may find out an investor's expected return for IBM by asking him. However, it is impobetaible to 
determine the expected return for IBM of the market, because this parameter does not exist. Different investors 
have different cash flow expectations and different expected (and required) returns to equity. One could only 
talk of the expected return of the market if all investors had the same expectations. But investors do not have 
homogeneous expectations. 

Valuation is about required return. There are persons, papers and books that mix (or abetaume that are equal) 
expected and required returns. 
/////////////////////////////////
"

.C10EXPLAIN17<-"One-line comments and criticism: on 'CAPM: an absurd model'
/////////////////////////////////
I teach CAPM as a kind of religion/belief. You neither can prove nor falsify it. 

I totally agree with the absurdity of CAPM model. 

Every profebetaional investor knows CAPM doesn't work. I know of no portfolio manager that actually uses it. 

I agree with most of your abetaertions. In my opinion, CAPM is at best a waste of time. 

I share your opinion about CAPM. It has for a long time been a \"taboo\" in financial research and practice. 

Why you send this for review which can ruin your reputation? 

I myself think that CAPM is overemphasized and blindly used without seeing the suitability even for valuations 

CAPM is good for nothing (or it is good for the purpose different from the declared one - to be quite precise). 

I have been telling my clabetaes not to use this model for some years now. 

I agree about the general uselebetanebeta of CAPM for practical applications. 

In the U.S. Tax Court case of Gallagher, the U.S. tax court heavily discounted the CAPM model except for large entities. 

Finally someone dares say what many sensible people secretly thought. CAPM is not a good explanation. 

I couldn't agree more with your paper's title. 

Nice work... I will use it with my students in ethics in finance 

Welcome to the party of combating bad economists! 

I am convinced that CAPM it's one of the most stupid ideas around... 

My own opinion is that our inability to separate systematic from idiosyncratic risk is the root problem. 

Simply great to see you're trashing this pompous model! 

We say \"Beauty is in the eye of the beholder.\" Perhaps we should say \"Beta is in the eye of the beholder.\" 

It is a very good fundamental work in the jungle of too much empiricism. 

I have never believed in CAPM for circularity in its reasoning. 

The IMF carried out an analysis of Banks' profitability based on the CAPM in the last ibetaue of its GFSR! Have a look! 

We advocate using multiple measures of estimating cost of equity to ensure reasonablenebeta. 

CAPM is absurd, but it has many friends who are not always open to criticism. 

I appreciate your demonstration that common sense is the best available shield against phony models. 

Quite scary for poor old finance profs. like myself who have to fight the textbooks and rewrite their old teaching notes. 

Trying to prove an investment is good or bad based on stock volatility (rather than its basic merits) is silly. 

I have always regarded the CAPM as absurd because of all the irrationalities that investors display. 

Note that this is a model for which a Nobel Prize was granted. 

I would add that the real flaw is in the concept of beta itself. It's like a dog trying to bite its tail!!! 

I would suggest focusing more on the recommendation on how to calculate the beta in a sensible way. 

I think it has the right findings and it offers a good alternative for estimating the cost of equity. 

Your manuscript is impabetaioned with no reasonable. Every model has limitations and trying to explain (only) something. 

I agree that \"there are in fact two things, science and opinion; the former begets knowledge, the latter ignorance\" 

I think that your points and arguments are sufficiently strong to demonstrate this absurdity. 

I don't agree with any linear pricing models, these include CAPM and any multi-factor pricing models. 

It appears that you are saying the emperor has no clothes! 

A paper like this had to be written. I am grateful you did. 

From my experience economists do not like when somebody criticizes a widely used model. 

/////////////////////////////////
"


.C10EXPLAIN18<-"more comments on 'CAPM: an absurd model'
/////////////////////////////////
2. Comments and criticism of persons that did not like much \"CAPM: an absurd model\" 
-----------------------------------------------------------------
The author's comments are absurd. Just because there is no uniform consensus about the MRP, it does not follow that the 
MRP does not exist. There is no consensus about the value of shampoo, but that does not mean there is no market 
equilibrium price. 

I am a profebetaor teaching finance, also a past businebeta valuation consultant. While you are on the right track, I disagree 
about your abetaebetament: \"There really is not market\" to determine MRP.\" This is the weak part of your argument, not 
necebetaary to make your points, and not even true. As a businebeta valuation appraiser, it is obvious there are many aspiring 
buyers and sellers of common stock, but THE MARKET is that juncture where prices clear and valuation experts look to 
recent sales of securities to determine just what the MRP is at any given time. This is why businebeta appraisers use very long 
term Ibbotson data to come up with an average MRP over very long periods of time. In summary, determining a MRP is not 
easy, a guebeta to some extent, but it is so important in actual practice that it is NECEbetaARY to do as good a job as pobetaible 
based upon actual market transactions. 

I disagree. While one should NOT be using the CAPM to do many of the things you list, I personally find the CAPM a useful 
tool for students. However, I review the CAPM quickly and move to Fama/French 3 factor model. The model is part of history 
of finance (a large piece), however, I believe the CAPM is used too much today. 

The paper really doesn't contribute to what is already known with respect to the flaws of the CAPM, or any single factor 
model. It has been written about in volumes.... There is nothing new that contributes to the CAPM and its shortcomings.... 

I beg to differ with your abetaertions. CAPM is based on fact. It is based on fact as much as the proposition that objects falls 
at a speed unrelated to their weight. The CAPM works so well that we use the kind of experiments in the attached articles to 
teach it. I used it in my financial markets laboratory MBA clabeta last month, and below is the plot of prices of one of the trading 
sebetaions. There, the CAPM equilibrium prices were 5 dollars and 3.50 respectively. Both abetaets had the same expected 
payoff and the payoff variance, and nobody knew the market portfolio so even if students believed in CAPM, they could not 
compute equilibrium prices. 

I have been your same idea since I began studying money and banking. I never tried to discubeta the problem and I refused 
the model 'ideologically'. This is because my idea of science is quite different from the one you cite on your abstract. 

I disagree. 1. Common sense is not an alternative model. 2. The CAPM should be used with sense when used to estimate 
ex-ante return. As of now there is no better alternative model. 3. The CAPM does not apply to \"one\" investor but reflect the 
average market through the trading of abetaets/shares 

A small disagreement on the nature of \"theory\". The dictionary might define 'theory' as you state, but I would add that a 
theory explains facts in a way that can be tested and disproved. (See Karl Popper's ebetaay \"Conjectural Knowledge\", 1971). 

By this definition, CAPM is a good theory - it predicts specific outcomes and can be tested. However, if the data does not 
substantiate the theory, it should be rejected. 

I don't think one can conclude that the model is absurd, but only how it is used. A model is just that; a model. If it is being 
misused, you shouldn't blame that on the model. I think the CAPM as a simple idealized model that provided important 
insights when it was introduced, such as the importance of considering diversification in pricing financial abetaets. 

Also certain market prices do not exist, following your logic: for instance, \"IBM closing price\" is simply a weighted average of 
multiple bid- and offer- prices for the IBM stock in a certain hour of the trading day: still, based on that \"non-existing\" price, 
quite a number of events, contracts, remunerations, are based. An \"average\" value may well be a never-occurring event, we 
know well, but still it can be highly meaningful in signaling market trends, dynamics, risks, and so on. 

I have only one disagreement with you: instead of writing that the model is wrong, I prefer to exprebeta the idea that it is only 
an approximation. We never have a discount rate published in the newspapers and so we have to estimate a percentage 
with some logic and some realism and here the formula provides some guidance. Unfortunately there is no rule of thumb for 
making good estimates and that is the reason why I tell my students that there are only a few good financial managers but a 
multitude of \"economists\" that simply use formulas produced by others. 

I was shocked at how horrible your paper is. It is without a doubt the worst excuse for an academic study I have ever seen 
(and believe me that is saying a lot). After simply saying that some abetaumptions of CAPM are not realistic and just bashing 
the model with no evidence other than poor English and summary of real studies that explore some CAPM anomalies, you 
recommend using the MRP and beta but with \"common sense\" and some qualitative subjective table to rank companies. An 
academic paper should have either a theory based on an abstraction of reality and predictable conclusions or an empirical 
test of a given model (or both). Your paper is simply a vomiting of the well-known problems abetaociates with CAPM most of 
are not fatal since you recommend using CAPM in the end and since the Nobel committee awarded a prize to the developers 
and recently testers of the model who probably wish they had read your paper before they did their work. Maybe the Nobel 
committee should take prizes away from Sharpe and Fama given what your paper has uncovered - really? CAPM is an 
absurd model and this is because its abetaumptions are not realistic? But all models are by definition abstractions of reality and 
no model should be judged solely on the realism of its abetaumptions. Your alternative to CAPM is basically as follows - use 
CAPM but build in your own subjective scale to derive an expected return that is based on a finger in the wind? I am sorry 
to say that I am afraid if this is an example of your academic work then you are truly in the wrong profebetaion. 

This paper strikes me as silly. I think there are three tests of a theory. First, is it correct, given its abetaumptions. There is no 
doubt that the CAPM meets this test. Second, does it provide a basis for further advancements in theory. The CAPM has 
spawned a range of further advancements in theory. Brennan's tax model and Kraus and Litzenberger on skewnebeta are 
early examples. The Fama-French model can be seen as an empirical extension of the CAPM. Third, is it useful empirically. 
It's going on 50 years now, and CAPM is still being used in empirical research. There is no questioning that the CAPM is an 
under-specified model. FF's 3-factor model addrebetaes that empirically, and Carhart has extended that to include momentum. 
And there is quite a bit of current research investigating the relevance of financial distrebeta and idiosyncratic volatility in 
adapting the CAPM. It takes a model/theory to beat a theory. So rather than try to make the silly argument that the CAPM is 
absurd, I suggest you put forward your model and then set out to demonstrate it is a better model empirically (it's clearly not 
a theoretical model). Then put your evidence out in the finance literature and see if it stands the test of scrutiny. 

3 questions or comments on your paper: 
---------------------------------------

- What about the Fama-French 3 factor betas - are they not working a bit better or is a beta of 1 still better correlated? 
- What about market implied Cost of Equity - does this not come closer to what current expectations are? 
- What is your suggestion or conclusion? It appears a bit like the Black Swan book: agree with the diagnosis, but what is the 
\"solution\" - using qualitative beta? With the large number of criteria you show, I would expect a strong averaging effect, i.e. 
little dispersion 

I agree with your thesis that no one should trade based on the CAPM, but I do think that it was an important historical 
achievement that has served as a step in the development of 3-factor and later higher-order factor models. Such models 
when applied with care have been demonstrated to be practically useful for risk management. For example the roughly 50factor 
BARRA model continues to be used (via a very expensive subscription to MCI) in a majority of financial institutions, 
and indeed is able to capture on the order of 30-40% of variation of stock-prices for companies in the US markets. 
Extrapolating historical alphas and betas from the past into the future is generally a very challenging (and maybe a futile 
task) and requires the use of sophisticated econometrics models, combining past time-series of betas for the company, its 
sector, factors that the company has exposure to (oil / interest rates).... Tracking (in the statistical sense) of the dynamic beta 
may allow some short-term predictions. The CAPM provides an interesting abstraction (in the limit of perfect information) 
and homogenous investors -- and perhaps it can be argued that it may characterize an idealized 'equilibrium' of where the 
aggregate behavior of investor would converge (reach a consensus) if the world was frozen, and no new public or private 
news were appearing. In practice it's a very dangerous and misleading tool -- and the textbooks should teach it with a 
caveat that this is purely a theoretical development and is a highly simplified representation of the world. 

I am of the opinion that betas and market premiums are not constant but time varying. There are long-term betas and market 
premiums which are unconditional estimates and short-term betas and market premiums which are conditional estimates i.e. 
time-varying. The long-term estimates are objective (in a sense they are average measures) and the short-term estimates 
are subjective (in the sense they are time-varying measures and based on subjective expectations). I disagree that historical 
beta has nothing to do with expected beta; but forms a reference point for expected betas. However, I agree that CAPM is an 
absurd model. In the short-run 'future need not be like the past'. And, as Keynes appropriately said, 'in the long-run we are 
all dead'. The key is to accept and to capture qualitative or subjective expectations of betas and premiums as implied by your 
paper. I agree. 

People making mistakes in applying CAPM: priests doing bad things isn't a valid reason in my point of view to reject religion. 
I made many mistakes when doing physics exams ...but that doesn't invalidate some of those theories. 

Absolute or relative use of a model: I find the 'absolute' of valuation a strange objective. I find usually investors/companies 
have a set of options they can choose between. Each of those options has a huge amount of qualitative and quantitative 
information abetaociated with them and as analyst/executive you absorb that all ... and then need to rank them in terms of 
'most attractive to least attractive' opportunity. That's when you get down to a set of representative numbers that quantify the 
opportunity. Valuation is one of them. Not as much in the sense of 'what is absolutely the value of this opportunity', but more 
of the type 'which one has most upside or downside opportunity'. That is where the model has validity: even if some of the 
abetaumptions underlying are plainly odd, the question is whether the specific abetaumption is likely to corrupt, reverse or 
randomize the order of those calculated opportunities. 
Wacky betas: I first found your work when thinking about betas. I followed your advice and indeed found what you described: 
volatile, dependent on history length, measurement frequency, etc. That said ... when I plotted out 'what I would have 
calculated' if I had been doing it for a few years: a lot of that noise oscillates around 'a level'. So daily observations do move 
rapidly, but not in a random walk pattern. Not at all. More like an oscillator around some averages. While you advocate 
'common sense' to decide 'required risk premium', I would argue that is no different from me using 'common sense' to 
looking at those oscillators, based on different frequencies, time periods, etc. and deriving an average. So all together for me 
it is lebeta about the model or theory, but about having a tool to rank investment priorities. At every stage common sense is 
indeed required, but whether that makes the model absurd is a step too far for me personally. 

What you bypabetaed in mentioning is that CAPM by virtue of the linkage of its equity premium component and betas with the 
stock market (usually) and its much wider usage outside the purview of the stock market, plays sort of a central planning 
function for the wider economy, because the stock market, being the planners center or a pricing authority (to use a Robert 
Slee's phrase) is thereby in position to amplify its return signals through the outer reaches of the economy. This is a distinct 
social effect worthy of investigation (e.g. why should the stock market data be used in fundamental valuation abetaignments?), 
along with the self-performativity effects of CAPM, 

Investors do not make investment decisions on the basis of the CAPM. Clearly, the ICAPM of Merton (1973) and subsequent 
improvements to the model are better models of investor behavior that can be related to the pricing kernel approach adopted 
in quantitative models of price paths or procebetaes. While the CAPM is not a good model of investor behavior, it is able to 
explain investors' behavior ex post with varying degrees of succebeta, depending on the version of the CAPM. The main 
thrust of the CAPM? Investors love diversification. From Fama (1965) we know diversification can be used to increase or 
decrease risk, meaning it is valuable independent of risk preferences. The absurdity in the CAPM of course is the 
abetaumption of a single representative agent in so far as risk preferences are concerned. Once this abetaumption is relaxed, 
resulting in at the minimum, a two-moment CAPM (Kraus and Litzenberger, 1976), the CAPM can be regarded as a 
somewhat realistic ex-post description of investor behavior. As noted in Robeta (1977), the CAPM is not a testable model. It, 
however, provides insights to investors' preference for diversification - the main benefit of the model. We just have to utilize 
the CAPM for what it can be credibly used for - understanding preference for diversification and tradeoffs between aversion 
to variance and preference for skewnebeta - Simkowitz and Beedles (1976). So long as we do not take the weaknebetaes too 
seriously its utilization in studies of market efficiency also is not inappropriate given the power of the Fama-French three 
factor model. 

The foundation of CAPM is conceptual and from that point of view it has a strong point. Investors require a return on their 
capital investment plus a return on the risk they are taking. Conceptually it is logical to eliminate diversifiable risk and thus 
the well-known CAPM formula pops up. In that sense I wouldn't call it a model or an opinion, but a theory. 
Big problem with CAPM is that it utterly fails to explain the data, and most in particular, the return vs. risk dependency CAPM 
predicts is not (or hardly) observed in practice. Thus I would formulate CAPM to be a theory to be rejected, rather than an 
uninformed opinion. Sprokholt, teacher at Nyenrode, states that for this reason \"Corporate finance is in crisis\" because 

corporate finance fails to understand risk return dependencies. I would think it most ebetaential that some kind of market 
efficiency is underlying CAPM. In principle if the linear dependency return vs. risk is not there, investors could arbitrage and 
that would force the market to follow CAPM. I am therefore somewhat surprised you only mention this abetaumption in a 
footnote. If CAPM fails, and I agree with you that it fails, you should question why investors don't do this kind of arbitrage. An 
answer to this question would maybe be a clue to find an alternative. 

As Prof. Box's immortal quote highlights \"All models are wrong, some models are useful.\" I believe you misunderstand 
what a model is. Models are supposed to have unrealistic abetaumptions; otherwise they will not be called \"models.\" Model 
building is similar to map building: Maps are not realistic, but they are useful. A realistic map would not fit in a pocket. With 
the help of a map, one can find the directions easily. In physics one can run an experiment in vacuum to understand what 
happens under special circumstances, and to help understand what happens if we remove those circumstances. 

I agree that the CAPM is not a perfect model. But economics is NOT like physics and our models will never fit perfectly since 
we are modelling people and behavior rather than neutrinos. But the CAPM is the simplest and most robust benchmark we 
have. It is easily understood, easily applied, and it does have empirical support: see for instance \"CAPM over the long-run\" 
by Ang and Chen (2007) and even Kothari, Shanken and Sloan (1995). It isn't perfect, but neither are the other \"solutions\" 
out there. You cannot say that it is an absurd model so easily, and I would recommend a fine-tuning of the language you 
use. Following up, while some of your solutions seem ok at first, they are full of ad-hoc abetaumptions and are subject to so 
much potential manipulation. People can fine-tune the risk categories as they see fit (adding and subtracting to an already 
long list of them) in order to get whatever beta they want (almost reverse engineering things). And your setup for the return 
on equity is, by the way, very close to what the CAPM delivers: rE = rF + risk premium. So I find it hard to swallow your super 
harsh criticism of the CAPM while proposing something that is basically identical but full of idiosyncratic and subjective 
choices. Second, there is a huge difference in beta estimates when using daily returns versus monthly returns, and we 
rationalize these differences using the notion of opacity or slow information diffusion. 

The only thing I might object to is your calling CAPM absurd because I think it is an implication of an Arrow-Debru type 
equilibrium model. I wouldn't call that model absurd so much as I would call it a vision of what the world would look like if 
people stopped being people and so stopped learning, experimenting, and colliding with one another. This situation would 
be, in other words, a model of the end of history. I don't see any point in speculating about the end of history, nor do I think it 
is sensible to invoke some type of goodnebeta-of-fit claim to abetaert that the model is some kind of reasonable approximation. 

I am of a different view that the CAPM has never been properly tested. Domestic abetaet-pricing tests identify multiple factors 
but a five-year beta estimation-period does not capture risk changes over time. At a minimum, supplementary factors figure 
prominently in abetaet-pricing tests because they are more current than estimated beta and, thus, act as updates for the 
unobserved true beta. In the paper from the attached link, we undertake abetaet allocation with ex ante returns. In future 
research, ex ante returns I think will be the basis of the only definitive test of the CAPM. 

I think you are wrong in conclusions. The relation between return and risk exists. It may be nonlinear, but still exists. CAPM 
is a simplified relation. I will not cite your article. I think it is a very primitive one. 

There was a \"beta is dead\" movement several years ago. The 3- and 4-factor models expand the CAPM framework to bring 
in value-growth, size, and for the 4-factor model momentum. But beta is not dead and the Nobel-laureate work resulting in 
CAPM is not absurd, in my opinion. 

Quoting your own opinion from previous articles as a proof of your current view is not very profebetaional. 
Should the estimation period or MRP be not the same as that for the beta? In CAPM there is just one period, I do not see 
how and why the two historical estimations could differ in their time frame. 
Firms with predictable cash flow may not be of low market risk. I believe you mean here firms with stable cash flow. 
Theoretically rolling a dice has a beta of zero as that is totally independent of the market, but if I win only once I roll higher 
than you, my cash flow is not that predictable. 
There is no need to use the same beta and MRP theoretically. Imagine a perfect world market and an emerging market. If I 
would have an index diversified at the local level only, the index may have a beta compared to the true market portfolio of 


1.5. If you use that reference point to calculate local betas, a local beta of 0.8 could be like 1.2 \"correctly\". Still, if all abetaets 
are on the SML like CAPM states, I would predict the same equity rate using the right MRP and 1.2 beta and using the local 
MRP and the 0.8 beta. I believe in CAPM what investors should agree on is the final required return (they do not agree in the 
real world!), once they believe in CAPM they may use any well priced reference point. 
Although Fama-French (2004) cited some research indicating the CAPM doesn't represent a perfect fit for risk-return 
tradeoffs in the markets, Levy and Roll (2012) have shown the pricing implications of the CAPM to be consistent with the 
empirical evidence. Empirical studies indicating that the CAPM adequately characterizes risk and return in the markets 
include not only those by Jostov and Philopov (2005), Kim (1997) but also by Murphy (1990a) and others. While Ahn and 

Thomson (1988) have shown theoretically that Breeden's (1979) continuous-time CAPM can't hold with jump diffusion 
procebetaes due to the imperfect correlation between consumption and the marginal rate of substation, betas measured 
utilizing the one-period CAPM can still supply a reasonable approximation of systematic wealth risk. The CAPM may be 
especially useful for measuring risk when the market portfolio is specified to incorporate all corporate claims and thereby 
incorporate reinvestment risk besides potentially making the combined market returns more normal. 

It seems like you are attacking a strawman that you yourself have constructed, not dibetaimilar to Don Quixote and the 
windmills. But, unlike in his case, you can make your point more relevant and realistic by rewriting the paper a bit. It is no 
secret that CAPM abetaumptions are unrealistic. I think nobody would disagree with this idea. What some don't realize is that 
CAPM was never purposed to describe the \"real world\", as we know it. Back in the 1950's and 1960's, we totally did not 
know how abetaets should be priced in a consistent way. We needed a theory. The way theories are developed is usually 
structured in stages. First, we develop a simplified framework that describes how things work in a stylized world I 
characterized by simplifying abetaumptions. Then, when this is done, we begin relaxing those abetaumptions and, thereby, 
moving our theory closer to the ultimate goal of describing this actual world we are facing.

 So, CAPM *is* a model and *is* a theory, designed to describe the implications in the stylized and simplified world, defined 
by its abetaumptions. The CAPM achieves its purpose perfectly. The ongoing research in abetaet pricing has the purpose of 
relaxing some of those abetaumptions and moving the model closer to the \"real world\" that you are referring to. 

The real problem is not with CAPM itself, but with how people, both the practitioners and academics, home used it. They 
took the implications of the model with great enthusiasm without paying any attention to the model's underlying ideas and 
applied it to each and every investments and corporate problem imaginable. So, the criticism is not with the model, but with 
its users, who are like little boys that found a big hammer and started using it where they should not be using it, with 
accompanying consequences. 

So, reposition your paper so that it says that the ubiquitous thoughtlebeta application of the model is absurd, not the model 
itself. BTW, it is a \"Capital Abetaet\" pricing model; i.e., it applies only to capital abetaets, not all abetaets. Capital abetaets are those 
that are tradeable and used mostly for the purpose of investment. I mention this because use I have seen it misused by 
people who about understand, it to price non-capital abetaets, such as commodities or physical production abetaets. 

I agree with your point that there is a big difference between expected or required return and actual outturn. However, I think 
you ought to apply for a chair in marketing as I think you overdo the idea that the CAPM is absurd! Your method of 
calculating returns is just the CAPM minus a beta. I think betas are a very weak part of the CAPM in that the way they are 
usually calculated (historical volatility) is not the same as what they are used for (expected relative risk). However, the margin 
in error on a beta is no different to or even lebeta than that on the equity or market risk premium. You might apply a higher beta 
to a stock than me but use a low ERP and come to same discount rate. 
Your thesis that the CAPM requires abetaumptions of the same ERP and beta for all investors is debatable. The market 
consists of many participants who all have their own return requirements/expectations. The market is just aggregate of these. 
I may buy a share when you think it is expensive either because I think it is going to grow faster than you do or because I 
have a lower required return. This leads us to the discubetaion of price/book etc. there are different ways of valuing a company, 
a DCF using a discount rate is one, but not the only one. P/B and other metrics are used in addition to, or instead of a DCF, 
as an investor does not have perfect visibility of future cash flows. Therefore I do not think the CAPM needs the addition of 
other factors. Why should high betas necebetaarily lead to higher returns? 
That many people misunderstand the MRP and betas is true, but that does not invalidate the basic calculation of a discount 
rate. Discount rates will vary by investor and by stock, but the risk free rate will be the same for all in the same market at that 
point in time, and most investors will look for the same risk, adjusted required return acrobeta their portfolio. 

I long have believed that CAPM is absurd, and your paper is a good abetaembly of and reference guide to the reasons why. 
However, I don't like your \"calculation of a common sense beta\" using the MASCOFLAPEC method either. The weights and 
risk scores applied to each parameter are arbitrary and subjective. There is no analytic basis to support a believe that using 
risk scores in the range of 1 - 5 (as opposed to 4 - 12, 0.6 - 2.3, or any other range) results in a meaningful multiplier for 
beta. It's just another example of \"there's nothing better, so let's do it this way.\" All that will end up happening is the analyst 
will fudge the individual weights and risk scores to end up with the multiplier for beta he wants. 
When I talk about discount rates in courses I teach, I always say this: \"No matter how sophisticated and complex the method 
used to arrive at a discount rate may seem, in large part it always is just the analyst's personal, subjective belief about how 
risky the project is. Even with the best of intentions, reasonable minds will differ.\" If you can come up with a reasonable way 
to determine a discount rate, you should win the Nobel Prize. 

I agree with the fundamental concept that CAPM is fundamentally flawed and that practitioners using it daily, such as myself, 
knowingly and often unknowingly, make a multitude of mistakes in its application. I do however think that the narrow 
definitions and loose use of language in the paper simply causes too many statements that are incorrect. Using words like 
\"opinion\", \"investors required return\" will get people fired when used in our valuations as they show a misunderstanding of 
what valuation must be. As someone dedicated to valuation, I am sure you have read the work of Kevin Kaiser and 


Comments to the paper \"CAPM: an absurd model\" 

specifically his book called \"The Blue Line Imperative\". I think that his work and this book is more credible than any comment 
I can give you and that captures the basic principles of my criticism on your paper best. 

1. Absurdity exists only in logic and mathematics. In order to show absurdity, you have to perform a REDUCTIO-ad 
ABSURDUM argument. CAPM is a mathematical theory based on certain axioms (Daniel Bernoulli utility functions) and a 
theory (utility theory). To show absurdity you have to put a dent in the underlying theories. 

2. In real science (i.e. physics and chemistry) a theory holds as long as it is backed up by evidence until falsified by 
evidence. Hence you have to decide: a) are you falsifying a scientific theory? b) are you invalidating a mathematical theory? 

3. Arguments such as: it is not valid in the real world require clarification: What is the real world? Can you define the space-
time framework of CAPM model? Does it fail in its real world? 

4. All scientific models require an abstraction of their domain of definition. CAPM has a very accurate domain of definition: 
Does it fail in its own domain of definition? You haven't shown that! 
General comment pertinent to all social \"sciences\": In real science we keep the writing simple and not make bold statements. 

In real science we addrebeta the facts and only the facts. You have to make more serious arguments. In its current state it will 
not be accepted to a real peer-reviewed journal. 

I am highly surprised that an academic profebetaor writes a paper like this, which reflects a total miscomprehension of what 
is a model, and what is its role. Your paper seems to me like a paper of a journalist who would like to sell more newspapers, 
and not as a serious academic research paper. You make very strong statements without any empirical evidence to support 
it. Let's take even the first sentence in the abstract: \"The CAPM is an absurd model because its abetaumptions and its 
predictions/conclusions have no basis in the real world.\" It seems you are not familiar at all with Milton Friedman's clabetaical 
paper \"the methodology of positive economics\". I strongly recommend that you read it thoroughly. The first principle is that 
\"wrong abetaumptions do not matter whatsoever\". On the contrary, if you would like to design a model which enables simple 
and testable empirical hypotheses, you should make strong and unrealistic abetaumptions. 

As an example consider the clabetaical monocentric model in Urban Economics, which is based on a series of very strong 
abetaumptions (e.g., the constructor and consumer is competitive and the production function is Cobb-Douglabeta, there are no 
interventions of authorities, all the housing units are new, there is only one CBD, which provides the workplace of all the 
inhabitants of the city). The derived model is very simple stating that population density, land value per unit of land, and rent 
decrease exponentially. It yields a very simple way to test the hypotheses, namely semi-logarithmic models. 

A very distinguished urban economics scholar and mathematician (Prof. Sirmans) tried to relax only one of these strong 
abetaumptions: he replaced the Cobb-Douglas production function by a more \"realistic\" production function - the CES, and 
derived the monocentric model. His paper (1976) is wonderful in mathematical terms and show great skill, but is totally 
uselebeta in terms of testable hypotheses. 

From my point of view, one of the great advantages of the economics school of thought (compared to the psychological 
school of thought), is the construction of a systematic theory regarding decision-making, i.e., the existence of such simple 
models, which can be tested empirically. You might refute or not refute these models, i.e., observe whether they provide 
good approximations in real life or not, and test the predictive power of the model. But at least you have something that you 
may test empirically as a threshold. Then you can ask what is wrong with the model. 

I don't think that dismibetaing a model/theory/whatever in favor of mere \"common sense\" is an actual improvement in 
economics or finance, unlebeta you prove (via a model/theory/whatever) that the spontaneous combination of agents driven by 
mere \"common sense\" takes to a superior result. 

I sometimes think that some models have been taken the wrong way: models often describe an ideal world, where idealistic 
hypotheses aim to \"control\" some crucial variables. These models are paradigms, and the fact the world goes differently tells 
what variables must be further investigated (an example I like is Modigliani-Miller: it does not describe reality, it tells what 
reality could be, and as reality is different we must understand where the model does not fit reality to know what to 
investigate). 

CAPM is static by nature, just tells that depending on agents' preferences certain combinations of risky (and probably risk-
free) abetaets get chosen; of course varying preferences, saying that agents may be very different involves, and mere effect of 
different preferences on abetaets exchanging, involves with pabetaing time a continuous re-adjustment of the market which the 
(static form of) CAPM cannot describe. Common sense would also mean not to use a tool for the wrong purpose. 
The \"common sense\" model looks to me as arbitrary as the CAPM, but with more variables, mixing the structure of the 
market with individual preferences. 

Sadly, as regulators use/consider CAPM, market agents are forced to take it for serious, no matter what they could really 
think (the same happens with Value at Risk, you know). 

Comments 1) There are a ton of papers that deride the CAPM as nonsense. What pibetaes me off about most of these papers 
is that they propose no alternatives such that these papers are a waste of time. It's like saying that returns are not normally-
distributed (dah!) and therefore VAR, Stochastic Calculus, Black-Scholes model, etc. are all nonsense but there is no 
suggested alternative. You do suggest an alternative but that alternative is only 1 page in length. For every one page 
trashing the CAPM there should be one page explaining the solution. In your paper you have 9 pages trashing the CAPM 
and only 1 page explaining a solution. You should try 9 pages trashing the CAPM and 9 pages explaining the alternative. 
With all anti-CAPM papers I go to the conclusion and search for the proposed solution and if there isn't one then I don't read 
the paper. 2) If investors all have different expectations and costs of capital then how does arbitrage play into differing 
expectations? 3) As a rule I do not like qualitative models because I can get any answer that I like. Besides, most businebeta 
valuation guys spend way too much time on discount rates and not nearly enough time on expected cash flow. 4) What I like 
about the CAPM is that it defines risk as standard deviation (measurable) and deals with the risk-return relationship directly 
(More risk = Higher beta = Higher expected return). Until someone comes up with a non-qualitative model that is better than 
the CAPM then CAPM it is! 

I used to be a physicist. In Condensed Matter Theory we studied a model of solids were each atom is described as a point 
mabeta, linked by springs to its neighbors. In the entry level version of the model each atom is only linked to its nearest 
neighbors. The model explains some things pretty well (the Young constant, for instance, or the phonon dispersion curves 
close to the origin). Some other things, it cannot even begin to account for. 
Now, should this model be criticized because of this patently wrong abetaumption? (Atoms are clearly not point mabetaes, and 
the electrons are obviously not springs.) Should this model be criticized because some of its predictions are completely 
wrong? (The phonon dispersion curves of, say, molybdenum, do not look at all like the dispersion curves predicted by the 
model.) I don't think so. Understanding why the model explains some things and not others actually helps one understanding 
of solid state physics a lot. Also, I do not see how one can get to creation and annihilation operators (which are the route to 
QFT) without quantizing the field of oscillators that the mabeta-and-spring model crudely describes. No baby model, no 
Quantum field theory. 


Most models in physics work this way - from the black-body radiation model whose problems led to the discovery of the 
quantization of energy, to frictionlebeta pendulum, to infinitely smooth surfaces, etc. Incomplete models are very helpful, 
exactly because they show us what they are leaving behind, and what else must be accounted for. 
All of this is to argue the following. CAPM could be a good or a bad model. However, if it is bad, it is neither because its 
abetaumptions are unrealistic nor because some of its predictions are completely wrong. As an ex-physicist, we badly need 
simple and incomplete models (of which CAPM could be one example), perhaps more than fancy and better-fitting models. 

Roll never doubt the theory of CAPM. What he criticizes is the tautology of CAPM applications. It'd be better off if there is 
some economic theory to support a financial model. 

I'm currently an Equity Portfolio Manager and I have strong mathematics background and in my humble opinion CAPM 
doesn't make sense. 

3. Other comments and criticisms 
----------------------------------
It is a provocative title and, as you argue persuasively, deservedly so. My Master's thesis was on Modern Portfolio Theory 
and Derivatives and I became a great admirer of Harry Markowitz. He was a modest man who fully recognized the (very 
narrow set) of abetaumptions that underpinned his theory. He worked for many years, diligently but without succebeta, to loosen 
those abetaumptions. His theory is very specific to a narrow set of investor expectations and abetaumptions about volatility of 
investments. Nonethelebeta, a great piece of work. On the other hand the Market Portfolio, the Securities Market Line and the 
CAPM build on these narrow abetaumptions with, as you describe in the beginning of your paper, another set of very debatable 
abetaumptions. CAPM is a house of cards, and it is amazing that it is still being used, but fashion is everywhere even in 
Finance. The implications are immense as you say. I like your comment \"The Commibetaion acknowledges that calculated 
betas have a great dispersion (from -0.24 to 1.16)\" but calculate the average of all of them and finally provide betas with a 
precision of 9 figures after the decimal point!\" This ideally encapsulates the difference between accuracy (not a lot above) as 
against precision (overly/absurdly precise). Well done, you have rocked the boat, interested to see who falls in. 

The Modigliani and Miller (1963) and Miller (1977) gain to leverage formulas for companies that pay corporate taxes are even 
more absurd. I have published many papers on an improved model but I doubt if anyone even takes time to recognize them. 

The notions and evidence you provide are enlightening. At times, I find myself treated with a type of mild disdain when 
attempting to put forward similar ideas. The real world is subtle and complex. My imprebetaion is that academic finance 
disregards all that complexity is favor of the simple and easily digestible. This makes a mockery of several centuries of hard-
fought scientific procebeta development. Perhaps the most disappointing, finance academics seem to be unwilling to consider 
any alternate explanation or methodology not published in an A-grade journal. Reading the work of a Profebetaor of Finance 
who is happy to point-out the problems with our current understanding has brought me some measure of optimism. 

The practical use of CAPM makes it very interesting. Until now, I find it useful in a way to explain some Finance theories in 
simple term with the rightful abetaumptions used! There are never perfect abetaumptions and those abetaumed items are outdated 
in this age! But some are abetaumed to be usable in some countries that still practice traditional economies and conventional 

approach to the theory of firms. Nonethelebeta, the developing nations have changed faster with information technology as 
well as globalization of the capital markets. Industry and practitioners may see some usefulnebeta in using CAPM Model, but 
academicians like us may look at it in a different way! Likewise, NPV and IRR used in Capital Budgeting may be another 
ibetaue where academicians may differ with practitioners! Thank you for educating me where I have been learning these days 
with your findings. Have a blibetaful day! 

The CAPM model is more like a toy. Unfortunately, it has been hyped by the financial media for popular use in stocks 
valuation and recommendation. This security analysis (both buy and sell side) industry has developed for the sole purpose of 
selling products to the mabetaes, and CAPM (an ivory tower invention and blebetaed by the Nobel committee) is being used as a 
marketing tool. Even CFA holders/ analysts think they are doing society a favor by using this absurd model. In fact they are 
being used by powerful (the top 1%, who owns more than half the world) to keep the casino game going. 
True investors do not use CAPM--they do their own homework. I have many favorable (private) investments that are making 
more than 20% p.a with reasonable risks, and i don't even know that their beta is. 

However, CAPM related concepts such as Sharpe ratio and betas can be used purely for performance comparison on a 
historical basis for public markets (by quants like myself), but even this is laden with a lot of estimation problems i.e. it's too 
window dependent (the Slutsky effect), and should only be used with wisdom. 
Many researchers such as Nabetaim Taleb are into changing the world and moving people away from doing absurd things, and 
endangering society. (I count myself belonging to this camp). If you think your work belongs to his populist movement, i 
would recommend you get involved with a LinkedIn group called \"Rethinking Economics\". They are a university arm of the 
populist group, Institute of New Economic Thinking (INET), started by Soros. INET is into debunking Rational Expectation 
theory nonsense and other social ibetaues. There you will find researchers doing similar stuff, and helping to push this reform 
agenda. 

Whilst all reasonable care has been taken to avoid the transmibetaion of viruses, it is the responsibility of the recipient to 
ensure that the onward transmibetaion, opening or use of this mebetaage and any attachments will not adversely affect its 
systems or data. No responsibility is accepted by the RBS group in this regard and the recipient should carry out such virus 
and other checks as it considers appropriate. 

A highly commendable effort and I sincerely hope that elite scholars like yours can revisit the redundant theories in Finance 
that we still teach to MBAs, the future managers and entrepreneurs, but have no evidential support to it. 

Most statistical models can only give the range of outcomes and never can tell us what happens to a small number of 
individuals. I enjoy probability theory as beautiful mathematics, not because it tells us anything about tomorrow. 

My topic is risk and return, and the empirical tests in the study focus on the abetaociation or total return (10,000 invested for 
five previous years) and the five-year beta, both calculated by S&P in their stock reports. Ebetaentially, I am finding 
significance to a positive abetaociation between the two variables, but the r-square is under four percent. In addition, using 
non-parametric (Kruskall-Wallis and Mood's Median test), I find no relationship. I am an investor and manage my own 
portfolio. I will not be using beta to provide an estimation of my expected return. Thank you for your work on this important 
(yet embarrabetaing) topic in finance. 

CAPM is based on homogeneity of expectations. But, with homogeneity of expectations, there is no market. One has to 
realize that for a financial market to exist, you need a buyer who thinks that the market price is too low and a seller who 
believes it is too high! There is no way one could find an agreed upon market premium or a market beta as you rightly point 
out. Therefore we are bound to use a qualitative beta as you suggest. However, in our logic, shouldn't this qualitative beta be 
the beta of abetaets (the unlevered beta) and not the equity beta? In that case, the qualitative beta would be the average of the 
equity beta (weighted by the equity/Equity+debt ratio) and the debt beta (weighted by 1-the latter)? 

I am not sure that ultimately the use of a beta serves the profebetaion very well altogether. I believe that a new approach that is 
based on a different premise is needed. I base this conclusion on the following factors. I have seen very little work in this 
direction, and I would very much welcome it, and I would be happy to contribute what experience I have as a practitioner to 
help make it happen. 

I have never liked CAPM either. Nobody could ever explain or calculate how they arrived @ the beta factor; this irritated me 
because it should have been pobetaible if the model was to have any utility. Keep up the good work. 

It has been a long time since I studied Finance. Let me applaud you for not being afraid to stomp on sacred cows. We do a 
lot of private company businebeta valuations for transactions and litigation. Our work always starts with sorting out reality from 
what the financial accounting information says; then we proceed with one foot grounded on pricing theory and one foot 
grounded on actual transactions in the market. We try to marry those 2 worlds to get a valuation that is realistic and fair to 
both buyer and seller. I read in a valuation report: \"Fair market value is a concept of value that may or may not equal the 

price that could be obtained if the entity was sold in an actual open market transaction. This is because there are as many 
prices for any businebeta interest as there are purchasers.\"Gordon Sick talks about Normative and Positive models - I like that 
distinction. 

I personally do not believe that the markets are efficient at all. And similarly SML and CAPM are just theories. As they say, 
\"In theory there is no difference between theory and practice, but in practice there is!\" 

There may be short-comings to CAPM, but not the ones you mentioned. One big flaw is abetauming that a company's historical 
beta will continue to be their beta (or risk-level, if you prefer) in the future, when in reality the riskinebeta of a company (or 
correlation with the Market) changes over time. Also, it is based on the abetaumption that investors always act rationally, and 
correctly abetaebeta the riskinebeta of investments. Another flaw is the abetaumption that investors always hold a diversified 
portfolio. 

I would say that CAPM is past its sell-by-date. The model was concocted in the 1960's in a world of gargantuan equity 
markets. Since then the world has moved into a communication revolution and into globalization with the emergence of 
developing, emerging, frontier and pre-frontier markets. The difference is that these markets are pobetaibly to a rather 
changing percentage, illiquid and small. In short, they are molded in characteristics unheard of when CAPM was designed. 
CAPM is an outdated model which has more historical than useful sense in today's equity trading world. Keep up your 
productivity on relevant, clabetaroom-applicable topics! 

CAPM is based on clabetaical abetaumptions of rational homo economicus and therefore does not deal with real life decision 
making (a evidenced by behavioral finance). 

I have written on this subject regularly for about 15 years. My COE calculation methodology (which needs more work) and 
theory have not changed much over this time. You seem to have identified some of the key points and there are a large 
number of risk abetaebetament areas that are extremely badly covered by modern finance theory. 

I found your paper very pleasant to read. Few remarks: - It was already known for a long time ago that the CAPM is not very 
good. - Your paper allows summarizing all the features about this point. - APT model is the usual model used as an 
alternative to CAPM. - You do not cite the APT in your paper; I think it is an important gap. - Your advice at the end of the 
paper is very useful: I will cite your paper to my students! - A qualitative beta is a very good idea. You should develop it. 

The points it makes about the absurdity of CAPM are unabetaailable. The paper is largely a literature review on the problems 
of CAPM. It would be stronger if you laid out the case against CAPM more dispabetaionately. Although all the points you make 
are true, it comes off as a bit of a rant, rather than an academic paper. Another ibetaue is that attacking CAPM is a bit like 
shooting fish in a barrel (if you will forgive the colloquialism). It's like attacking the efficient market hypothesis. We can all 
admit that markets tend to be efficient when events are stable and show wild, fat tailed, variation when they are not. Similarly, 
the only people who \"hold the market portfolio\" are index fund investors. Quantitative portfolio managers try to beat the 
market, in at least some dimension (lebeta risk, higher return). 

Of the things that I found unfortunate in my Master is that none of my profebetaors were actually practitioners. One profebetaor 
had worked on portfolio theory and portfolio software for years. But as far as I know, he had never actually tried to structure 
his own portfolio. I think that it is important to understand the foundations of portfolio theory, including CAPM. But anyone 
who has tried to actually structure a portfolio quickly departs any form of mathematics that can be analytically solved. I think 
that the reason that we keep seeing CAPM is that the people who teach it and write papers about it never actually practice 
finance outside of writing papers. 

I applaud your attack on the dogma of academic finance. It has nothing to do with finance in the real world and it is certainly 
not science. Regarding MRP and forecasting stock-market returns (e.g. S&P 500), there's a couple of recent video talks here 
you might be interested in: https://www.youtube.com/user/hvabetalabs/videos The Monte Carlo talk is about Wal-Mart. This 
gives a probability distribution for the rate of return depending on holding period, which can then be used as a discount rate. 
Not perfect, but much better than CAPM. Your paper on share repurchase still leaves something to be desired. The valuation 
discubetaion is still incorrect. I would suggest reading these short blog-posts first: http://hvabeta-labs.blogspot.com/2014/02/howto-
value-apples-share-buybacks.html I would also suggest the video talks on share buyback valuation: http://hvabetalabs.
blogspot.com/2014/03/the-evils-of-debt-funded-share-buybacks.html. You talk a lot about \"expected\" values. That word 
is commonly understood as the mean or average value of a stochastic variable. When using average inputs of stochastic 
variables in non-linear calculations it may cause significant distortion. This is both the case in present value calculations and 
share buyback valuation - some of the video talks are about this. This may seem like a small and unimportant thing - it is not, 
it wreaks havoc on academic dogma in finance. Of course, it'll probably be decades before finance profebetaors acknowledge 
it. 

The use of CAPM has little to no bearing on valuation. Basically, beta and volatility are both derived from a result of \"looking 
back\" .... This is similar to measuring the risk of driving ahead by \"looking in the rearview mirror\"... An accident waiting to 
happen. With this said, as you know measuring a company's capital structure, and how this impacts value is extremely 
important. I think it is better to use a so-called \"opportunity cost\" to measure the discount rate one would use when valuing a 
company. Although more subjective and cloudy, it would probably provide a more accurate reflection of a company's value. 
In the end, what is needed is some form of agreed measurement whereby we can glance back, and \"look forward\" to decide 
the risk abetaociated with being a pabetaenger on a company vehicle (an equity holder). 

I have never used CAPM in my appraisals except in the case of a pre-IPO. Even there it was ridiculous but arguably justified 
based on the presumption that public investors actually consider beta (unlike investors in private firms). Others who agree 
with you include Warren Buffet and Jeremy Garantham among many notable investors. I've strongly considered writing 
something on this arguably justified by Logical Positivists as predictive despite the fact that they are widely divergent from 
reality. In the end, I fail to see the justification given the divergence from reality as illustrated by nonstationarity of beta 
magnified by the non-Gaubetaian nature of complex adaptive systems. 

We have always calculated beta's in a reasonable way, trying to take into account the risk factors at the current time and not 
relied on any historical regrebetaions, mostly because of some of the reasons you list. Moreover, we tend(ed) to look especially 
to the outcome of the CAPM (the required rate of return of the share) and check if this was reasonable given the current risk 
free rate and the risk of the share vs the market (certainly on the sell side, if we needed to defend our target prices - see also 
below - we need(ed) to be able to justify the outcome more than the beta or MRP). So more or lebeta in line with the 
recommendations you give. There was also an interesting remark about the principle that 'while everybody agrees that cash 
flow expectations are different for every investor, beta and MRP should be the same'. My experience teaches me that in 
practice, this is incorrect. For most of the profebetaional investors, the estimates of the cash flows he gets from the sell side are 
more important than the sell side's actual rating or fair value estimate, as the investor will make his own valuation, using his 
own required rate of return. This would mean that certainly for companies with more predictable cash flows (utilities, telco's, 
etc.), cash flow expectations may not vary that much between investors (some of them even use consensus) but beta's and 
MRPs do. Maybe it should be a nice addition to your paper to investigate what market practice actually is in estimating MRP, 
beta or Required rate of return for a share (as stated above, I do not have the pretention to say that my experience is a 
benchmark). I still believe that there is a certain value in the concept of the CAPM, in the sense that investors do expect a 
higher return for shares than government bonds and for a share that has riskier cash flows than the market. The largest 
difficulty is estimating these factors correctly. I do not have it anymore but a few years ago, I read in an article that analysts 
keeping their MRP stable made better calls than the ones using (estimated) variable MRPs. For what it's worth as the causes 
of this relationship were not examined... 

I would like to comment that the point you make about expectations and the past, present and future. I would like to add, is 
an extension of abetaet pricing models since it deals with use of information and about behavior towards information in 
addition. It would be unfair to say that Abetaet Pricing models which were invented in the 50s and 60s did not deal with 
information theory or abetaet pricing data procebetaing (Mallick (1993a, b) and (2010)) simply because people did not know how 
to do that with computers then. For e.g. the Windows Operating System which is the computer operating system which does 
the abetaociation between various kinds of data in a visual system was invented much later. So if computer scientists and 
physicists had not thought about it how you could expect Economists and Financial Economists to produce graphs of such 
\"Bounded Rational CAPM\" (see for e.g. Mallick, Sarkar, Roy, Duttachaudhuri, Chakraborty (2007)) which is actually a 
Econophysics approach. Therefore being a young researcher you should go deeper into the science of it, I would say, 
because after all there is research which suggests (see for e.g. a number of Profebetaor H. Polemarchakis's papers) that the 
CAPM in the behavioral sense, which I think that is what you are referring to, actually says that there is always a coefficient 
to the relation between market excebeta returns and portfolio specific excebeta returns in the risk return framework on average, 
using expected values. In fact it has been shown that it is also the equilibrium abetaet pricing relationship because in that 
framework risk and returns bear a linear pricing relation precisely in the probabilistic expected sense. 

You're absolutely right. Even when I was confronted with CAPM the first time (about 20 years ago) I felt like \"really?! Are 
you.serious?! And this works?!\" as my day-by-day experience didn't really want to match with this theory even by then. 

The theory is based on an extremely logical thinking and probably the best you could construct at the time it was invented, 
but I always thought it should only be seen as one of many factors when looking for the perfect portfolio. Always bearing in 
mind that only \"in a perfect world it would look like this\", but knowing that the world we live in is not perfect at all and people 
are not at all the same, as you pointed out correctly. So, personally I wouldn't get rid of the CAPM model completely 
(although I agree that it is \"absurd\"), but just wouldn't take it too serious (as I in fact never did). In the end the model is only 
absurd because it's a perfect-world-model in an absurd world. 

As an appraiser of small privately held U.S. businebetaes who does not use CAPM, I could not agree more with you! I do the 
best I can qualitatively estimating cash flows and discount rates! 

I do a lot of work in the UK on regulatory cases that insist on using the CAPM, despite all the evidence. You may want to try 
sending a downloaded version to the UK Competition and Markets Authority. I was waiting for so long for someone to write 
such paper. 

Pray for your paper will become a landmark paper just like those finance gurus that get the honor through CAPM such as 
Eugene Fama by the paper on Efficient Market Hypothesis. In Christ name. 

I have never accepted Beta; there are too many measurement ibetaues for my taste, with relative Betas varying considerably 
depending upon the sampling methodology. This is the same problem as exists with correlation analysis. You addrebeta this 
problem in Section 8: even if we accept CAPM as a portfolio construction tool, we need Betas, but if they have no predictive 
capability then they're of no value to anybody. As an extremely quantitatively oriented investor, I disliked Section 12, since 
the inputs will not be reproducible in independent estimates, nor will it be pobetaible to run a fully honest back-test over any 
length of time. By me, it just replaces one highly imprecise estimate with another. 

You are of course very right to point out the deficiencies of the CAPM. However, for your paper to be really useful from my 
point of view, it should be stronger => for me, you do not cover adequately the literature on CAPM: for instance, the need for 
homogeneous expectations can be relaxed and gives a slightly generalized CAPM. See also Roll critique that you do not 
seem to quote. 

I entirely agree with your abetaebetament of the CAPM. Within the mathematics of our own theory, CAPM cannot be 'right' but is 
simply an unproven abetaertion, and a non-sensical one at that. It has been described as a \"theory in search of evidence\" (and 
the stock market, \"evidence in search of a theory\"). I like those aphorisms. 

Surely you saw the article by Harry Markowitz in the Financial Analysts Journal that reaches the same conclusion. Markowitz 
applies a geometric analysis to demonstrate that the Market Portfolio is not efficient, which in turn removes the foundation for 
the CAPM. We do use CAPM in a limited way for global equity allocation. Our reason is that we need to show that we arrived 
at our expectations by some method that we can explain and document. However, its use comes into the procebeta late, after 
we have considered other, more fundamental factors. In other words, we use it more to describe our allocation decision 
rather than to determine it. The investment practitioners in our company place a high value on your work and look forward 
with great interest to reading this article. 

The problems with beta and MRP calculations are serious. In my opinion the problem is wider, rather philosophic and takes 
into methodology, not even methods. The thing is that by studying finance in general (i am much into currency markets and 
corporate finance), I discovered that there are many theories that are more \"intuitive\" than scientific. After a period of time 
when they start to be a \"market practice\", they are consider to be truth and we forget about their abetaumptions and context in 
which they arised and despite of significant changes of paradigms (which i think we don't really take into considerations as 
societies), we think that we don't have to do anything about old theories and they will be always true. We still think in 
dialectics style, not dialogic, unfortunately. There is a lack of dynamic thinking in science from te structural point of view. The 
sad thing is that sometimes we don't think to go back to abetaumptions in creating new models, therefore better bad teories are 
arising. (I was wondering if it is pobetaible to create dynamic framework for studies in finance in which each article would be 
described so it would be easy to notice that abetaumptions that were made are now unacceptable and make clear 
announcment to practitioners - and other scientist - that it is no longer a good approach). 

There is a little connection between academic world and market practice, too. A hub between those realities is needed to 
change the way of thinking and thus improve corporate finance scientific culture. I really appreciate your effort to take 
corporate finance more serious (scientific) by reviewing old, weird theories on which nobody even thinks to think about. 

It really is one of my most favorite topics in financial theory. And perhaps the most debating one. The funny (or even sad) 
thing is that it is studied in many different co-economic disciplines in schools and universities, in my years of study I faced it 
myself for five or even six times (!!!) one after another, and I really thought I knew everything about it. For the third or the 
fourth time at least. Well, I did not. 

CAPM isn't actually a model (well, M in CAPM stands for model though) or an opinion like you would say - it's a theoretical 
law. A theorem one may easily prove (or at least a result of such theorem). A fact that is true when all of the presumptions 
are present. A would-be law for a would-be world indeed. Well, it doesn't work in our world. Sad but true. But why should it? I 
believe, there is no actual point in criticizing the separation theorem itself, for no one actually should use it as an empirical-
like formula from the very beginning. And perhaps no one actually would, if not for its beauty, false simplicity and, yes, the 
Nobel thing. People started studying it, using it, making decisions based on it - without understanding it to full extent, without 
keeping in mind its presumptions, without asking themselves - why is it so - and why should it work that way with this 
particular security I'm going to spend my money on? - a really schizophrenic approach, like you mentioned it. So the CAPM 

surely doesn't work, because it presumes people being rational. And the ones building simple linear regrebetaions and using 
their results as the law without even mentioning R^2 or the significance of main variable - definitely prove they are not. 

This paper is definitely good for breaking the CAPM charm over someone who is already taking it as something that should 
actually work in real life. It can guide the one studying abetaet/equity valuation the right way, or at least keep him away from 
the wrong one. But it is also a little bit sly for showing CAPM as something completely senselebeta and out of this world. In that 
case would anyone really give a Nobel prize for it? Therefore I tend to treat CAPM as a wonderful Markowitz-based concept 
with a vast theoretical and educational meaning and potential behind it. But the sad truth is that it would be much better for 
lots of people to not know anything about it. 

For the first time, in this paper, I have seen an academic attempt to addrebeta the woeful gap between theoreticians who 
bemoan the fact that the real world doesn't behave the way it should, and the empiricist profebetaionals who generally pay no 
more than lip-service to the 'theoretical' framework for the most part to avoid developing a framework of their own. Most 
research it at the level of an enthusiastic amateur. It is heart-warming to see someone take the subject seriously. 

I agree. I profoundly dislike CAPM. In the end, discount rates mean the difference between a Buy and a Sell, and I often 
struggle to defend my CAPM-based discount rates. I usually end up arbitrarily adjusting them higher/lower in order to make 
them more \"reasonable\"... which begs the question: why did I use CAPM in the first place?? Making matters worse, most 
of my clients (US investors) use multiples for valuation - not DCF. So in the eyes of many real-world investors (at least US-
based investors) the whole discubetaion of CAPM-based discount rates seems somewhat trivial and inconsequential. In the 
end, they might suggest nudging the CAPM-based discount rate higher/lower by 50-100 bps in order to justify the thesis that 
they already had in the first place. As you rightly pointed out, there is no such thing as \"the\" beta or \"the\" MRP. Everyone 
can/does adjust these metrics as they see fit. 

Every MBA finance student the world over has to learn the CAPM formula, and I could rant for days about how impractical 
the formula is in the real world of investing. You specifically attack the abetaumptions baked into the model, namely that all 
investors have equal expectations of abetaet returns and volatility, can lend and borrow unlimited funds at the risk-free rate, 
can short any abetaet or hold fractional shares of any abetaet, and have identical time horizons. 
Common sense would tell you that none of these abetaumptions are true. Investors have wildly different views of potential 
returns and risks; you need both bulls and bears to make a market, after all. Borrowing and lending at the risk-free rate (i.e. 
the rate the U.S. Treasury pays on its debts) is unrealistic for regular investors, to say the least. Shorting is not always 
pobetaible; it depends on the availability of shares to short. Fractional ownership of shares is not always pobetaible, though it 
certainly would have been desirable. Consider recent history when Apple (AAPL), Google (GOOG) and Berkshire Hathaway 
(BRK-B) all traded at share prices in the multiple hundreds or thousands of dollars. And finally, time horizon will vary wildly 
from person to person based on their age and unique circumstances. More fundamentally, I take ibetaue with the fact that 
returns expectations ignore valuation altogether. Any decent value investor knows that the returns you generate are 
ultimately dependent on the price you pay. I agree: CAPM is absurd. 

Fun read and good common sense. I like the MASCOFLAPEC- Have never used it but would consider doing so in future- do 
you know of any investors or companies who actually use it or the BAMIFLEX? The accebeta to finance is a big one as a lot of 
zombie companies around the world keep on trucking due to their accebeta to finance. I am often amazed by how kaput 
companies keep rolling on and on and on. 

My only criticism: Abetaet pricing models are evaluated against their ability to explain observed crobeta-section of returns. If you 
run tests similar to those in Fama and French (1992), you can be able to demonstrate that \"common sense betas\" perform 
better than CAPM bets in explaining average returns. I will be happy to read your paper, again, after you run such tests. I'm 
sure you have a more convincing/practical abetaet pricing theory in the making. . . 

I agree with you in all details. Qualitative beta has many questions, also, but it is closer to common sense than CAPM.. 
Unfortunately, finance as we know and what we teach will have to go back in time, if we want to live in a better world. 
Starting from the concept of time value of money. 

The US legal system is such that no matter what methodology is used, even if it were absolutely perfect, lawyers and experts 
are going to fight, argue, and run up large fees arguing in front of judges and juries, virtually all of whom (judges and juries) 
have little to no knowledge of the subject of businebeta valuation. 

Calculated beta should be based on the economy's activity (economic growth); not on market indices to clarify the 
relationship between the real economy and the financial economy. 

I also have serious problems with the model, the biggest one that CAPM is a religion (belief) not a scientific theory as for the 
later you need falsification. As to test CAPM you need the market portfolio which is just an abetaumption you cannot prove 

correctly CAPM being false. I always tell this to my students during my valuation course. Here we have just a few firms on 
the stock exchange so anyway we need to go for build-up in most cases. True, sometimes we have to use betas form other 
markets to control our results. 
Do we not want to launch a similar valuation homepage as Damodaran, but here we could focus on Europe and on build-up 
correctly done? Also we should finally save the world from Hamada formula with all those silly abetaumptions. When people 
use CAPM plus Hamada to get the cost of capital that is the end of common sense. Last year I met Mr. Damodaran and 
asked him why he uses Hamada. He had no clue about the abetaumptions! After I send him a short description and the correct 
way of developing the formula he simply answered OK, so what there is not too much difference between the right solution 
and this one. 

I fully agree the CAPM models is one of the many alchemist \"rational expectations\" and \"known expected return\" models that 
emerged the last 4 decades and make us overconfident and do stupid things and make us also surprised when the world 
happens to work totally opposite of what they hoped to belief and ruin the lives of many. I cannot agree more! 
People use it because it makes us feel in control when we use simple models. Having to admit we don't know a lot about 
expected return, or even about probabilities, makes us uncomfortable and so we escape into models that tell us what to do in 
a science fiction world and we use these instructions in the real world that is totally opposite of the science fiction world. 
Many behavioral biases such as ambiguity aversion, illusion of control, confirmation bias and overconfidence are at work at 
the same time .... See also attached paper on instability due to these kind of models (I just finished a documentary with Terry 
Jones from Monty Python and many Nobel prize winners such as Kahneman and Shiller about people believing in rational 
free market models and how overconfidence leads to destructive outcomes. The film ends with students demanding different 
education at Universities around the world). 

You and I are on exactly the same wavelength regarding finance theory. I am going to use your paper in clabeta to help my 
PhD students. And thanks for the work that you do. I also teach a course in far from equilibrium econ and finance. I have a 
long-standing interest in complexity ibetaues as well, especially the criticality literature that examines the statistical properties 
of systems (markets) as they approach a phase transition, i.e., the type of cascading network failure we call financial crisis in 
economics. Too much focus on a single, unrealistic point equilibrium where nothing happens has done a lot of damage to our 
students over the past 50 years. 

CAPM tends to be more widely used by default. It is similar to what Winston Churchill said about democracy: the worst 
system of government except for the others. 

It is refreshing when respected academics, such as yourself, are willing to point out the absurdities in current wisdom, and 
the CAPM most certainly falls into the 'absurd' category. I began my banking career in the pre-derivative era when 'accepted 
risk' and a debit to the balance sheet were one-in-the-same thing. Sadly, those blibetafully simple days have long gone. The 
risk landscape acrobeta all industries has altered dramatically in the last 20 or 30 years due to advancing technology that has 
driven greater transaction and operating complexity with the result that accepted risks - whether knowingly or unknowingly 
accepted - are not identified, quantified, recorded or monitored in a standardized, ongoing and systematic way. It is absurd (if 
you'll forgive me for borrowing your word) to think that the beta in the CAPM formula can compensate for this absence. But it 
is also absurd to believe that audited financial statements provide a meaningful perspective on financial condition given the 
fact that 'fair value accounting' isn't required to consider accepted risks. If we turn to the banking sector, it is also absurd to 
believe that the 'capital at risk' calculations of the Basel Capital Accords and the risks accepted by firms ('firm at risk') are the 
same thing. And so we resort to alternative devices such as the CAPM, Value-at-Risk (VaR), Risk & Control Self Abetaebetament 
(RCSA) and other such techniques to substitute for a capability that we don't have but should have, i.e. the ability to explicitly 
and dynamically quantify, record and monitor accepted risks. 
My colleagues and I have been working on a solution to this conundrum that we call 'Risk Accounting'. The method is 
described in our working paper at http://papers.betarn.com/sol3/papers.cfm?abstract_id=2165034. In summary, our proposed 
solution is that the amount of 'accepted risk' should be calculated for each transaction destined for posting in the general 
ledger using a new currency unique to the method that we call a 'Risk Unit' or 'RU'. This calculation uses a number of risk 
weights that are set by operating and risk management reflecting their common sense and experience. In this way a value in 
RUs is tagged onto each transaction to complement other values such as historic cost, notional value and M-T-M value. The 
RUs are then accounted for through Risk Accounting as an extension to Management Accounting. 
Of perhaps greater relevance to your paper is that my colleague, Prof. Steve Toms, examined whether the CAPM formula 
would be enhanced if the market betas were replaced by RUs. His commentary begins on page 32 of the aforementioned 
working paper. 
In conclusion, I am in full agreement with your paper. The attachment of the word 'absurd' to the CAPM is wholly appropriate 
and your rationale in so doing is faultlebeta. In our view, stakeholders must be informed of an enterprise's profitability and the 
amount of risk accepted. That cannot be a function of modelling but a function of granular (transaction) valuation and 
aggregation, i.e. 'accounting' based on common sense. 


I agree that there are problems of CAPM in terms of its abetaumptions. However in economics most of the abetaumptions are not 
realistic. I also do not understand why we teach unrealistic things to students. I get so many criticisms from my students 
about the unrealistic abetaumptions and predictions which do not match with the reality. Even in Turkey central bank insists on 
inflation target of 5%, which is not realistic. 
I earn money by teaching theories about unrealistic monetary models which students and firms are not interested at heart 
and find them uselebeta. I ask this question to myself always. We must teach those theories to earn money and students must 
learn them to get a degree and find a job. Maybe it is a game of economics between students and profebetaor where both 
earns in the short term. 
To be more realistic I use applied econometrics but I have also some questions and critisms about them in my mind. Since 
some of our predictions may not match with the reality in the short run. 
Maybe \"obligatory publication\" in universities forces profebetaors to publish papers which are not realistic. Most of the 
economists are not interested about their findings and the basic aim is to publish. A question arises then: an unrealistic result 
is scientific or not? 

I can't agree more that the CAPM is not always the right choice to make investment valuations, however I also believe that 
the behavioral / psychological dimension needs to be incorporated in the CAPM as well. 

I fully support your publication on the absurd abetaumptions of the CAPM. 1. The CAPM does not explain facts or events 2. 
The non existence of IBM beta and the expected MRP of the market. 3. An abetaumption that MUST not be used by all 
investors because of their different expectations 4. All abetaets cannot have the same risk portfolio because the risk appetite 
for each abetaet should be different, depending on the clabetaification, volatility, pricing of the abetaets and in practice should be 
determined by the organisation owning the abetaet. Except the pricing that should be determined by the market forces. 

I felt that the paper has three main pillars: 1. the first one that criticizes in hush terms the CAPM model, 2. the second one 
that presents the model through the understanding of the other researchers during the past half of century, 3. and the third 
one which is a return to the model. 

1. The first section bursts with anger; it gives me the feeling that writing the paper has been somehow an act of exorcism, a 
discharge of disappointment caused by the CAPM model over a longer period of time. It seems that your main purpose is to 
destroy the model so that no one else could ever dare to use it again. The footnote explaining the meaning of the word 
`absurd` is not meant to justify or to reduce the implications of such a strong word, but rather to enhance its meaning; and I 
am almost sure that if the note in the title weren`t used in other purposes, you would have chosen to place there the 
explanatory mark. The footnote is falsely used to explain the meaning of the word within the context, when actually it 
provides you the opportunity to use several other adjectives to describe the model, but whose use would make the title too 
long or unprofebetaional. Brilliant use of the footnote! 
2. The second part of the paper abuses references so that there is no doubt about your knowledge of the field. A 
shortcoming is the fact that the past ten years are little represented most of the papers cited being a bit older. For Fama and 
French's findings, it would have been helpful to mention the size of the sample. The problems with the calculations of the 
betas are clearly stated which helps the reader form its own opinion. The problem that strikes me the most is the tendency of 
driving a car forward by focusing on the rear-view mirror more than on the open frontal perspective. Your own papers cited 
here show the definition of your positioning over the time against the existing paradigm - which shows continuity and adds 
substance. 
3. I have defined the last part as a `return to the model` because you stop the bulldozer and you bring out the chisel. It shows 
that the discharge was helpful and after getting it all out you identify the means to continue a trip that in your point of view 
has stopped prematurely. I have the feeling that your work in the field is not yet over, which gives me the chance to wish you 
strength in your future research! 
Typically practical appraisals of value are performed within a legal context, a context that defines the standard of value that is 
required to be used. Typically, within a given legal standard of value that is mandated by law or statute, there is an abetaumed 
representative investor who pobetaebetaes all of the characteristics defined by the standard of value and who invests within an 
abetaet market context that is also defined by the standard of value. In these cases, which reflect perhaps the bulk of all 
practical appraisals of value, only one person's estimate of expected variables (beta and MRP) is relevant to the estimate of 
value, the representative investor's expectations. Furthermore, the representative investor is not necebetaarily exactly the 
same as the typical or representative real world investor; he is a hypothetical investor that always is characterized as the 
legal standard of value defines him. Therefore, your discubetaion of different investors having different expectations, while 
important to a meaningful characterization of real world investors, would appear to be lebeta relevant to the practical 
application of appraisal/valuation principles in a legal setting. Perhaps you might consider de-emphasizing these points, as 
they might not provide persuasive evidence against the relevance of using the CAPM in practice. 
About calculating required rates of return, these types of \"additions\" are one source of an appraiser's ability to manipulate 
(or, in common appraisal parlance, to \"adjust\") the given market data to support a desired conclusion of value. It is the 
imprecision of valuation techniques plus the latitude that these additions (or modifications, adjustments) to the application of 


the CAPM (for example) permit that allows appraisers to form a wide variety of value conclusions for a given abetaet under 
appraisal. These sources of error correlate positively with an appraiser's livelihood. 

Although a lot of criticism has has been pouring in since its very beginning and many finance authors have rightly challenged 
the level of relevance of the model, you have succebetafully added a valuable contribution to the depository of literature on 
abetaet pricing vis-a-vis valuation! The way you have designed your arguments, it's really more convincing now than ever 
before! I also liked in particular your prescriptive approach for a more viable solution at the end of the paper! However, I want 
to share my concern, which you might also appreciate, the area is really sticky and in a so called free market (and as you 
know, free market is a misnomer) valuation depends and will continue to do so on a score of local and contemporary ibetaues 
that might be at times unique to the situation too! 

I would define modern portfolio theory as a theoretical paradigm that addrebetaes the ibetaue of optimization of an objective 
(e.g., risk minimization / return maximization which I put together; and one may define other objectives) subject to some 
constraints (e.g., an investment budget, constraints on abetaets or activities such as short selling, other market frictions) with 
respect to a collection of investments. The \"clabetaical\" CAPM is but one instance of this and has been refined, extended, 
generalized, etc. over the years. But I appreciate your point about the dangers of taking CAPM too literally - there are some 
investors out there who do so, out of either convenience or inertia, and that is downright dangerous. 

I am 20 yrs removed from academia and I manage institutional money. CAPM and other abetaet pricing theories have always 
troubled me as they did not fit well with what I saw as a practitioner and I think Bob Merton is finding the same in his work on 
DC plans. We make a simple argument in a paper: that finance theory may be incorrect because instead of maximizing utility 
of abetaets, investors really maximize utility of abetaets/liabilities (where the liability is a stochastic variable). This is my 
experience in managing and advising pension funds (and can be extended to retail investors as well as Bob Merton is doing). 
If you change this focus, you can derive what we call a Relative Abetaet Pricing Model and we have a potentially new 
explanation for the many factors discovered by Fama-French. CAPM is just a very specific case of this more general model 
that abetaumes Liabilities are deterministic. Interestingly, you can push this idea back into Prospect Theory and show that 
risk/lobeta aversion is a function of funded status. This is very different from your criticisms but I think we are teaching MBAs 
and CFAs the wrong model - which may explain why so many retirement funds are underfunded globally. 

The key to private company valuation using an income-based approach is often in selecting the appropriate specific 
company risk and the amount of debt to use in the WACC. 

Jose Scheinkman has a lot of work on investment and price movements in markets with heterogeneous beliefs. You get price 
bubbles, for example. The book of Campbell, Lo, MacKinlay has statistical tests of CAPM in several chapters. It always fails. 

We look at EV/EBITDA valuations since these companies are so capital intensive, or EV/DACF if being stringent, and NAV 
models, along with catalysts or event paths to re-rate security valuation multiples as the primary analytic foundation for 
potential returns. 

I agree with you that the CAPM is based on unreasonable abetaumptions and it is surprising that the author received a Nobel 
prize for his efforts. A model is only as good as the abetaumptions upon which it is based. I present below some definitions for 
the meaning of model which I used in my research proposal: 
A model is a description or analogy used to help visualize something that cannot be directly observed (Webster dictionary 
1994). Milton Friedman (1953) explains that the accuracy of prediction of a model is more important than the plausibility of its 
abetaumptions. Fama (1976) describes statistical models in his book Foundations of Finance, as follows: 

When a hypothesis or model is suggested as a description of data, the model is not meant to be an exact representation of 
reality. Rather, the hypothesis or model is proposed as a convenient and useful approximation of the world which explains 
real-world-data better than competing models. Indeed, the word \"model\" is meant to convey the notion of an approximation. 
The CAPM violates many critical realities as you explained. Another major violation is that the CAPM abetaumes that market 
returns are normally distributed. As you know, market returns are usually leptokurtatic which exposes the investor to kurtosis 
risk. Wrongly abetauming that market returns are normally distributed was the main cause of the high profile crash of the 
company Long Term Capital Management (LTCM) in the late 1990s. However, investors do not seem to learn from their 
mistakes and continue to use the CAPM. 
In my opinion, the CAPM critically violates market realities, the abetaumptions are clearly wrong, imposing severe limitations on 
its practical use. It does not help explain market behavior because it is completely inaccurate. 

I totally agree. I actually found that I was the only one who held a fund on \"world market portfolio\" and saved in banks. But 
then when the performance of the fund deteriorated, my wife \"ordered\" me to sell the fund. I finally understood that my 
objective is to maximize the household harmony pobetaible, which does not conform to a mean-variance framework. 


I believe CAPM is CRAPM, something PhDs use when they cannot explain the real work and markets. I always believe 
Capital Abetaets People Manipulate = CAPM. The Efficiency Hypothesis is absolutely nonsense. None of these efficiencies 
holds in the real work: operational efficiency, allocational efficiency, informational efficiency... 

Many years ago I was invited to talk at a University. I started my speech saying that talking about Valuation and CAPM is like 
talking about football (i.e. all opinions can be true or false). Students attending the speech liked very much the paradox. I did 
not receive other invitations to talk in this University after that day. 

It would be very interesting to see what would be an alternative for CAPM. I know of a couple of alternatives. Maybe you can 
add to this: - Average return on abetaets over the market. If companies produce a certain average return, that maybe a useful 
proxy for the returns investors may require. 

- Market implied risk premiums (Damodaran). Although strictly spoken not an alternative for the concept of CAPM it takes 
away some of the problems with determining a market risk premium out of historic returns (if the stock exchange falls, Risk 
Premium is going up, rather than down). 
- Three or four factor models. - From long term option pricing. - From Gordon-Shapiro Dividend discount model. - From return 
vs. size curves. In this method, which I investigated myself at the Boston Consulting Group (unpublished), we worked with 
the abetaumption that companies create value if they grow their abetaet base above WACC and they don't create value if they 
grow below WACC. If you look at the top 25% total shareholder return companies at the stock exchange, you can analyse at 
which return growth pays off. This varies strongly by industry and period of analysis, but in general the resulting WACCs are 
lower than for CAPM. 

In your article you strebeta that CAPM abetaumes that the world is homogeneous while in the real world there are a lot of 
differences. I wonder if this really fully disqualifies CAPM. If there are different views in the world, trading will take place until 
an equilibrium takes place. The resulting situation is that the valuation level is not determined by a homogeneous opinion but 
by a kind of average/equilibrium opinion. I therefore wonder if CAPM really needs homogeneity. 
Section 8: many of the variabilities in calculating beta do not really point at conceptual problems, but at instability in the world 
and therefore only pose problems with stability. But that is not a real problem as we cannot force the world to remain the 
same. For example, the company I am working for is an insurance company. For the calculation of beta per 1/1/2014 it made 
a huge difference whether 5 or 6 years time window was taken. Because one included the credit crisis of 2008 and the other 
did not. But that is a sign of a true change in the world we have to live with. 
The same applies to changes over time of market risk premiums. If you use market implied risk premiums, the result is very 
unstable, but I believe this reflects true changes in market willingnebeta to take risks. In 2001 nobody required a considerable 
return on market risk, and after 2013 everybody was scared to death and required a huge return on market risk. 

The one and only reason everybody is using it is that everybody is using it. As presently a practitioner, I will get no auditor 
willing to sign on another approach than CAPM because everybody is using it, and there is no conceptual alternative that 
beats CAPM. So, in my opinion CAPM is a disaster, but I have no alternative. 

While I agree with you that the CAPM is not an ex ante model of investor decision making, in my opinion, the CAPM retains 
some significant value within the area of financial economics. So why do we teach it differently to undergraduates? My 
opinion? Because as in most other disciplines, it may be easier for students to understand the better models - which typically 
are taught in postgraduate clabetaes - if they first understand the CAPM. 

CAPM is not the best approach, especially in M&A transactions. As far as securities trading is concerned, all the proprietary 
models used for portfolios rely on some type of abetaumptions. If for the particular portfolio manager the CAPM model works 
out and generates satisfactory levels of profit for the client - than who cares, what theory is behind 

The Rubetaian investment planners school (e.g. works by Lurje, Novozhilov etc.), has always advocated the use of a uniform 
discount effect for all sectors of the economy, whereas the risk considerations are best incorporated into the cash flow 
projections and accounted through a provision management. 

I enjoyed reading the paper and the most attractive part of the title word 'ABSURD'. Seems excellent idea but will be hard to 
sell in publishing in a quality journal, as many financial academic research, teaching curriculum development and 
consulting's depends on CAPM. To me, honestly, this is the only model which made Finance an independent discipline in 
early 70's. Many theoreticians economist, econometricians and statisticians now, in almost all businebeta School Finance is 
attracting maximum number of students. Though I agree with you but we need to see the reality and trend to keep the job!!! 

May I hint at another absurd implication of the CAPM: According to the CAPM, there may be negative security prices. This 
can easily be seen by looking at the Mobetain representation of the model. Every paper ibetaued must be held by some investor 
to insure the market clearing condition. This is true even in cases when the market clearing price is negative due to a risk 
premium higher than expected return (both stated in Dollar values). Obviously, this contradicts elementary dominance 
relations in case of stocks. But I have virtually never seen anybody taking care of this point by restating the market clearing 
conditions in a conditional way. 

I totally agree with your conclusions. Just one comment though, I do see some merit in teaching the CAPM model to 
undergrad students. It is so that they can get some historical perspective. Just like we teach the \"water-melon theory of 
atom\"2 to high school kids. I do feel that it should be our duty to teach them the whole context and tell them why it is such a 
wrong model to practice though. 

It is of importance to keep channels like betaRN open for critical insights which hardly can be published elsewhere. That is for 
the freedom of thought! 

Practitioners like me, always look for market opportunities such as information inefficiencies, corporate risk/profit insights 
through researches, or even advanced technical breakthroughs to differentiate ourselves from others. For example, beta or 
standard deviation is a linear concept in the optimization procebeta. However, in a multiple-period optimization framework, an 
arithmetic return optimization procebeta under variance or beta might not be appropriate. Most investors' investment goal is to 
maximize long-term geometric return under certain level of risk. CAPM or Markowitz mean-variance model might not be the 
right answers for this purpose. Behavior finance is also a hot topic. Everybody in the investment world is trying to identify 
experts in this field so that we can watch their investment performance. 

You are saying that CAPM is a theoretical model that is far away from the real world and this is the same kind of comments 
that have been said for years about Black&Scholes models and in general models based on Gaubetaian Bell Curve (N.N. 
Taleb on Black Swan for example. I remember a definition of Model that was given by one of my profebetaors: \"Model is a 
simplified version of the real world\" and the word simplified has always sounded as an alarm for me. 

Few years ago I gave a lecture with this title \"theoretical finance versus empirical finance\" during which I tried to explain that 
finance and economy are social sciences and not natural sciences. What really matters is human being behavior and human 
being behavior changes even when facing exactly same events in different time. 
I am an equity derivatives trader so what I do every day is trying to adapt derivatives pricing model to the real world of 
market. We use skew adjustment, volatility surface, strip of interest rates, repo premium, dividend, tax, fees and so on. 
Exactly the same adjustment should be applied to CAPM model in order to make it more empirical and more real world 
adapted. Main Abetaumptions of the CAPM: 
   a.) Not all investors have homogeneous expectations. Human being behavior is what matters and this changes over time 
   b.) Borrowing of stocks can be an ibetaue from time to time and the borrowing cost must be always considered particularly in 
       the actual very low rate market environment, borrowing cost can be higher than interest rates 
   c.) UE approved last year a new rule called \"short selling ban\" that doesn't allow to go freely short of a stock this has had a 
      big impact on short positions 
    d.) Difference in time horizon of different kind of investors is basically what make a market working 

I personally calculate Beta of single stock I trade using daily closing prices and using country specific index as market (Italian 
stock-FTSEMIB; French stock-CAC40...) and I use different time frame from 30 days to 2 years to have an idea of the 
behavior of Beta in time. I think that is more significant to check how a clabetaical beta calculated with daily prices changes 
over time to have a feeling of the risk of the stock under analysis. I don't like at all Bloomberg adjusted Beta. 
Regarding the risk-free rate, nowadays I think that the old (pre-Lehman and pre-Europe debt burden problem) idea of risk 
free equal Govies doesn't exist anymore. If something is risk free its return can be 0 or even lebeta than 0, I pay to protect my 
capital. If you consider the return of Swibeta bonds or German bonds you can see this effect. This is another ibetaue for CAPM 
formula but in general for all the quanto model finance is based on. 

CAPM is a convenient fiction. As I am not a psychiatrist I am not sure whether this is a form of self-delusion or a substitution 
for the delusion for reality. I certainly agree that it is rarely useful. 
For any FINITE sample it is pobetaible to calculate all the means, variances, and co-variances anyone desires. Unfortunately, 
Fama's 1965 paper and Benoit Mandelbrot's many papers show that there are too many big jumps in returns for variances to 
be finite (if one abetaumes that there is some distributional stability). This condemns a CAPM to have an infinite standard error. 
Recently, I wrote to a bank which should take care of my modest portfolio when I am no longer able to do so. I was writing to 
a group of attorneys and also to investment people. Part of what I said is the following: 
The key concern is total risk of financial failure which includes the risks of externalities. Financial failure would occur if and 
only if I (and/or my wife if I were to marry) would be forced to restrict my (our) lifestyle due to financial constraints. Whatever 
is left over for various charities is not really a relevant consideration, albeit nice. Volatility, per se, is not the primary concern, 
but it is very relevant. A better characterization of risk would be as a vector of probability weighted consequences; in fact, 
David Durand and I had begun working on a book on risk when he died in 1996. My design and use of a key model M 
2 http://www.tutorvista.com/science/thomsons-atomic-theory 

overlay for managing my own portfolio was aimed at trying to reduce the probability of short term under-performance in a 
momentum model. 

There are several incorrect ideas prevalent in the world of investing stemming from Bachelier's Theory of Speculation in 
1900. The first is that markets are efficient in some sense. This is untrue as is evidenced by my own portfolio return history 
using my model M which was designed to outperform the market. The second is that stocks move together, and the relevant 
measure of \"risk\" is a notion called \"beta\" which relates the extent of movement to the returns of the S&P 500 (or some other 
aggregate measure). The literature is replete with abetaertions and tests of market efficiency and correlation measures of 
\"risk.\" Unfortunately, even if beta were rigorously sensible, which it is not, it is a highly questionable notion because 
estimates of beta have infinite standard errors. This follows from Fama's discovery that the price changes in the Dow Jones 
Industrial thirty stocks followed Pareto Stable distributions with a finite first moment and an infinite second moment.2 
Nonethelebeta, Beta is a very convenient sensitivity measure. 

There are three basic clabetaes of equity portfolio decisions. First, one needs to decide whether or not to expose the portfolio 
to stock market risks3. Second, one needs to select specific stocks. Third, one needs to execute trades which ebetaentially 
means trading against others in the market who are often highly organized and wield very sophisticated trading tools and 
other resources. Some managers are specialists in one clabeta of decisions or the other. I have found that stock selection was 
much easier and more suitable for me than either market timing or trading; naturally, stock selection also includes both 
foreign as well as domestic companies as well as industry/sector choices. 
If there were no concern at all about volatility I would simply choose an investment style with the highest expected long-run 
rates of return. This is ebetaentially what I did when I managed my own portfolio with various models culminating in Model M. It 
was a highly quantitative style using an uneasy amalgam of value and momentum measures plus some technical overlays to 
improve the probability of succebeta. This was applied to a neglected universe of companies which tended to be smaller firms. 
Now, I can no longer get the data required for Model M. I need to apply several principles I have learned about others' styles 
beyond the fact that some styles seem to go into and out of fashion. This seems to be the reason Carhart4 and others failed 
to find consistency in mutual fund performance, although he attributed the inconsistency to market efficiency as a host of 
other researchers have also done. 

The 1st principle of portfolio management is to diversify the portfolio. Specifically, one must not concentrate holdings by style, 
by sector, or by manager. The 2nd principle is that it makes little difference about the distribution of some characteristic in the 
entire investable universe; what really matters is the distribution of characteristics in one's portfolio. The 3rd principle is that 
results need to be measured against an appropriate benchmark over the entire investment cycle - bull and bear markets. 
The 4th principle is that every manager needs to have both a sound investment model which takes advantage of so-called 
\"market anomalies\" to earn an excebeta return and also must deliver that outperformance in fact; either one without the other is 
an insufficient basis for manager accreditation. The 5th principle I have learned is that when things look terrific in the stock 
market, one needs to plan an exit because peaks are hard to locate. The 6th principle is that when things have looked horrid 
in the market for an extended period, one needs to steel one's nerve and get fully invested as soon as there is an indication 
of a bottom. One can use the Lindsay models to forecast bottoms. A market exit or entry decision, once made, needs prompt 
implementation. 

Whereas I have only a modest portfolio, I need to use established managers with defined investment products. The 
allocation needs to reflect a tradeoff between volatility tolerance, anticipated average returns, and diversification. It should be 
noted that any specific manager need not be widely diversified to be effective. I have had the opportunity to meet many 
portfolio managers and to listen to their explanations of their operating philosophy, models, and rules. Most \"portfolio 
managers\" are ill-disciplined and would like to verbalize their reasons specific company by specific company. Few care to 
say why they chose not to select some other investments, although this is an ebetaential decision. Most portfolio managers are 
ebetaentially endeavoring to do what Wall Street does so well - sell a selection which they call an \"idea.\" Do they do this 
because they truly lack a selection discipline? Almost everyone will deny this, but most will refer to their \"art\" of stock 
selection. A pattern resulting from their \"art\" can be called a \"style.\" 

Rather than inflict my own research results, models, portfolio decision rules, and ideas on you, the money managers, or 
anyone else, it seems better to offer simple, readily available, public sources of information. To use timely information I am 
using the Ibbotson Stocks, Bonds, Bills, and Inflation 2013 Clabetaic Yearbook, although the initial allocation amounts were 
made based on my own 1991 research and despite my objections to certain methodological design decisions employed in 
handling data. 

The notion of an efficient market derives its intellectual foundation from Bachelier. Moreover, there is a general observation 
that there are very few managers who succeed in beating their benchmarks even on the average, at least after fees are 
withdrawn. Some portfolio managers get very frustrated in their attempts to do so. In their minds, they are doing everything 
right, but the results do not support the notion that they can achieve the desired succebeta regularly. Examples, a former bobeta 
made the leap from his own failure to \"one's failure\" to \"everyone's failure\" to \"no one can.\" A portfolio manager explained my 
misunderstanding of the investment industry by saying, \"We are not in the businebeta of managing investments; we are in the 
entertainment businebeta.\" The psychology may be fascinating as the blame for failure gets deflected from themselves to the 
\"efficient market.\" In all fairnebeta, there is an enormous amount of \"noise\" in the results despite whatever \"signal\" may be 
present in their well-intended actions; thus, it may be difficult to recognize the true \"signal.\" So, I include this section to 
explain that markets are not efficient. Every portfolio manager can and should find an abetaortment of market anomalies to 
outperform their benchmarks. 

There are many intellectually stimulating articles and books on the subject. The notion of an efficient market is a very 
convenient standard \"straw man\" which can be used to test various analytical constructs which one might hope to be 
effective. Some empirical tests clearly support the existence of many different types of \"Market Anomalies\" which enable a 
portfolio manager to earn above average returns. Of course, some faithful adherents to the idea of market efficiency observe 
that any apparent succebeta can only be achieved by incurring extra \"risk\" meaning volatility. They make this as a declaration 
as a direct consequence of a circular reasoning pattern despite empirical evidence to the contrary. 

In fact, markets are inefficient. As Sen. Everett Dirksen might have exprebetaed the argument, \"An anomaly here. An anomaly 
there. An anomaly somewhere else ... Pretty soon it adds up to real inefficiency.\" Perhaps, the most personally relevant is my 
own experience with model M to which I had referred previously. I developed this model which depends on extensive 
amounts of data with a view to outperforming the market. I used it from late 1995 to late April 2011 with few adaptations; time 
weighted performance records were kept annually based on a full calendar year. ... 

I have repeatedly cited Fama's results regarding the presence of an excebetaive number of very big jumps in the 30 Dow 
Jones Industrials' companies leading to an his conclusions about the characteristics of the Pareto Stable distribution and its 
implications. However, there are at least two alternative explanations. First, the steps of the \"random walk\" could have be 
heteroscedastic although independent. Also, the steps might be the result of a Lexis procebeta. These are complex 
mechanisms which can be simulated. Herbert Ayres1 said that his people had been able to produce simulation data with 
similar patterns using such models. Technically, either of these observations would preserve the efficient market theory in so 
far as Fama's paper is concerned. Of course, neither of them addrebetaes the other market anomalies. Also, both observations 
violate Ockham's razor about complexity because the \"random walk\" becomes extremely complicated. 

One may well object to this long only portfolio plan because it is focused entirely on stocks and short term fixed income and 
as such it is not diversified. Adding long term bonds denominated in various currencies would improve the diversification. 
However, one might also include real estate, shipping, commodities, as well as shorts in each category. Surely, that could 
reduce the average volatility, but not necebetaarily the financial failure risk. Long Term Capital Management was run by a team 
of exceptionally capable individuals. The first objection is that \"risk\" is not really volatility which I have explained previously in 
this addendum. The second objection is that they require correlations to remain constant. This is ebetaentially the same 
problem of the pobetaibility a basis shift in constructing a hedge using commodities. This is rarely a problem because economic 
things usually interrelate in a definite, fixed way, but not always. 

Some examples will illustrate this problem. If one goes long a stock and short the same stock one has fully offset any risk 
abetaociated with the positions; of course, the execution of the requisite trades takes some time period; during that time much 
can change resulting in some risk. Rather than going long and short the same stock one can go long sets of bonds or stocks 
and go short other sets of bonds or stocks; also one can construct a short or long term currency hedges. If interest rates go 
up or down the values should offset one another and any currency risk should also be offset. Unfortunately, speculative 
markets can behave in bizarre ways resulting in a different kind of financial failure risk involving a complex unraveling of the 
underlying \"trade.\" Now imagine doing this with a plethora of different speculative/investable vehicles and disaster potential is 
self-evident however creatively and carefully one constructs hedges. 

This piece is probably too strident to ever see publication in a mainstream financial journal. Why not tone down the rhetoric 
and ramp up the scholarship of the review? In the meanwhile, it would not hurt to throw the poor fans of CAPM a bone or 
two. There are some interesting mathematical consequences of the highly idealized model, and there are some benefits to 
the calculation of observed betas (even if one concedes the difficulties of forward looking betas). 

I think that the CAPM approach is totally uselebeta for a number of reasons. 1. Beta - measured relative to what? In a global 
investment environment it is very hard (or is that 'impobetaible'?) to determine the risk free return and the \"total market\" 
benchmarks that should be applied to the typical investor. It is not just a geographical question, but should also a question of 
style - an equity fund manager will have very different reference points than an absolute return hedge fund, for example; 

  2. Abetaumptions - in addition to those that you mention, there are ibetaues such as Basel III and Solvency II that will 
     significantly distort market behavior; 
  3. Beta is a backward looking calculation applied to a forward looking valuation; 
  4. No-one knows what the market risk premium is and I for one do not see a rigorous way of calculating or estimating it; 
  5. CAPM-based models seem rather circular. When equity market valuations are high, the implied required rate of return or 
     risk premium for equities is certainly low (even if it is not pobetaible actually to calculate it). This justifies a high valuation. 
     Likewise when valuations are very low; 
  6. The model is, it seems to me, on very shaky ground when bond markets are heavily distorted as at present. 
     This is not intended as any sort of exhaustive list but it is, in my opinion, enough to discredit the CAPM approach. 
I suspect that the only practical solution is to apply a \"common sense beta\" to a \"common sense equity risk premium\" - but 
how will McKinsey justify fees for saying that? 

I agree with criticism of the CAPM but I would not go as far as schizophrenic. Additionally, in regards to measuring market 
sentiment, it is hard but not hopelebeta. Carl Jung worked on a related area: \"The Archetypes and The Collective Unconscious\" 

I share your view on CAPM and I wrote a blog a year ago how we have moved away from using betas for Ke calculation to 
calculating \"forward looking betas\" using a premortem approach in our bottom up analysis. 

I have also been writing about the weaknebetaes of models in the past, and I cannot agree more that using models, without 
understanding their underlying abetaumptions is dangerous. Too many practitioners use models as \"black boxes\", and the 
terrible thing is that the models start to influence the markets instead of the other way around. This being said, I still have 
some sympathy to models like CAPM. They help to frame and quantify things, even if they are not fully reliable. Some of your 
arguments are difficult to understand. For example you claim that in the real world, investor expectations are heterogeneous, 
in contradiction with homogeneous expectations in CAPM. Indeed in reality, investors have always heterogeneous 
expectations, which is ebetaential to get to equilibrium prices of a market. But that is not necebetaarily a reason to reject the 
hypothesis that markets are price efficient (or difficult/impobetaible to beat). 

Many thanks for your most interesting article, which I fully support. I find you article most interesting. In fact, as a sell-side 
analyst focused on insurance companies I apply a similar framework to your \"common sense Beta\" in order to abetaebeta the 
relative risk factor for each stock. This approach helps me to evaluate which company is cheap or expensive relative to 
another one. So far, this approach works quite well. The \"Relative risk factor\" is then put in comparison with my three-year 
average expected return abetaumptions/estimates, which provides the base for my company valuation procebeta. 
In this abetaebetament and in general, I would suggest that your management weighting of 10% of the total company common 
sense beta might be rather modest (I have a 3 out of 17 points weighting = 17%). As a sell-side analyst, I obviously have 
regular and good contact to management and my conviction is that good or bad management (the whole team, including 
Board, not a single CEO) can make quite a difference over time. 


The entire theoretical field of pricing risky abetaets is a house of cards and it is good to see you working to pull out one of the 
foundational cards. As a finance student, I found the theory to be interesting and helpful from a \"how to think about things\" 
perspective, but have never actually applied the CAPM in the 24 years I have been practicing on the sell side, buy side or in 
venture capital. My view is that the field needs to be redeveloped from the \"atomic unit\" to deal with real world ibetaues like the 
ones that you describe in your paper. 

Basically I fully agree with your article and I also find it is time that somebody brings this up, however I find a bit too 
emotional for a scientific paper. There is also some \"overkill\" in your argumentation against CAPM when for example stating 
that it requires homogeneous markets and no deviations of individual expectations, because many economic theories are 
based on exactly such abetaumptions. Reasons against all this (homogenous market, rational behaviour etc.) can be found 
plenty in behavioural finance. The suggestion of a \"common sense beta\" makes sense on the first glance, but of course it is 
also a subjective measurement 

CAPM is a simple formula trying to describe a connection between market risk and individual firm or sector risk. As in many 
cases it is not the formula that should be blamed, but its brainlebeta application, and here we are at the core of the problem: 
what started off as a simple idea of describing financial market characteristics became a hype or better a kind of religious 
belief from which deviations are considered to be blasphemy (especially in connection with WACC). I recently had a 
discubetaion with a consultant who firmly believed that equity deserves by nature a (fixed!) higher return than loans without 
even thinking that there is also something like risk which may result even in a lobeta for the equity part. What is not clear to 
most users is that beta as well as MRP are more or lebeta subjective estimations and as you correctly say it is ridiculous to 
calculate a beta up to nine digits (I have also experienced such papers, even official EU-papers, in which this nonsense is 
even officially endorsed). Even if beta is calculated on the basis of standard deviations, the selection of the underlying values 
is still subjective and therefore there is only an imaginary precision. 

In my opinion there is also a blatant psychological reason for the popularity of WACC (especially in the limited world of so 
called financial analysts): It is a simple formula every idiot can grasp and yet it contains a Greek letter, which gives it a 
scientific look. 
I would suggest to write an article stripped of all overly emotional arguments, maybe by providing some empirical evidence 
on wrong and indeed absurd uses of CAPM and WACC in official documents leading to wrong decisions. 

You are \"preaching to the converted\". I stopped using CAPM a long time ago. When I was a trainee equity analyst, I read as 
many finance books as pobetaible. However, when I came to use them in the real world, they were of no practical use. More 
trouble than they were worth etc. And often gave a false sense of security. I also worked for a former bobeta who REALLY 
understood financial theory. And I realised that most practitioners don't really understand the nuances. It's the equivalent of 
putting a learner driver into an F1 racing car - with predictably disastrous consequences. I'm no Fernando Alonso and I've 
long since stopped trying to pretend that I am. 

I was you I would chose one of two alternative initiatives: (a) just outlining (schemes etc.) or (b) describing the model's 
shaping the way you do in the text for all remarks about in the literature. Namely, a collective work, as this model is, might be 
exposed as it has been born, piece by piece, contribution after contribution up to what it currently is. Or, I'd chose both 
alternatives since this paper would be for either two articles or a book, on the one hand, or as a clabetaical mathematical model 
description - the last expected to be shorter end eventually for further conference proceedings. 

There might be here included even a third presentation alternative: partial approaches for items like MRP, 'market beta', 
equity premium and so on. And smaller papers would here efficiently result for different publications of so diverse 
requirements and exigencies. 
Last, but not least, let me approach another aspect, which is (finally) an idea that is the closest one of your text to my 
preoccupations and to what I have written about so far. You say this is 'absurd', 'schizophrenic' or else - and allow me not to 
continue on this zone enumeration. Is this 'literature'? Is this irony, or what else? Let me say I believe this couldn't join a 
serious and genuine paper about a topic like this, or, if you really like this special kind of approaching it, once more (as in the 
above described order, in my opinion), the same model description gets previously needed for. 
Your approach isn't absurd or schizophrenic, but something else is this-way: economics itself; economic theories, each one 
abetaociated to its own model. I wrote about this. Shortly, economics as a science mibetaes its own measuring units, laboratories 
and experiment. Economics isn't like physics, biology or medicine. These last are different, so they discover. Economics, as 
it is, has no discoveries, by definition (just some findings, as limited)- and let me here remember a recent reaction of the 
Quinn of UK, why so many economic experts couldn't foresee this big crisis? What does economics actually do, by 
definition? In my view, it doesn't do, but fights for its own survival. 

Economics cumulates theories and models, since the modeling approach for reality is all that remains to it when there is no 
tool to use for economics as for exact and natural sciences. Moreover, there is 'hard life' for models. (1) They face reality 
which is complex and would need complex approaching everywhere; (2) they need simplicity in exprebetaion for the sake of 
good understanding and transparency; (3) they are forced to fight one another since plurality is another rule of such an 
environment. There might be also (4) specific difficulties, as in the CAPM case for data collecting and the other causes you 
here already find. 

Let me here add another memory of mine about the famous Roland Barthes, philosopher and literary theorist of the 70ies. 
He was once asked about how the fiction literature would evolve and his shocking answer was: 'literature goes onto its 
disappearance...' That was a shock for me, at that time, when I was young and found of fiction literature, but now I see that 
fact differently since I realize that economics - that I teach in clabeta - would be also able to disappear one day when its 
theories and models would get obsolete one by one. They don't do, but approaching reality as it is, they fight one another, 
but reality itself can change. There are enough cases of theories unable to cover the whole reality area, as much as just 
answer me where are now the Marxian theory of value or the old Gresham's law (the bad currency chases the good one) ? It 
might be true that newly changed reality would always be able to create new economic procebetaes and rules of the game, but 
nobody could guarantee that economics would ever be able to run after them. As in exchange, phenomena and procebetaes 
that just obsebeta nowadays might vanish themselves, and theories and models will go after. 

V. But now, Pablo, let me get funny myself. You say 'on another planet'... or so. Let me just think what I've never thought so 
far (and now I'm doing this thanks' to you): what if market itself would quickly give up all its unknowns to everyone and get 
transparent on all its dimensions? What if market risk wouldn't exist? What if the book value of any company and of all 
inventories would equal their market values and these would never change? What if the exchange rates would stay fixed, as 
by consequence, and so the currency risk would vanish as well? What if things would occur as in the Karl Marx' view that the 
French profebetaor Jean Pierre Patat has once remarked as 'l'erreur de Marx': 'a merchandise entering a firm's courtyard 
should not change value, unlebeta it is procebetaed there'. But, would these get really valid on another planet?... maybe not 
really. ... 

The European Electricity Regulatory Commibetaion quote hit home. I am reminded of Karl Borch (1974) abetaebetament of MPT: 
\"...I shall continue to use mean-variance analysis in teaching, but I shall warn students that such analysis must not be taken 
seriously and applied in practice\" (p. 430). I admire your patience in putting together such a rebuttal of such nonsense. But 
why stop at CAPM? No model in Financial Economics, despite their widespread use, is in any way reliable. 

I am not a big fan of the CAPM largely because how can one variable predict something as tricky as future prices but in its 
defense there are a number of plubetaes 
  1 it's the basis for the index fund market 
  2 the one variable beta has become a standard way to measure if a given stock is more or lebeta variable than the overall 
     market and how it might move as the market moves 
  3 academic finance people like models with very few variables so this is one of them adding small cap and price to book as 
    Barr Rosenberg suggested in 1967 and Fama French did in 1992 is one such example and it uses CAPM as its basis To me 
    factor models with fundamental or anomalous factors represent reality and predict better. 

I fully agree with your sentiments and you articulated basically what I teach the students every year. I have been in trouble a 
number of times because students accuse me of contradicting the text book. Now at least I have everything together in one 
place. I feel especially that the discount rate (hurdle rate) is investor specific and has nothing to do with the company's 
WACC, nor the company/market rates. I am an investor, so maybe that is why I know to use common sense and ignore the 
MRP, beta, CAPM etc. 
How can you go to the market (technical analysis) to get the discount rate to do fundamental analysis? As soon as you do 
this, you choose a cost of equity that will get you back to the market price, not the fundamental value. In this case people use 
the cost of equity that gives the market price, modify this by the cost of debt and then calculate the value. If you abetaume the 
market is efficient - why bother, the Price = Value, so you do not need to do any calculations to find the value. 

I tend to use the Gordon model (DDM) to do valuations, but I do not add a risk premium to the required rate of return, instead 
I use a growth rate that is one standard deviation below the calculated historical growth rate (Off course using geometric 
means and std dev.). I found that this gives me a reasonable (conservative) estimate of the growth rate to be realized. 
I abetaume that if you value a project using FCF, then the WACC could be of value as the company is the investor - here I 
would use the marginal cost of equity, not the WACC. For the cost of equity I use a common sense approach and not the 
market. What would it cost if we wanted to sell additional shares (or depending on approved debt facilities the marginal 
interest) to fund the project? Stock brokers and project managers do not like my method as I get discount rates (hurdle rates) 
that are too high. They want to convince investors that a stock trades below intrinsic value to earn commibetaion when they 
buy, or convince companies to undertake projects that are actually not profitable. 
  1) Statistical analysis, by design, is not suitable for non-stationary procebetaes, because depending on the time period chosen, 
     anything may happen in a statistical analysis for a non-stationary procebeta. Financial time-series are inherently non-stationary 
     (traders come and go and different traders use different trading strategies), so it is a big puzzle for me why do so many very 
     smart people do statistical analyses of financial data? For example, what does the \"Historical\" mean in \"Historical Equity 
     Premium\"? Does it mean last year? Last three years? Last month? Last week? Or last hour? (Which makes sense in the 
     current algorithmic trading environment.) Depending on the time point and length, we could validate or invalidate almost any 
     argument (so that many papers can be published such as those mentioned in your paper; is this the answer to my puzzle?). 
 2) The engineering approach to non-stationary procebetaes is to use \"adaptive systems\" which adjust the model parameters 
    on-line, in real-time, as soon as new data become available. I agree \"it takes a better theory to kill an existing theory\", so 
    I think a better way for me is to develop a better theory, rather than criticizing an existing theory (such as what I will do next)). 
 3) I think the most harmful element in modern finance is the prevalence of the concept of equilibrium. For evolving, ever-
    changing systems such as financial systems, there is no such thing of a (stable) equilibrium (except Keynes' equilibrium: 
    \"Eventually we all die.\") CAPM is based on equilibrium; I think the origin of the problems abetaociated with CAPM as discubetaed 
    in your paper is the abetaumption of (stable) equilibriums which simply do not exist for the real systems (trading among 
     humans) that generate the stock price data. 
 4) I think the \"common sense beta\" is a useful framework to provide initial conditions (a priori knowledge) for \"adaptive 
    systems\" which I think is the way to go if we really want to track the stock prices and get something useful out of them. 
  5) In short, time (and timing) should be the single most important (and inherent) element in all financial modeling and 
     analysis and should not be \"averaged out\". Statistical analysis and equilibrium intentionally kick out this most fundamental 
     element, and consequently give misleading or irrelevant results when applied to real data. 
     I agree with your opinion on CAPM. Predictability is the main ibetaue. The underlying ingredients of the formula are mere 
     estimates and may vary significantly from actual position. Further they are very hard to quantify in real world. 

I made a research concerning the transaction currency risk of a global group and - having the data - I had the idea to link it to 
the home country of the shareholders as, for example, an investor from USA in the shares of an European share does not 
have an USD currency risk. I script the idea after feedback from others, because one US investor can hedge the risk and the 
other does not. And I do not know what are the currency strategies of the investors. Therefore not considering the link to the 
shareholders is for me based on the same reason I understand your thoughts about the CAPM. 

Yes, CAPM is a very absurd model. Sooner, it is openly established through journals and text books, better for the financial 
community world over (The current \"below-the-line understanding\" acrobeta the community that it is invalid and uselebeta could 
only lead to \"cultural problems\" due to lack of profebetaionalism that could start at the B-School level itself). 

I started my investment career in 1976 at the advent of application of CAPM in the investment procebeta. I joined MFS in the 
Operations Research department with the mandate to help evaluate and introduce quantitative tools to be used by portfolio 
managers and analysts to improve their investment procebeta. I don't view CAPM as absurd; it is a simplistic model that has 
validity in the starting procebeta. In the 1970's and 80's many papers emerged to find systematic returns for small cap or low 
P/E etc. People like Barr Rosenberg built systems to calculate predicted Beta's based on fundamental ratios of each 
company. These ibetaues on the shortcomings of CAPM are by no means new. 

In my view, models are tools in the investment procebeta. These models range in complexity. The more complex, the more 
cumbersome they are to use, but the more accurate the predictions. The more complex, the more input estimates are 
required; the simplistic models require lebeta input. I believe that the CAPM model is simplistic first order model with 
explanatory powers much higher for portfolios than individual securities. Most disappointment with Beta and CAPM is 
abetaociated with too much reliance on the predictive power. 
I appreciate your paper since it takes me back to discubetaions I had with investment profebetaionals 30 years ago. 


It's a beautiful theory, but doesn't fit well. What is slightly absurd is that it has such staying power on B-School profebetaors and 
textbook. I think the reason for that is that the alternatives like the Arbitrage Pricing Model are much lebeta beautiful. You don't 
see many ugly politicians, and the same holds for theories, for better or worse. 


*First of all, I support what you are talking about in ebetaence that if we all have a mutual consent about a concept, does not 
mean to turn it right. This what I always refer \"we have to believe it because scientist say\" 
*calculating returns, investing, financing have even existed before the merge of finance in 1950s, 1960s. 
*I can also refer to reflexivity and human fallibility because of \"wrong stylized facts\" in which we react and build a \"theory\" 
based on wrong \"not even realistic\" abetaumption, at the end an abetaumption in natural science is not as an abetaumption in 
social science. (We forgot the difference between natural and social science)...you can refer to George Soros article on 
human fallibility. 
*Additionally, beta has no value or not indication if the whole market is going wrong (it's more to do the market rather than 
beta) because no solid benchmark for beta. 
*It's a totally subjective measure that serves the untended purpose. 
*Rational choice and risk aversion abetaumptions are also important. 
*I think beta work in stable markets with no long and medium shocks. And to work in other kinds of markets, there should 
introduce a significant margin of error that distracts the value of return and risk premium. And the value of the error is high 
because beta is small is a magnitude. Finally, according to me: CAPM has something logic to tell (but just to tell until now) 
until we modify the way to calculate beta. 


I am constantly \"fighting the CAPM\". Your paper makes a lot of sense, and is a good reflection of what I do (and promote) in 
practice. The basic logic of the model can help to explain the relation between risk and expected return. But I usually prefer 
clear \"guebetatimates\" of MRP and Beta that can reflect better future estimates (versus historical data) and are more stable. In 
models, I tend to keep a fixed MRP (say 4% + Country Premium that is also fixed and \"guebetatimated\"). For Beta, I use a 
simpler, but very similar, system than the MASCOFLAPEC you suggest. I find it a good balance between a realistic number 
and a needed stability. 
Also, the \"maths\" from the formulae usually gives a false sense of exactitude. An educated guebetatimate does not. By 
simplifying the use of this model (and eliminating the \"math\"), analysts can focus more on estimating future cash flows. The 
link between the evolution of estimated values and projected cash flows is more direct and leads, in my experience, to better 
discubetaions about the potential investments. 


I have some personal doubts regarding the coincidence between the historical beta and the beta taken into account in the 
calculation of expected return. In my view, the beta considered in CAPM should be a measurement of risk abetaociated to the 
abetaet. Only for a matter of convenience (or perhaps, lazinebeta, or for trying to construct an objective = artificial measure) 
historical beta should be considered as a proxy for the expected beta. In other words, I have really doubts that is correct to 
consider a past volatility (basically, something that exprebeta a variability of results recorded in the past) as a 'perfect' measure 
for the future risk. 


I am irritated and sometimes frustrated by the stubbornnebeta with which so many academicians (and practitioners as well!) 
cling to so many ABSURD (as you name them) approaches and theories in economics and finance, like CAPM or market 
efficiency!!! What is equally frustrating, some of these people (who you cite in your recent paper) even admit outright that 
they are aware of how unreliable and misleading (and, in my opinion, harmful) those tools are, but they still propagate them 
on the ground that they 'have not seen the better theory yet' (Koller and Murrin, 2000). Is it just stupid?!! I have to sincerely 
admit that I really regret that so few finance profebetaors are as honest and pragmatic as you. The economics and finance 
education all around the world would benefit a lot if there are more academicians like you (in place of those blind supporters 
of so many harmful theories). 


Even if anywhere in the future there is a consensus about these factors, the reliable estimation of Beta will still be unfeasible! 
This is because stock price changes are influenced by so many factors (and not only by the changes in the broad market) 
that the reliable econometric estimation of the relationship between stock prices of individual companies and markets as a 
whole is not pobetaible. 
We know that many macroeconomic variables (e.g. inflation, GDP growth, exchange rates) as well as industry-specific and 
company-specific variables (e.g. firm's indebtednebeta, profitability, changes of legal environment, competitive prebetaures) 
influence the variability of stock prices of individual companies. For any company, the full list of factors which impact the 
relative variability of its stock price would be very long. And in practice it is next-to-impobetaible to prepare such an exhaustive 
list for any company. Furthermore, these Beta-drivers are time-varying and they differ between industries and companies. 
In such circumstances, any econometric estimates of Betas must be derived from so-called incomplete regrebetaions, i.e. 
regrebetaions where not all of the drivers of the dependent variable are included in the set of explanatory variables. In such 
cases the obtained slope coefficients (including Betas) are almost always heavily biased, even if only one out of dozens of 
explanatory variables is omitted in the model. 

This problem is illustrated by the short hypothetical example which You will find in the Appendix to this email. This is the 
extract from the textbook entitled 'Applied Regrebetaion Analysis for Businebeta. Tools, Traps and Applications'. Our intention is 
to emphasize pitfalls and abuses of econometrics (rather than 'praise' for econometrics), which are too often (in our opinion) 
neglected by other textbooks. Our motivation stems from our businebeta consulting practice, where we (as non-
econometricians) too often encounter the misleading and harmful applications of the 'elegant' analytical tools. Beta 
coefficients (and the whole CAPM) are among those areas, where such abuses of quantitative tools are most common. 
the enclosed simple hypothetical case-study illustrates the scenario, in which the dependent variable is deterministically 
driven by its eight explanatory variables. However, even if we omit only one out of these eight drivers (i.e. we regrebeta the 
dependent variable against seven out of its eight drivers), we may end up with heavily biased regrebetaion parameters. And, as 
we know, any Beta estimates are derived from similarly incomplete (and thus flawed) models, because capturing all the 
causes of stock price changes in a single regrebetaion is not pobetaible. 

Though I have often taught the CAPM, I do so in conjunction with a more extensive course on decisions under uncertainty, 
which also traces the development of general equilibrium theory under uncertainty, from the Arrow-Debreu model to the 
Radner model to the theory of allocation under incomplete markets (see the last few chapters of my micro text with Hugh 
Gravelle for the basic approach). I then present the CAPM model as not only being based on very special abetaumptions on 
preferences and/or risk distributions, but also as being a complete markets model - the space of (mu,sigma) pairs is spanned 
by the set of market pobetaibilities and so allocation decisions are first best Pareto efficient. One important implication of that is 
that if it were really true there would be no need for insurance markets to exist because abetaet portfolios provide a full set of 
insurance pobetaibilities. Yet when I talk to finance economists I meet with incomprehension, the idea that, as you point out, a 
market beta does not exist in reality despite claims that it has been measured is just dismibetaed with a shrug. I think in general 
that the importance of incomplete markets for risk exchange, both positive and normative, is entirely under-appreciated in 
both Finance and Economics. 

It is not necebetaarily true that if everybody has the same expectations then markets are small. What determines different 
actions is not only heterogeneity of expectations, but also the different values individuals abetaign to behavioral parameters 

(e.g. risk aversion). You say that it is absurd to think that expectations can be the same for all investors. While this is 
probably true, I am sure that you would appreciate that, in the absence of such a simplifying abetaumption, no usable 
economic model could be built. Indeed, expectations are crucial not only for CAPM, but for virtually all economic actions 
(investments, consumption, the Phillips curve, uncovered interest parity, etc.) 
I think that qualifying the CAPM of absurd is a bit too strong. It makes sense for quantitative analysts who do not deep dive 
in the fundamentals of company. It also makes sense if you follow the market sentiment, which sometimes behaves in herd. 
But the CAPM certainly has weaknebetaes. I strongly believe that the businebeta reasoning behind all the abetaumptions is the key 
for a high quality model. Running a regrebetaion on a few data point would not tell me much about the fundamental value of a 
company. Plus, depending on whether you place yourself from the target or the acquirer point of you, you will use a different 
WACC to value the same company. So, it all depends of what you are trying to achieve. 

Let me exprebeta my joy from reading such a heterodox opinion. Fortunately, you showed enough courage to write about 
some weaknebetaes of the CAPM model. I do agree with your position: we still know very little about abetaet pricing. At best, we 
can measure historical prices, but about forecasting their future I suspect we will never be able to achieve. 

In my clabetaes I explain that CAPM is a MODEL but not a true description of the economic phenomenon determining abetaet 
prices. A model is only a simplification of the reality which we do not know in detail. But here I usually fail in conveying the 
following mebetaage to my students: a formula as the one for the CAPM only is important to guide our more or lebeta subjective 
estimation of the applicable discount rate for shares. In spite of my insistence, students tend to keep reading the formula as 
an accurate method of computation. Even if I explain that I will never hire an economist simply to plug in numbers in a 
formula, they still read the formula as the last explanation of abetaet prices. 

An anecdotic example I sometimes use in clabeta to refer to the different way the surrounding market influences a company is 
to say that a funeral company may benefit from an economic crisis in opposition to the most common negative influence 
upon other firms. It may the last to fail in case of catastrophic events! 

My concern is your insistence on \"common sense\" and on \"reasonable individuals\". It gave me the imprebetaion that that there 
is some alternative ways to estimate the best discount way. I suspect I understood your intentions with those two ideas, but I 
would prefer to focus instead on the concept of approximation and on the inevitability to use subjective but educated guebetaes 
in such estimates. 

I am in complete agreement with you: the CAPM does not reflect reality. I believe, however, that most valuation theory (i.e., 
not just CAPM) does not reflect reality. It might be helpful to provide my background in order for you to better understand my 
perspective. I started in the businebeta valuation industry fresh out of graduate school in 1983. I started with a company where 
I learned the fundamentals of businebeta valuation. After a couple of years I was recruited by Arthur Andersen where I was 
promoted to manager. After a couple of years in the Valuation Practice at AA, the Firm started an investment banking 
practice which we called the Corporate Finance Consulting Group. I was recruited and spent the next several years working 
with clients mostly undertaking management buyouts. We worked with several management groups helping them buy their 
companies. We developed prices, optimal capital structures, arranged financing, and negotiated with the sellers, in order to 
complete the MBOs. There I learned that businebeta valuation, as performed by \"Appraisal Firms\", really had nothing to do with 
true market value. A couple of quick examples, my bobeta asked for the cash flow model we used in the Valuation Group and 
he immediately discarded it. He said that no buyer of a businebeta, or financing source, would analyze a company and its 
value using this type of model. We built a new model, based on the real world, from scratch. When my ASA dues came up at 
some point and I asked him to approve the expense he refused, saying that he felt the organization meant nothing to the 
profebetaionals who bought and financed companies. So we became very good at structuring deals, developing optimal capital 
structures, and, on behalf of our clients, getting deals done, and I became an expert in true \"Businebeta Valuation\". 
The work was extremely addictive, and took a physical toll on those of us doing the transactions. So when my son was born I 
walked away and found myself doing businebeta valuations again for a valuation firm (not an m&a firm). What I have found in 
coming back is an industry that is driven by accounting and tax regulations. But valuation is a financial discipline, not an 
accounting or tax specialty. Accountants and tax specialists want generic rules, at the expense of recognizing reality. So do 
academicians. I understand that rules must be developed and applied and I follow the rules, it's what provides me with a 
paycheck now. But, based on my M&A experience, do I think that what we develop in a financial reporting or tax project 
represents value? No. To that point, I spend much of my time educating my CFO clients and my private equity clients about 
the difference between true market value and the values we develop for accounting and tax purposes. They, frankly, see little 
value in what we do other than providing them with the input they need to prepare their financials or file their tax returns. 
In the case of equity returns, the subject of your paper, no company or PE investor calculates equity return using CAPM or, 
frankly, the approach introduced in the latter part of your paper. The market drives equity returns. These investors have to 
attract capital (a limited resource with many competitors) and deploy it in a fashion that provides a competitive return. If they 
can't do that, they go out of businebeta. And these returns have nothing to do with CAPM - in fact if you mention it to these 
folks they'll laugh in your face. Ultimately, one question: Does valuation, as performed today, help an investor in a company 
understand the true value of the company and its abetaets that he is invested in/looking to invest in? I would argue no. 

I thank you for your research output over the last decade. I am an accounting academic with an interest in strategic 
management accounting and public sector performance measurement and evaluation and, naturally, questions of what cost 
of capital to use in evaluating proposed investment decisions arise. Your work reflects on the rather problematic nature of 
how an important variable can impact on decisions to implement or reject strategically important projects. 
In the paper CAPM: an absurd model, you argue the case very well. The ibetaue around what is a market consensus about 
returns generated from equity investments is present in all other markets characterized by willing buyers and sellers and 
trading at arms-length. For example, where you have a willing buyer and seller (i.e., other influences, such as the urgent 
need to liquidate an investment, are not present), then the agreed price is a compromise of the values the exchange gives 
each party (i.e., the seller realizes a value greater than the price obtained, whilst the buyer also obtains a value greater than 
the price. If this was not to hold, absent other reasons, the exchange would not occur. Given the dynamic states of equity 
markets, the observed bundle of \"market\" premia is no more than a transitory statistic. 

Also the various models proposed for calculating a qualitative beta have a couple of ibetaues: 1. how is the weighting 
determined acrobeta the parameters are determined? Might the management parameter be more of lebeta important when 
considered in the context of other parameters such as firm size and maturity (i.e., for an emerging firm with lebeta experienced 
management, the management parameter might require a higher weighting than 10%). 2. Also the risk scale abetaumes an 
interval (or pobetaibly ratio) relationship acrobeta each parameter. I am not sure if any parameter with a very high risk (of 5) is 
always going to be 5 times the value of low risk (of 1). In other words, the interval (or ratio) between a high risk and low risk 
rating for all parameters is not always going to be 5. For example, the management parameter might have a risk spread of 
say 2 to 5 whereas strategy might be 1 to 7. 
Again can I exprebeta my great appreciation to you with the work that you have been undertaking and sharing with your 
colleagues in the global academic and profebetaional communities. 
I just received a call from a member of a Board of Directors. He recounted a Finance Committee meeting he attended last 
night where the committee discubetaed a recommendation to change the valuation of the organization's facilities from historic 
cost to a present value of future earnings. When asked as to the cost of capital to be used, he replied that it was to be 15% 
as the committee felt that it had a social contract with the community. How this enters into the determination of the cost of 
capital to use somewhat escapes me. 

I agree that the standard CAPM method has a multitude of drawbacks. I have one suggestion in the calculation of a 
\"common sense\" beta. I did not see a row for diversification or portfolio insurance. I work in the gold mining industry. Gold 
stocks at various times do not follow the general market and tend to be negatively correlated. Many investors who run 
portfolios buy gold stocks for diversification or insurance against falls in the general market. Although gold mining is 
inherently risky, the benefits of insurance should mitigate some of that risk. In fact I don't know whether you know but gold 
analysts typically use a discount rate of 5% (too low in my opinion) based on the benefits of portfolio asymmetry. Therefore I 
would suggest a row which addrebetaes portfolio insurance or portfolio diversification and given a suitable weight. I think your 
approach is a good one but a recognition of portfolio approach would make it even better. 

I personally never trusted the CAPM: I am very critical of financial markets. Rather than a theory, I prefer to have a 
mathematical relation that works, maybe this is the way forward. Instead of applying a theory to the real world, let's apply the 
real world to a theory. 

Problems with CAPM. 1. There is confusion about the nature of beta. The conceptual view of the indicator is that it is a measure 
of relative volatility of a specific stock with respect to the larger market that it is a part of. Volatility is described as the rate of 
change in either direction (upwards and downwards).However another view supported by the computational approach it 
resorts to, is that beta represents the ratio of the expected future returns of a specific stock to the expected future returns of the 
larger market and its indicators(S&P index for instance in the U.S.), both of these computed as incremental returns over 
those of risk free securities such as Government Bonds. To my mind the former is the more correct view. Yet if one explores 
volatility in greater depth, it would be more appropriate to project future prices and returns on shareholder investment for a 
specific stock , by confining oneself to the historic changes in the prices of that stock while incorporating expected changes 
in the industry environment as well as the financial performance of the company itself. 

   2. It is difficult to obtain a reliable figure of future returns particularly as we go further into the future. 
   3. Since the greatest influencers of Stock/Share prices are speculative as opposed to objectively reported and abetaed 
      performance based ones, attempts to calculate both reasonable and expected prices are bound to be flawed. 
   4. Taking a larger universal database of shares as the basis for calculating expected rates of return would defocus from 
      specific industry related businebeta and financial environments which would be more likely to influence a specific company's 
      share price. 
   5. Since Businebeta Management is a young and developing Science, many of the theories and frameworks are incomplete 
      and not fully representative of the various phenomena studied and variables attempted for prediction. Unfortunately few 
      academicians and businebeta practitioners realize let alone accept this reality. Attempts to forecast/estimate are to this extent 
      likely to be unsuccebetaful, particularly where attempts at exactitude are made. The CAPM is one such instance. Irrespective 
of the Nobel prize awarded for work on the subject, it reflects this painful reality. 
6. To my mind, it would be better to analyze the historic price performance of a specific stock, make educated \"guebetaes\" (that 
given the nature of businebeta management as a young science would be realistic and appropriate), and make attempts to 
factor in known and likely changes in the industry environment as a result of incorporation of new technologies and intra 
industry competition. 
CAPM was developed out of Portfolio Theory, which was ebetaentially a benchmarking model with its \"efficient frontier\". CAPM 
introduced a distinction between idiosyncratic which can in principle be diversified away and systematic risk which can't. It's 
surely the use of CAPM to \"price\" or value individual abetaets, outside of a portfolio context, which might be called \"absurd\", 
rather than the CAPM itself. Maybe \"an abused model\" would be more appropriate? The question is why people (including 
the apparently knowledgeable) do it? For lack of anything better? 

When I went through my training as a businebeta valuator, I was ridiculed in my clabeta for criticizing the CAPM model. But as a 
private equity manager and businebeta intermediary that perform numerous transactions, there was no way I could validate this 
model to any of my partners, clients, etc., due to some of the unrealistic abetaumptions. Thank you for taking on this widely 
accepted--although extremely flawed model (in my opinion). It reminds me of a quote I have in my office: \"Just because we 
have always done it this way doesn't mean that it isn't incredibly stupid\". 

I am totally agreeing with your views. The abetaumptions and practicality is out of the society and the world. This CAPM 
approach is only good for us because it gives us an idea to think and to predict about the impact of risk factor. We all are 
only worried about future because future is uncertain. Uncertainty is the cause of risk. So depending on individual level of 
capacity of investors (i.e. how much? Up to what period? Up to what extent?) we can predict or forecast or estimate or catch 
the quantum of risk up to some extent which will help us minimizing the risk or lobeta of investors and maximizing the gain or 
achieving the institutional target. But it is true: calculating Beta Coefficient is not feasible. 

While investing and gambling are often said to be different, there are many similarities. With gambling the odds (the 
probability of succebeta) are well known for games such as craps and roulette. The probability of succebeta of an investment is 
determined through various valuation models. It strikes me that the various models for valuing usually require judgement by 
the individual using the model. Where human element is introduced to any model, it is susceptible to bias. Any bias leads to 
corruption of the data and reliance compromised. Intuitively where the expected return equals or exceeds the investors 
required return, an investment should be made. 

the paper was very well written. The depth of the research was good and it clearly showed why the CAPM is a deficient 
model. I do not really have so much in terms of criticisms or arguments to the arguments raised in the paper. However, I 
have some comments which I feel may be important. Firstly, I think that after writing this paper, you should go on to propose 
a much better alternative to the CAPM which would correct most if not all of the deficiencies of the CAPM. The paper does a 
good job showing the weaknebetaes of the CAPM but that is only halfway through the journey. People need alternatives. If 
there is a way the CAPM as it is can be modified or corrected to make it a better model, that would also be a good areato 
research on. Many Economic models abetaume that consumers are rational and they abetaume that they make similar choices. 
While these are unrealistic, I believe they are made to simplify reality and make modelling pobetaible. If we discredit the CAPM 
for making some of such abetaumptions, we may as well discredit almost every other economic model. I hope my comments at 
least gave you something to think about. Kudos for the great work done. 

A very interesting paper. One source you might have quoted: Jim Crotty, 'The Realism of Abetaumptions Does Matter: Why 
Keynes-Minsky Theory Must Replace Efficient Market Theory as the Guide to Financial Regulation Policy', in M. Wolfson and 

G. Epstein (eds), THE HANDBOOK OF THE POLITICAL ECONOMY OF FINANCIAL CRISES (OUP 2013), pp. 133-58. He 
strebetaes methodology, but his criticisms are very similar to your. 
In my opinion the CAPM provides reasonable approximations a majority of the time. But I would agree with you that a 
significant minority of the time it provides very flawed answers. I believe that applying an equity risk premium and any other 
suitable premium for illiquidity, control and size will provide a more satisfying cost of equity almost all of the time. 

I would weaken the title. I do not think the CAPM itself is an absurd model. I think it is a conclusive model in its structure and 
results, meaning that it tells you what would happen, if the abetaumptions where true. From my point of view it is merely absurd 
to use a model like this in reality, since this is one thing I learned, a model is always restricted in its abetaumptions, and from 
my point of view, the abetaumptions of the CAPM are so far from reality, that it shouldn't be used in practice. I think the model 
should only be used on universities, since it is, form my point of view, able to explain to student, how an idealised financial 
market would work. The lecture should go on and show what happens, if the abetaumptions are weakened. Also the evidence 
against the abetaumptions should be discubetaed. In economics, we also discubetaed Keynes and Friedman's models, before 
moving on. Since these are the basics. I don't think you can teach \"common sense\" without using an idealized / abstract 
(even absurd) model at first. 

A good point in your paper is, as I see it, the praise of common sense in the valuation procebeta. In the last ten years I worked 
at different jobs in consulting and investment banking, and this is one thing I learned: after you calculated something, take a 
step back and look, if the result is making sense, before using it for the next steps. The problem I see here is, that you make 
yourself contestable, if you use common sense instead of a clearly stated procedure. I think this is the biggest incentive for 
using the CAPM, everybody seems to be using it, so just run with the herd. 

I find it very interesting but hard to read because it is very choppy in its presentation. It needs to be written in a paragraph 
form and not in a bullet form as though you were presenting it to a course. I would suggest putting it in APA format. The 
material is great and I agree with the premise. 

I enjoyed your paper. As a practitioner I fight constantly with the use or the abuse of the concept of Beta in risk management 
application. Next time a have a discubetaion with my college I just show them your paper (I already forward it to a couple of 
them...). I would have appreciated to find same more reference in your paper of the use of Beta in risk management field. I 
am of the idea that the use of Beta in portfolio theory is misleading, but it is even worse in Risk management, where we deal 
with the tail of the returns distribution, when we neglect all the problems you underlined in paragraph 8 of your paper. I 
borrowed from Paul Willmot the idea of Crash Coefficient in order to overcome at the Beta problem you strebetaed. 

I agree with your findings and conclusions. In addition, you might want to look deeper into the factors related to geopolitical 
macro-risks and calculating CAPM for alternative abetaets that tend to be very popular these days. I'd also spend an extra time 
thinking about the expected (and/or required) returns and using appropriate betas taking a short-term versus medium-term 
and long-term timeframes... 

I share your conclusions and opinions about the CAPM and market risk premia. A major consequence of using the CAPM for 
market actors is that small differences in rate estimates lead to huge differences in company valuations. The determination of 
expected cash flows finally appears to be of smaller importance. As you mention it, people use CAPM by simplification. As a 
teacher, I also used it, even if I wasn't persuaded of its efficiency. It was even worse with the concept of risk premium. I 
particularly appreciate section 9. 

Your proposition in section 12 is very interesting and may find echo among market practitioners. Neverthelebeta, I understand 
that valuating each factor's weight and the risk abetaociated may be a difficult exercise, much more than just using our well 
known CAPM! 

What is specific of the CAPM is NOT \"more risk, more return\", but \"more beta, more expected return\". And we know of the 
problems measuring \"the beta\". 

Use of beta: 

a) Inside a company: to evaluate investment projects,.. 
b) Portfolio management 
c) Company valuation 
B-S, CAPM and Factors models are not comparables. B-S has arbitrage behind, but CAPM and Factors models do not 

A common request: 'Give me a rule of thumb I can follow without thinking' 
Learning means being able to keep perceiving reality as it truly is: complex - and not trying to fit 
every new experience into a closed and pre-conceived notion or overall scheme. Yepes Stork, Ricardo. 
Profebetaor of Philosophy. University of Navarra Experience doesn't consist of the number of things 
one has seen, but of the number of things on which one has reflected. Pereda, Jose Maria. Writer. 
Santander. Spain Common sense (Merriam-Webster): \"sound and prudent judgment based on a simple 
perception of the situation or facts.\" 

/////////////////////////////////
"

.C10EXPLAIN19<-"Youtubes 
/////////////////////////////////
 Calculating stock beta using Excel (4m28s)
       https://www.youtube.com/watch?v=zlClflcSrM8
 
 What is Beta? - MoneyWeek Investment Tutorials (5m29s)
       https://www.youtube.com/watch?v=etlv7qTQUSY

 Beta Calculation on Excel (9m48s)
       https://www.youtube.com/watch?v=7LiK-qbmPsw

 How to Calculate Beta with Excel, Calculation of Beta (18m43s)
       https://www.youtube.com/watch?v=LRyFn_T94IU

/////////////////////////////////
"

.C10EXPLAIN20<-"references, links and YouTube 
/////////////////////////////////
  Damodaran, Aswath, Estimating beta
       http://people.stern.nyu.edu/adamodar/pdfiles/eqnotes/discrate2.pdf

  Damodaran, Aswath, Estimating Risk Parameters   
       http://pages.stern.nyu.edu/~adamodar/pdfiles/papers/beta.pdf

  Dimson, E., (1979). Risk measurement when shares are subject to infrequent 
     trading. Journal of Financial Economics 7,197-226.
     http://www.sciencedirect.com/science/article/pii/0304405X79900138

  Fernandez,Pablo, 2014,2015,CAPM: An Absurd Model,
       https://papers.betarn.com/sol3/papers.cfm?abstract_id=2505597
       http://www.appraisers.org/docs/default-source/event_doc/2016_bv_presentation_fernandez1.pdf?sfvrsn=2

  Ide,Michael,2014,'Absurd' Comments About CAPM Masquerading As Research
       http://www.valuewalk.com/2014/12/capm-investing/

  Invetorpedio, The Capital Abetaet Pricing Model: an Overview
       http://www.investopedia.com/articles/06/capm.asp
/////////////////////////////////
"
.chapter11<-function(i){
" i  Chapter 11: Market imperfections 
  -  -------------------------------------
  1  Borrowing vs. lending rates 
  2  Information/opinions
  3  Market depth
  4  Transaction costs/taxes 
  5  Insider information 
  6  SEC forms 3, 4, and 5
  7  Basis point
  8  Market is perfect?   
  9  Abetaumption #1: No difference in oppinions
 10  Abetaumption #2: Infinitely many investors and firms
 11  Abetaumption #3: No transaction costs 
 12  Abetaumption #4: No taxes 
 13  If the market is not perfect 
 14  Seperation of invesment decisions from financing decisions 
 15  One example  
 16  Important: credit spreads
 17  Market depth
 18  Liquidity 
 19  Youtube
 20  Links

 Example #1:>.c11     # find out the list 
 Example #2:>.c11(1)  # see the first explanation 

";.chapter11_(i)}


.c11<-.chapter11
.n11chapter<-20
.chapter11_<-function(i){
    .printEachQ(11,i,.n11chapter)
}


.C11EXPLAIN1<-"Borrowing and lending rates 
///////////////////////////

 For a perfect market, both borrowing and lending
 
     rates are the same. 

///////////////////////////
"


.C11EXPLAIN2<-"Information/opinions
///////////////////////////

 Information: public information
              private information 

  Opinions: different opinions

///////////////////////////
"

.C11EXPLAIN3<-"Market depth
///////////////////////////

 For a perfect market, the market is very deep. 
  In other words, we have many buers and sellers. 

  No single buyer or seller would influnce the market. 

///////////////////////////
"

.C11EXPLAIN4<-"Transaction costs/income tax breaks 
///////////////////////////
What are Transaction Costs
   Transaction costs are expenses incurred when buying or selling a
   good or service. Transaction costs represent the labor required 
   to bring a good or service to market, giving rise to entire 
   industries dedicated to facilitating exchanges. In a financial
   sense, transaction costs include brokers' commibetaions and spreads,
   which are the differences between the price the dealer paid for a 
   security and the price the buyer pays.

   Chen, James, 2019, Transaction Costs
        https://www.investopedia.com/terms/t/transactioncosts.asp

Income Tax Brackets and Rates
    In 2019, the income limits for all tax brackets and all filers will be 
    adjusted for inflation and will be as follows (Tables 1). The top 
    marginal income tax rate of 37 percent will hit taxpayers with 
    taxable income of $510,300 and higher for single filers and $612,350
    and higher for married couples filing jointly.

Tax Brackets and Rates, 2019
-----------------------------------------
  Rate	For Unmarried ,    For Married Individuals  For heads of Households
        Individual,        Filing joint return,     ,Taxable Income Over
        Income over                                 Taxable Income over 
  10%   $0                 $0                        $0
  12%   $9,700             $19,400                   $13,850
  22%   $39,475            $78,950                   $52,850
  24%   $84,200            $168,400                  $84,200
  32%   $160,725           $321,450                  $160,700
  35%   $204,100           $408,200                  $204,100
  37%   $510,300           $612,350                  $510,300

   Amir El-Sibaie, Amir, Twitter Logo, 2019, 2019 Tax Brackets
        https://taxfoundation.org/2019-tax-brackets

///////////////////////////
"

.C11EXPLAIN5<-"Insider information 
///////////////////////////
 Insider Information,KENTON, will, 2018
     Insider information is a non-public fact regarding the plans 
     or conditions of a publicly-traded company that could provide
     a financial advantage in a securities market. 

  Insider information is a non-public fact regarding the plans or 
     condition of a publicly-traded company that could provide a 
     financial advantage when used to buy or sell shares of that 
     or another company's securities. Knowing about a company's 
     significant, confidential corporate developments, such as 
     the release of a new product, could provide an unfair advantage
     if the information is not public and only a few people know 
     about the developments. Insider information is typically gained 
     by someone who is working within or close to a listed company.

  Insider trading is illegal when the material information has not been 
     made public and has been traded on. This is because trading on 
     insider information is seen as an unfair manipulation of the 
     free market to give preference to specific parties. It undermines
     general investor confidence in the integrity of the market and can
     dampen economic growth. 

   https://www.investopedia.com/terms/i/insiderinformation.asp
 
///////////////////////////
"


.C11EXPLAIN6<-"SEC forms 3, 4, and 5
///////////////////////////
Forms 3, 4, 5
  Corporate insiders - meaning a company's officers and directors, 
     and any beneficial owners of more than ten percent of a clabeta of 
     the company's equity securities registered under Section 12 of the 
     Securities Exchange Act of 1934 - must file with the SEC a statement
     of ownership regarding those securities. 

 The initial filing is on Form 3. An insider of an ibetauer that is registering 
     equity securities for the first time under Section 12 of the Exchange Act
     must file this Form no later than the effective date of the registration 
     statement. If the ibetauer is already registered under Section 12, the insider 
     must file a Form 3 within ten days of becoming an officer, director, or 
     beneficial owner.

 Changes in ownership are reported on Form 4 and must be reported to the SEC within
     two businebeta days. You can find the limited categories of transactions not 
     subject to the two-day reporting requirement in the new rule.

  Insiders must file a Form 5 to report any transactions that should have been 
     reported earlier on a Form 4 or were eligible for deferred reporting. If 
     a Form must be filed, it is due 45 days after the end of the company's 
     fiscal year.

  For more information on the reporting requirements for officers, directors, 
     and beneficial owners, you can read Section 16 of the Exchange Act. You 
     can download blank PDF versions of Form 3, Form 4, and Form 5 as well as 
     the instructions to these Forms.

    SEC: https://www.sec.gov/fast-answers/answersform345htm.html

///////////////////////////
"

.C11EXPLAIN7<-"Basis point
///////////////////////////
 Since interste rate is quoted as a percentate, 
    it is comfusing to claim that the rate was increased 
    by 1%. 

 Abetaume that the current annual rate is 2%. 
    What does it mean that its value is increased by 1%?

  1)  2% + 1% = 3%            ??
  2)  2% * (1+0.01) =  2.02%  ??
       > 0.02*1.01
         [1] 0.0202

  For this reason, a new concept called basis is introduced. 

  One basis is 100th of one percent, i.e., divided by 100 twice. 
                    50
  Thus, 50 basis = -------    = 0.05%. 
                    100*100

///////////////////////////
"

.C11EXPLAIN8<-"Market is perfect?   
///////////////////////////
 page 243

 For many financial securities -- for example, publicly traded--
     the abetaumption that the market is perfect is reasonable. 

 For other financial securities and many nonfinancial goods, 
      this abetaumption is lebeta acurate. 

///////////////////////////
"

.C11EXPLAIN9<-"Abetaumption #1: No difference in oppinions
///////////////////////////



///////////////////////////
"

.C11EXPLAIN10<-"Abetaumption #2: Infinitely many investors and firms
///////////////////////////



///////////////////////////
"

.C11EXPLAIN11<-"Abetaumption #3: No transaction costs 
///////////////////////////

What are Transaction Costs
    Transaction costs are expenses incurred when buying or selling a 
    good or service. Transaction costs represent the labor required 
    to bring a good or service to market, giving rise to entire industries
    dedicated to facilitating exchanges. In a financial sense, transaction
    costs include brokers' commibetaions and spreads, which are the differences
    between the price the dealer paid for a security and the price the buyer pays.
      
         https://www.investopedia.com/terms/t/transactioncosts.asp

 Commibetaion
       https://www.investopedia.com/terms/c/commibetaion.asp

///////////////////////////
"

.C11EXPLAIN12<-"Abetaumption #4: No taxes 
///////////////////////////

///////////////////////////
"

.C11EXPLAIN13<-"If the market is not perfect 
///////////////////////////

 If the market is not perfect, the seperation of 
    ownership and value breaks down. Therefore,
    project value is no longer unique. 

 It can depend on who owns the project. 

///////////////////////////
"

.C11EXPLAIN14<-"Seperation of invesment decisions from financing decisions 
///////////////////////////

  A project manager should make an investment decision based on
    the quality of the project, not based n his/her personal 
    wealth or financing options. 

///////////////////////////
"

.C11EXPLAIN15<-"One example 
///////////////////////////

  Today's investment is $1,000. One year later, we have 
        cash inflow of $1,050.

 Case #1: lending and borrowing rates are both 4%. 

          NPV= -1000 + 1050/(1+0.04)  -> 9.615385
          Since NPV>0, we will accept the project. 

 Case #2: Abetaume that ledning rate is 3% while the 
          borrowing rate is 7%. If we borrow $1000, 
          the discount rate will be 7%. 

          NPV= -1000 + 1050/(1+0.07)  -> -18.69159

///////////////////////////
"

.C11EXPLAIN16<-"Important: credit spreads
///////////////////////////

 The fact that credit spreads reflect a default premium -- a 
      difference the promised rate of return and the expected 
      rate of return - is not a market imperfection. 

 The fact that credit spreads reflect differences in opinion 
     between borrower and lender -- a difference about 
     the two abetaebetaed expected rates of returns - 
     is a market imperfection. 

///////////////////////////
"

.C11EXPLAIN17<-"Market depth
///////////////////////////



///////////////////////////
"

.C11EXPLAIN18<-"
///////////////////////////

///////////////////////////
"

.C11EXPLAIN19<-"YouTube
///////////////////////////
 Now This World, 2012, What Is Insider Trading And Why Is It Illegal?
    (v179k,s2m,t3:2)
    https://www.youtube.com/watch?v=2BtawLeS5fM
 
 Hirsch, Paddy, 2014, Insider trading, explained
    (v35k,s14k,t3:35)
    https://www.youtube.com/watch?v=2nEH8zRSyAM

///////////////////////////
"

.C11EXPLAIN20<-"Links
///////////////////////////
 Chen, James, 2019, Transaction Costs
     https://www.investopedia.com/terms/t/transactioncosts.asp

 FRANKENFIELD, Jake, 2019, Commibetaion
      https://www.investopedia.com/terms/c/commibetaion.asp

 Kaplan, Gabriel E.,2019, Transaction cost
      https://www.britannica.com/topic/transaction-cost

 SEC, Forms 3, 4 and 5
      https://www.sec.gov/fast-answers/answersform345htm.html

 Transaction Cost Calculation, 2019, 
       https://investmentdataservices.info/en/products/reporting/transaction-cost-calculation/

///////////////////////////
"


.chapter12<-function(i){
" i  Chapter 12: Perfect/Efficient Market, Behavioral finance
  -  -------------------------------------
  1  Market efficiency 
  2  Price and information 
  3  Market efficiency vs. mean-variance efficiency 
  4  Market efficiency: short-term vs. long-term 
  5  Market perfect vs. market efficiency 
  6  Important: market efficiency vs. mraket force 
  7  Bid-ask spread 
  8  Large transaction costs 
  9  Technical analysis 
 10  3 types of Market Efficiency Hypothsis (MEH)
 11  Random walk 
 12  N-day statistics 
 13  Important: quality of inference vs. time
 14  True arbitrage and risk(y) arbitrage 
 15  Event study 
 16  When mangers have super information 
 17  If the financial market is (close to) perfect 
 18  Contrarian strategy 
 19  Youtubes
 20  Links

 Example #1:>.c12     # find out the list 
 Example #2:>.c12(1)  # see the first explanation 

";.chapter12_(i)}

.c12<-.chapter12

.n12chapter<-20

.chapter12_<-function(i){
    .printEachQ(12,i,.n12chapter)
}

.C12EXPLAIN1<-"Market efficiency 
///////////////////////////

  Market efficiency means the market uses all available 
      information in setting the price 

///////////////////////////
"

.C12EXPLAIN2<-"Price and information 
///////////////////////////
  A price is called efficient if the market has set the 
     price correctly as if it were using all available 
     information. 
 
  It is not necebetaary that any investor has all the information. 
     
///////////////////////////
"

.C12EXPLAIN3<-" Market efficiency vs. mean-variance efficiency 
///////////////////////////

  Market efficiency is a different concept from mean-variance 
      efficiency (the efficient frontier)

///////////////////////////
"

.C12EXPLAIN4<-"Market efficiency: short-term vs. long-term 
///////////////////////////
 Over long horizons (say, 1 year or longer), market efficiency is 
      extremely difficult to disprove. 
 
 Over short time inverslas (say, days), market efficiency 
     is a ver powerful concept. 

///////////////////////////
"

.C12EXPLAIN5<-"Market perfect vs. market efficiency 
///////////////////////////
///////////////////////////
"

.C12EXPLAIN6<-"Important: market efficiency vs. mraket force 
///////////////////////////
 If a market is perfect, market forces shoukld drive it strongly 
      and quicly toward efficiency. 

  If a market is not perfect, self-interested invividual behavor
      should still drive it toward efficiency. But his force is 
      much weaker, and third-party traders may not be able to 
      aid in the procebeta. 

///////////////////////////
"

.C12EXPLAIN7<-"Bid-ask spread 
///////////////////////////

  Bid: price you receive when sell a share

  Ask: price you pay when buy a share
   
   spread = ask price - bid price

          = high price - low price 

///////////////////////////
"

.C12EXPLAIN8<-"Large transaction costs 
///////////////////////////
  For small stocks, 
      1) The bid-ask is often high

      2) The posted bid-ask spread is only guaranteeed for 
         100 shares- if yu want to trde moe shares, the price 
         is linkey to move against you

      3) commibetaions can be high

      4) Shorting small stocks can be ery costly when compared to 
         the ideal of a perfect world in which you have full accebeta
         to the proceeds (e.g., to earn interest)

///////////////////////////
"

.C12EXPLAIN9<-"Technical analysis 
///////////////////////////
  Technical analysis 
       Trading based soly on historical price patterns

///////////////////////////
"

.C12EXPLAIN10<-"Three types of Market Efficiency Hypothesis
///////////////////////////

  Weak form: all information is past prices is reflected in 
             today's stock prices so that techinical analysis
             cannot not beat the market. 
             Put differently, the market is the best technical analyst. 

  Semistrong form:all public information is reflected in today's stock
                prices so that neigher fundamental trading nor technical 
                anslysis can be used to beat tht emarket. 

  Strong form: all information both public and private, is reflected 
               in today's stock prices, so that nothing - 
               not even private insider information - can be used 
               to beat the market. Put differntly, the marke is the 
               best analyst and cannot be beat. 

///////////////////////////
"

.C12EXPLAIN10<-"
///////////////////////////
Weak Form
    The three versions of the efficient market hypothesis are varying degrees of 
    the same basic theory. The weak form suggests that today’s stock prices reflect
    all the data of past prices and that no form of technical analysis can be 
    effectively utilized to aid investors in making trading decisions.

   Advocates for the weak form efficiency theory believe that if the fundamental 
      analysis is used, undervalued and overvalued stocks can be determined, and 
      investors can research companies' financial statements to increase their 
      chances of making higher-than-market-average profits.

Semi-Strong Form
    The semi-strong form efficiency theory follows the belief that because all 
    information that is public is used in the calculation of a stock's current 
    price, investors cannot utilize either technical or fundamental analysis to
    gain higher returns in the market.

  Those who subscribe to this version of the theory believe that only 
    information that is not readily available to the public can help 
    investors boost their returns to a performance level above that of the general market.

Strong Form
   The strong form version of the efficient market hypothesis states that all 
   information \"both the information available to the public and any information
   not publicly known\" is completely accounted for in current stock prices, and 
   there is no type of information that can give an investor an advantage on the market.

Advocates for this degree of the theory suggest that investors cannot make returns 
   on investments that exceed normal market returns, regardlebeta of information 
   retrieved or research conducted.

https://www.investopedia.com/ask/answers/032615/what-are-differences-between-weak-strong-and-semistrong-versions-efficient-market-hypothesis.asp
///////////////////////////
"

.C12EXPLAIN11<-"Random walk 
///////////////////////////
 What Is the Random Walk Theory?
     Random walk theory suggests that changes in stock prices have the
     same distribution and are independent of each other. 

     Therefore, it abetaumes the past movement or trend of a stock price 
     or market cannot be used to predict its future movement. 

     In short, random walk theory proclaims that stocks take a random
     and unpredictable  path that makes all methods of predicting 
     stock prices futile in the long run.    

   https://www.investopedia.com/terms/r/randomwalktheory.asp

///////////////////////////
"

.C12EXPLAIN12<-"N-day statistics 
///////////////////////////
Abetaume that we downlod IBM's daily historical price. 
  Then calcualge returns. By applying Excel var() and stdev()
  fucntion we could calcuatle daily variance and daily std. 

     n-day variance = n *var(daily)

     n-day std      = sqrt(n) * std(daily)

///////////////////////////
"

.C12EXPLAIN13<-"Important: quality of inference vs. time
///////////////////////////
 The quality of our inference about a strategy's performance increases 
     roughly with the square root of time. 

 On an avergae ay, the typical sotkc may easily move up or down by about 20
    to 50 times as sum as it offersin expected rate of return. Theerefor, it 
    takes at leat mny decades, if not centuriebetas, of data to realiably conclude 
    weather a signal-based strategy of picking individual stock is real or illusory., 

///////////////////////////
"

.C12EXPLAIN14<-"True arbitrage and risk(y) arbitrage 
///////////////////////////
 A true arbitrage is a businebeta transaction 

    -- that offers positive net cash inflows in at lest some scenarios

    -- and under no circumstance - either today or in the futures - 
       has a negative net cash fow. This mean that it is risk-free. 

///////////////////////////
"
.C12EXPLAIN15<-"Event-study 
///////////////////////////

  When applying Event-Study to finance, we group similar events 
    together and study their impact on the underlying stocks. 

  type the following comand to see more 
   .explainEventStudy

///////////////////////////
"
.C12EXPLAIN16<-"When mangers have super information 
///////////////////////////
 When managers have super information 

    If the firm's undrevalued, CEOs should abetaume a relative high 
         cost of capital and consider repurchasing the firms own shares. 

    If the firm's overvalued, CEOs should abetaume a relative low 
         cost of capital and consider ibetauing more of the firm's 
         own shares. 

    A good decision rule for managers is to take projects up to the 
         point where the maringla costs and benefis of projects are
         the same as what they could obtain from repurchasing or 
         ibetauing the firms's own shares. 

///////////////////////////
"

.C12EXPLAIN17<-"If the financial market is (close to) perfect 
///////////////////////////
 If the financial market is (close to) perfect 

  1) Earnings report: you cannot fool your investors by how you 
                      report your earnings. 

  2) Capital structure: There must be no value to changing 
                      capital structrue. 

  3) Stock splits:  Stock splits must be irrelevant, too. 

  4) Dividends: You  can not use dividend to fool investors. 

///////////////////////////
"

.C12EXPLAIN18<-"Contrarian strategy 
///////////////////////////

  The opposite of the usuall pattern of hedge funds are strategies that 
      lose money most of tie but then gain a lot in a crisis. 

///////////////////////////
"

.C12EXPLAIN19<-"YouTubes
///////////////////////////
 Duomo Initiative-Trdaing & Investing, 2019, Are Markets Efficient? (Discubetaing the Efficient Market Hypothesis)
   (v3k,s91k,t13:32)
   https://www.youtube.com/watch?v=xG8FY1TAj8s

 Chegg, 2016, Efficient Markets Hypothesis (EMH) | Finance | Chegg Tutors
   (v43k,s16k,t8:46)
   https://www.youtube.com/watch?v=iR7agdiPLoQ&t=89s

 Investor Trading Academy, 2016, What is The Efficient Market Hypothesis - EMH?
   (v21k,s50k,t1:57)
   https://www.youtube.com/watch?v=e-BoCacmkM8

 MBAsullshitDotCom,2011, Efficient Market Hypothesis in 2 Easy Steps: What is Efficient Market Hypothesis Lecture EMH
    (v173k,s116k,t11:53)
    https://www.youtube.com/watch?v=h5JDftgykcg&t=8s

///////////////////////////
"

.C12EXPLAIN20<-"Links
///////////////////////////
 SEC, SEC forms 3,4,and 5
     https://www.sec.gov/fast-answers/answersform345htm.html

 Random Walk Theory
     https://www.investopedia.com/terms/r/randomwalktheory.asp

///////////////////////////
"


.chapter13<-function(i){
" i  Chapter 13: Capital Buegeting Applications & Pitfalls   
  -  -------------------------------------
  1  So many returns
  2  Key: promised return > expected return 
  3  Promised, expected, typical or most likely 
  4  Risk reduction  creates value? 
  5  Risk and conglomeration 
  6  Hedging 
  7  Risk management creates value? 
  8  Important: Does hedging add value?
  9  Do projects nned their own costs of capital?
 10  Important: independent projects
 11  Positive external effects (positive project interactions)
 12  Negative external effects (negative project interactions)
 13  Decision rule: project NPV vs. firm's NPV
 14  Economics of scale 
 15  Sunk costs
 16  Real options 
 17  Control mechanisum/fidciary responsibility 
 18  NPV checklist 
 19  Youtube
 20  Links

 Example #1:>.c13    # see the above list
 Example #2:>.c13(1) # see the 1st explanation 

";.chapter13_(i)}


.c13<-.chapter13

.n13chapter<-20

.chapter13_<-function(i){
    .printEachQ(13,i,.n13chapter)
}


.C13EXPLAIN1<-"So many returns
/////////////////////////////

  Internal rate of return 

  Cost of capital

  Expected rate of return 

  Hurdle rate

  Warning: The IRR should be an expected return concept, 
           but it is often misapplied to promised returns. 

/////////////////////////////
"

.C13EXPLAIN2<-"Key: promised return > expected return 
//////////////////////////////////////

  Many users are confused with those two returns: 
       promised and expected returns. 

  When estimating an NPV, they mistakenly use a promised 
       return isntead of an expected return. 

  Becase the promised return is usually higher than
     its corresponding expected return, the NPV will be 
     inflated overward. 
  
//////////////////////////////////////
"

.C13EXPLAIN3<-"Promised, expected, typical or most likely 
//////////////////////////////////////
  Promised return: this is not the return an investor
                   would get.  

  Expected return: considering the probability 

  Typical retrun:  could be treated as the mode

  Most likly return: mode  

//////////////////////////////////////
"
.C13EXPLAIN4<-"Risk reduction  creates value? 
//////////////////////////////////////

//////////////////////////////////////
"
.C13EXPLAIN5<-"Hedging 
//////////////////////////////////////

  Hedging is an arragnement that reduces the firm's volatility 

//////////////////////////////////////
"
.C13EXPLAIN6<-"
//////////////////////////////////////

//////////////////////////////////////
"
.C13EXPLAIN7<-"Risk management creates value? 
//////////////////////////////////////

  Hedging agains stock market risk can lower the market 
      exposure and/or risk of the firm. 

  Hedging against jet fule price increases can 
      reduce risk exposure. 

  Q: Does hedging create value?
  A: Only in an imperfect market

//////////////////////////////////////
"

.C13EXPLAIN8<-"Important: Does hedging add value?
//////////////////////////////////////
 In a perfect market, the following holds:
    If two firms are independent, then combination them into 
    a conglomerate usually reduces the overal firms risk, 
    but does not create value for investors. Investors can 
    easily diversify risk themselves. 

 Adding independent projects to the firm can not create value
    if those projects as not positive NPV in themselves. 
 
 In an imperfect market, the value effects of hedging are complex. 
    Hedges could indeed add (or reduce) value. 

//////////////////////////////////////
"

.C13EXPLAIN9<-"Do projects nned their own costs of capital?
//////////////////////////////////////


//////////////////////////////////////
"

.C13EXPLAIN10<-"Important: independent projects
//////////////////////////////////////

  Investors can simply add the project NPV's of independent projects

//////////////////////////////////////
"
.C13EXPLAIN11<-"Positive external effects (positive project interactions)
//////////////////////////////////////

//////////////////////////////////////
"

.C13EXPLAIN12<-"Negative external effects (negative project interactions)
//////////////////////////////////////

//////////////////////////////////////
"

.C13EXPLAIN13<-"Decision rule: project NPV vs. firm's NPV
//////////////////////////////////////
 Important:
    The decision on whether to take one additional project should be 
        made based on the following rule. 

      Accept New Project if:  Total firm's NPV    >  Total firm NPV
                              with new project       without the project 

 1) This means that the single new project should be credited 
       with any value increases or vlues decrese that it confers
       on other projects. 

 2) When considering a project on the margin (i.e., extra), 
       credit/charge to this project all externalites that 
       this project conveys onto the existing firm. 

 3) Everything else eual, project with positive externalitis on 
        the rest of the firm have higher marginal benefits than 
        do project with negative externalities. 

//////////////////////////////////////
"
.C13EXPLAIN14<-"Economics of scale 
//////////////////////////////////////

//////////////////////////////////////
"


.C13EXPLAIN15<-"Sunk costs
//////////////////////////////////////

 A sunk cost is an incurred cost that cannot be altered or revsersed. 
  
 Important: A sunk cost has no cost contibution on the margin. 
            It should therefore be ignored. 

//////////////////////////////////////
"
.C13EXPLAIN16<-"Real options 
//////////////////////////////////////

 A real option is the value of the flexibility to change 
      course in the future. 

//////////////////////////////////////
"
.C13EXPLAIN17<-"
//////////////////////////////////////

//////////////////////////////////////
"
.C13EXPLAIN18<-"
//////////////////////////////////////

//////////////////////////////////////
"
.C13EXPLAIN19<-"Youtube 
//////////////////////////////////////
 I Hate Math Group, Inc,2013, How to find the Expected Return and Risk
   (v226k,s18k,t6:52)
   https://www.youtube.com/watch?v=h7Fqk529BP0&t=1s

 Learnto invest,2018,Hedging a Stock Portfolio - Hedging Strategies for a Market Crash
   (v3k,s25k,t18:12)
   https://www.youtube.com/watch?v=Wj5Q3GxGiG8

 Tastytrade,2016,Hedging Positions | Options Trading Concepts
   (v63k,s129kt13:52)
   https://www.youtube.com/watch?v=1iYQ0XOLHNU

//////////////////////////////////////
"
.C13EXPLAIN20<-"Links 
//////////////////////////////////////
 Chen, James, Investopedia, 2019, Expected Return
    https://www.investopedia.com/terms/e/expectedreturn.asp

//////////////////////////////////////
"


.chapter14<-function(i){
" i  Chapter 14: Financial statements/cash flows
  -  -------------------------------------
  1  Purposes of a financial statement analysis  
  2  A simple balance sheet
  3  A simple income statement
  4  Formula to generate cash flows
  5  manually download latest several years' financial statements (BS,IS,CF)
  6  Downloading BS, IS and CF for 10 companies 
  7  What is the purpose for a ratio analysis
  8  several frequently used ratios
  9  A list of accounting ratios
 10  DuPont Identity 
 11  CIK (Central Index Key)/accebeta to SEC filings 
 12  Common-size financial statements
 13  Long-term accruals
 14  Earning management 
 15  Short-term accruals and working capital 
 16  Depreciation nuance
 17  Important: balance sheet stock numbers
 18  Macro 4 financial statement
 19  Youtubes 
 20  Links 

 Example #1:> .c14     # find out the list 
 Example #2:> .c14(1)  # see the first explanation 

";.chapter14_(i)}

.n14chapter<-20
.chapter14_<-function(i){
    .printEachQ(14,i,.n14chapter)
}

.c14<-.chapter14

.C14EXPLAIN1<-"Purposes of a financial statement analysis  
//////////////////////////

Objective #1: compare with company itself

              look at various ratios to see improvements 
               check performance and weaknebeta

Objective #2: compare with peers in the same industry

//////////////////////////
"

.C14EXPLAIN2<-"A simple balance sheet
//////////////////////////

 A balance-sheet is snapshot for a company, 
    usually a quarter one or an annual one. 

Example

      Cash        = 0.2m
      Equipment   = 0.5m
      Other values= 0.3m
     -------------------
      Total abetaets= 1.0m

  Short-term debt =   0.1m 
  Long-term debt  =   0.3m
  Equity          =   0.6m
    ---------------------
  Total abetaets    =   1.0m

//////////////////////////
"


.C14EXPLAIN3<-"A simple income statement
//////////////////////////

Basic format	                        
     Revenue
  -  Cost
  -  Interest payment
     ----------------
       EBT 
  -  Tax 
     ---------------
  =  Net Income	

Example
  ----------------------------------
  Revenue            =   100
  Cost               = -  50
  Interest payment   = -  10
  -----------------------------
   EBT               =     40
   Tax rate is 0.34  = -13.6
--------------------------------
   Net Income        =    26.4

//////////////////////////
"
.C14EXPLAIN4<-"A simple cash flow statement 
//////////////////////////
  Free Cash Flow = NI + Depreciation - change in CapEx + change in NWC

      NI           is Net Income
  depreciation     is depreciation of the year
  change in CapEx  is change in capital expenditure
  change in NWC    is change in Net working capital 
  NWC              is net working capital defined as CA -CL
                      CA is the current abetaet
                      CL is the current liability

//////////////////////////
"

.C14EXPLAIN5<-"manually download latest several years' financial statements (BS,IS,CF)
//////////////////////////
 step 1: go to http://finance.yahoo.com

 Step 2: enter a ticker, e.g., \"ibm\"

 Step 3: click \"Financials\"

 Step 4: choose Balance Sheet, Income statement or Cash flow

 Step 5: choose annual or quarterly

//////////////////////////
"

.C14EXPLAIN6<-"Downloading BS, IS and CF for 10 comanies 
//////////////////////////
 .getdata

  .getBS10

  .getIS10

  .getCF10

//////////////////////////
"

.C14EXPLAIN7<-"What is the purpose for a ratio analysis
//////////////////////////
Objective #1: compare with company itself

              look at various ratios to see improvements 
               check performance and weaknebeta

Objective #2: compare with peers in the same industry

//////////////////////////
"

.C14EXPLAIN8<-"several frequently used ratios
//////////////////////////
Short-term liquidity
--------------------
                     CA
 current ratio = ----------------
                     CL

  CA: current abetaet 
  CL: current liability

                   CA - inventory
  quick ratio   = ----------
                       CL

                    Cash + short-term securities
  cash ratio ==  ---------------------------
                            CL
leverage ratios
---------------             D
   Debt to Total abetaets  = ---
                            A
                                    LT debt
   long-term debt to total abetaet=   -----
                                      A
                              D
    Debt to equity ratio =   ----
                              E
Probability 
------------
         NI                     NI
   ROA = ---            ROE  = ----
         A                      A
        
//////////////////////////
"
.C14EXPLAIN9<-"A list of accounting ratios
//////////////////////////
Profitability Ratios
--------------------
   Grobeta Profit Rate = Grobeta Profit / Net Sales
         Evaluates how much grobeta profit is generated from sales. 
         Grobeta profit is equal to net sales (sales minus sales 
         returns, discounts, and allowances) minus cost of sales.

   Return on Sales = Net Income / Net Sales
         Also known as \"net profit margin\" or \"net profit rate\",
         it measures the percentage of income derived from dollar 
         sales. Generally, the higher the ROS the better.

   Return on Abetaets = Net Income / Average Total Abetaets
         In financial analysis, it is the measure of the return on 
         investment. ROA is used in evaluating management's efficiency 
         in using abetaets to generate income.

  Return on Stockholders' Equity = Net Income / Average Stockholders' Equity
          Measures the percentage of income derived for every dollar of owners' equity.

Liquidity Ratios
-----------------
  Current Ratio = Current Abetaets / Current Liabilities
          Evaluates the ability of a company to pay short-term obligations 
          using current abetaets (cash, marketable securities, current 
          receivables, inventory, and prepayments).

  Acid Test Ratio = Quick Abetaets / Current Liabilities
          Also known as \"quick ratio\", it measures the ability of a 
          company to pay short-term obligations using the more liquid
          types of current abetaets or \"quick abetaets\" (cash, marketable 
          securities, and current receivables).

  Cash Ratio = ( Cash + Marketable Securities ) / Current Liabilities
          Measures the ability of a company to pay its current liabilities 
          using cash and marketable securities. Marketable securities are 
          short-term debt instruments that are as good as cash.

  Net Working Capital = Current Abetaets - Current Liabilities
          Determines if a company can meet its current obligations with 
          its current abetaets; and how much excebeta or deficiency there is.

Management Efficiency Ratios
-----------------------------
  Receivable Turnover = Net Credit Sales / Average Accounts Receivable
          Measures the efficiency of extending credit and collecting 
          the same. It indicates the average number of times in a year 
          a company collects its open accounts. A high ratio implies efficient credit and collection procebeta.

  Days Sales Outstanding = 360 Days / Receivable Turnover
          Also known as \"receivable turnover in days\", \"collection period\". 
          It measures the average number of days it takes a company to collect 
          a receivable. The shorter the DSO, the better. Take note that some 
          use 365 days instead of 360.

  Inventory Turnover = Cost of Sales / Average Inventory
          Represents the number of times inventory is sold and replaced. 
          Take note that some authors use Sales in lieu of Cost of Sales 
          in the above formula. A high ratio indicates that the company is 
          efficient in managing its inventories.

  Days Inventory Outstanding = 360 Days / Inventory Turnover
          Also known as \"inventory turnover in days\". It represents the 
          number of days inventory sits in the warehouse. In other words, 
          it measures the number of days from purchase of inventory to the 
          sale of the same. Like DSO, the shorter the DIO the better.

  Accounts Payable Turnover = Net Credit Purchases / Ave. Accounts Payable
          Represents the number of times a company pays its accounts payable 
          during a period. A low ratio is favored because it is better to 
          delay payments as much as pobetaible so that the money can be used 
          for more productive purposes.

  Days Payable Outstanding = 360 Days / Accounts Payable Turnover
          Also known as \"accounts payable turnover in days\", \"payment period\".
          It measures the average number of days spent before paying obligations 
          to suppliers. Unlike DSO and DIO, the longer the DPO the better 
          (as explained above).

  Operating Cycle = Days Inventory Outstanding + Days Sales Outstanding
          Measures the number of days a company makes 1 complete operating 
          cycle, i.e. purchase merchandise, sell them, and collect the amount 
          due. A shorter operating cycle means that the company generates sales 
          and collects cash faster.

  Cash Conversion Cycle = Operating Cycle - Days Payable Outstanding
          CCC measures how fast a company converts cash into more cash.
          It represents the number of days a company pays for purchases, 
          sells them, and collects the amount due. Generally, like operating
          cycle, the shorter the CCC the better.

  Total Abetaet Turnover = Net Sales / Average Total Abetaets
          Measures overall efficiency of a company in generating sales 
          using its abetaets. The formula is similar to ROA, except that 
          net sales is used instead of net income.
Leverage Ratios
--------------------
  Debt Ratio = Total Liabilities / Total Abetaets
         Measures the portion of company abetaets that is financed by debt 
         (obligations to third parties). Debt ratio can also be computed 
         using the formula: 1 minus Equity Ratio.

  Equity Ratio = Total Equity / Total Abetaets
        Determines the portion of total abetaets provided by equity (i.e. 
        owners' contributions and the company's accumulated profits). 
        Equity ratio can also be computed using the formula: 1 minus Debt Ratio.
        The reciprocal of equity ratio is known as equity multiplier, which is 
        equal to total abetaets divided by total equity.

  Debt-Equity Ratio = Total Liabilities / Total Equity
        Evaluates the capital structure of a company. A D/E ratio of more 
        than 1 implies that the company is a leveraged firm; lebeta than 1 
        implies that it is a conservative one.

  Times Interest Earned = EBIT / Interest Expense
        Measures the number of times interest expense is converted to income,
        and if the company can pay its interest expense using the profits 
        generated. EBIT is earnings before interest and taxes.

Valuation and Growth Ratios
--------------------
  Earnings per Share = ( Net Income - Preferred Dividends ) / Average Common Shares Outstanding
        EPS shows the rate of earnings per share of common stock. Preferred 
        dividends is deducted from net income to get the earnings available 
        to common stockholders.

  Price-Earnings Ratio = Market Price per Share / Earnings per Share
        Used to evaluate if a stock is over- or underpriced. A relatively 
        low P/E ratio could indicate that the company is underpriced. 
        Conversely, investors expect high growth rate from companies with 
        high P/E ratio.

  Dividend Pay-out Ratio = Dividend per Share / Earnings per Share
        Determines the portion of net income that is distributed to owners. 
        Not all income is distributed since a significant portion is retained
        for the next year's operations.

  Dividend Yield Ratio = Dividend per Share / Market Price per Share
        Measures the percentage of return through dividends when compared 
        to the price paid for the stock. A high yield is attractive to 
        investors who are after dividends rather than long-term capital 
        appreciation.

  Book Value per Share = Common SHE / Average Common Shares
        Indicates the value of stock based on historical cost. The value of 
        common shareholders' equity in the books of the company is divided 
        by the average common shares outstanding.
 Source: http://www.accountingverse.com/managerial-accounting/fs-analysis/financial-ratios.html
//////////////////////////
"
.C14EXPLAIN10<-"DuPont identity 
//////////////////////////
                          Net Income
 ROE is defined as   = ----------------
                           Equity 
             NI
       ROE= ---                      (1)
             E
 Let times equation (1) by Sales and divide sales 
             NI   Sales
       ROE= --- * ---                (2)
             E    sales  
 Let times equation (2) by total abetaets and divide it by the same value 
             NI    S    A
       ROE= --- * --- * ---           (3)
             E     s    A
  Now, let's reorganize terms
             NI    S    A
       ROE= --- * --- * ---           (4)
             S     A    E

     ROE=(net income/sales)*(sales/total abetaets)*(total abetaets/equity)

     ROE = Net Profit Margin * Abetaet Turnover * Equity Multiplier

//////////////////////////
"

.C14EXPLAIN11<-"Central Index Key (CIK)/
//////////////////////////
The CIK is the unique numerical identifier abetaigned by the EDGAR 
system to filers when they sign up to make filings to the SEC. 
CIK numbers remain unique to the filer; they are not recycled.

 CIK-ticker mapping 
     http://rankandfiled.com/#/data/tickers

Accebeta to SEC filings 
---------------------
   https://www.sec.gov/edgar/searchedgar/accebetaing-edgar-data.htm

Given CIK, e.g., CIK=51143
   https://www.sec.gov/Archives/edgar/data/51143/
   https://www.sec.gov/Archives/edgar/data/51143/000104746917001061/

//////////////////////////
"
.C14EXPLAIN12<-"Common-size financial statements
//////////////////////////
To compare the performance of a firm over several years or compare its 
   performance with other firms in the same industry, we use so-called 
   common size financial statements. For example, last year's Cash & 
   Equivalents was $1m and this year's corresponding value is $1.1m. 
   With those two values alone, it is difficult to figure out what the 
   impact of this specific data item. If we know further that the ratio 
   of this data item over total sales are a constant over two years, then 
   it is easier to interpret our results.

                       original data
  New Data Item= -----------------------
                       Reference data 

 For a balance-sheet
                       original data
  New Data Item= -----------------------
                       Total abetaet
 For an income statement: 
                       original data
  New Data Item= -----------------------
                       Total Sales 

//////////////////////////
"

.C14EXPLAIN13<-"Long-term accruals
//////////////////////////
 Accruals represent liabilities or abetaets that are 
    recognized in the balance sheet at the end of the 
    accounting period before they are invoiced or paid 
    according to the accrual basis of accounting.

 Accruals may refer to accrued abetaets (also called accrued revenues) 
    or accrued liabilities (also called accrued expenses):

 Illustration 1: Accrual revenues (abetaets) and accrued expenses (liabilities)

  Accrued Revenues (Abetaets)     Accrued Expenses (Liabilities)
  ----------------------        -------------------------------
  Interest receivable           Accrued interest
  Rent receivable               Accrued salaries
  Service revenue receivable    Accrued lawsuit expenses

   http://simplestudies.com/what-are-long-term-accruals.html

//////////////////////////
"

.C14EXPLAIN14<-"Earning management 
//////////////////////////

  There us considerable discretion in financial reporting. 

  Not only earnings-- but also cash flows -- can be managed. 

//////////////////////////
"

.C14EXPLAIN15<-"Short-term accruals and working capital 
//////////////////////////

  Working capital is defined as CA - CL

    CA: current abetaet
    CL: Current liability 

  Working capital = (current abetaets) - (current liabilities)

                   = (Marketable securities + account receivable + inventories)
                   - (Account payable + bank overdrafts + Taxes payables)

  More accruals are hidden in working capital. 

//////////////////////////
"

.C14EXPLAIN16<-"Depreciation nuance
//////////////////////////

  Why you need to get the depreciation number from the cash-flow statement
  
  Depreciation comes in different forms with different names 

  In real life, do not use the depreciation and amortization 
      on the income statement to extract economic cash flows. 
   
//////////////////////////
"
.C14EXPLAIN17<-"Important: balance sheet stock numbers
//////////////////////////
  Important: Balance sheet stock numbers are often inaccurate as 
             measures of true values. 
  
  This applies especially to the book value of equity, 
       it applies, to a lebetaer extent, to the book value of abetaets. 

  The most reliable figures on the balance sheet are often cash and short-term 
       instrument abetaet and financial-debt liability figures. 
           
//////////////////////////
"

.C14EXPLAIN18<-"Macro 4 financial statement
1) enter a ticker in cell A2, such as ibm
2) enter a staring position in cell A3, e.g., C10

Sub getFinStatements()
 sTicker = Range(\"A2\").Value
  If sTicker = \"\" Then
    MsgBox \"No ticker in A2\"
    Exit Sub
  End If
  
  starting = Range(\"A3\").Value
  If starting = \"\" Then
    MsgBox \"No starting cell in A3, such as C10\"
    Exit Sub
  End If

  Path = \"URL;http://www.advfn.com/stock-market/NASDAQ/\" & sTicker
  Path2 = Path & \"/financials?btn=annual_reports&mode=company_data\"
  With ActiveSheet.QueryTables.Add(Connection:=Path2, Destination:=Range(starting))
    .Name = \"financials?btn=annual_reports&mode=company_data\"
    .FieldNames = True
    .RowNumbers = False
    .FillAdjacentFormulas = False
    .PreserveFormatting = False
    .RefreshOnFileOpen = False
    .BackgroundQuery = True
    .RefreshStyle = xlInsertDeleteCells
    .SavePabetaword = False
    .SaveData = True
    .AdjustColumnWidth = True
    .RefreshPeriod = 0
    .WebSelectionType = xlSpecifiedTables
    .WebFormatting = xlWebFormattingAll
    .WebTables = \"6\"
    .WebPreFormattedTextToColumns = True
    .WebConsecutiveDelimitersAsOne = True
    .WebSingleBlockTextImport = False
    .WebDisableDateRecognition = False
    .WebDisableRedirections = False
    .Refresh BackgroundQuery:=False
End With
End Sub

///////////////////////////////
"

.C14EXPLAIN19<-"Youtubes 
///////////////////////////////
  Alanis Businebeta Academy,2012, How to Calculate Depreciation
    (147k,s90k,t5:21)
    https://www.youtube.com/watch?v=3Q3dRA-4yM8

  boardevaluation, 2014, Financial analysis made easy (and quick!)
    (v75k,s751,t8:8)
    https://www.youtube.com/watch?v=kRpfqzD4sNQ

  Edspira, 2013, The Income Statement, defined and explained
    (v84k,s106k,t5:5)
    https://www.youtube.com/watch?v=-__bUSEls5Y

  Hodder,Hamish, 2019, How to Read an Income Statement | Financial Statement Analysis (1/3)
    (v3k,s6.7k,t16:0)
    https://www.youtube.com/watch?v=3wsT0yHeKfk

  Khan Academy, 2012,Introduction to Income Statements 
    (v706,v2.9m,t15:26)
    https://www.youtube.com/watch?v=Z7C4cz2HkeY

  Khan Academy, 2012,Introduction to Balance Sheets 
    (v751k,v2.9m,t9:53)
    https://www.youtube.com/watch?v=mxsYHiDVNlk

  Plain Bagel, Plain, 2019, Cash flows
    (v24k,s38k,t10:24)
    https://www.youtube.com/watch?v=hefAHWvrFDQ

/////////////////////////////////
"

.C14EXPLAIN20<-"Links 
///////////////////////////////
  Cash Flow statements
       http://harbert.auburn.edu/~colqull/FINC3610/Chap9notes.pdf

  CIK (Central Index Key)
       https://en.wikipedia.org/wiki/Central_Index_Key
  CIK-ticker mapping 
       http://rankandfiled.com/#/data/tickers
  Google finance: https://www.google.com/finance

  Investpedia, Depreciaion 
   https://www.investopedia.com/terms/d/depreciation.asp

  SEC filings:    https://www.sec.gov/edgar.shtml
  SEC EGDAR Company filings
       https://www.sec.gov/edgar/searchedgar/companysearch.html
  SEC filing examples
       https://www.sec.gov/Archives/edgar/data/1599496/000146581817000048/0001465818-17-000048.txt
              edgar/data/1599496/0001465818-17-000048.txt
              edgar/data/1084869/0001140361-17-028809.txt
              edgar/1084869/0001140361-17-028809.txt
              edgar/data/1307969/0001683168-16-000379.txt
       https://www.sec.gov/Archives/edgar/data/1599496/000146581817000048/0001465818-17-000048.txt

  Yahoo!Finance:  http://finance.yahoo.com/ 

/////////////////////////////////
"


.chapter15<-function(i){
" i  Chapter 15: Comparables and financial ratios
  -  -------------------------------------
  1  Law of one price 
  2  P/E ratio
  3  Price based on growing perpetuity 
  4  Important: P/E
  5  PVGO (Present value of growth opportunities 
  6  Important:
  7  Measures of leverage 
  8  Measures of profitability 
  9  Common-size financial statements
 10  What is the purpose for a ratio analysis
 11  several frequently used ratios
 12  A list of accounting ratios (Profitability Ratios)
 13  A list of accounting ratios (liquidity ratios)
 14  A list of accounting ratios (Leverage Ratios)
 15  A list of accounting ratios (Valuation and Growth Ratios)
 16  DuPont identity 
 17  How to find competitors industry ratios/multiples and stock evaluation
 18  save financial statements easily 
 19  Youtubes
 20  Links .

 Example #1:> .c15     # find out the list 
 Example #2:> .c15(1)  # see the first explanation 

";.chapter15_(i)}

.n15chapter<-20

.chapter15_<-function(i){
    .printEachQ(15,i,.n15chapter)
}


.c15<-.chapter15

.C15EXPLAIN1<-"The law of one price
//////////////////////////
 Ultimately, NPV and comparable-based valuation are 
    both applications of the law of ne price -- first cousins. 

  It is the law of one price that ultimately gives you a value estimate

  In theory, companies with the same correct attributes should have the same value. 

  In practice, companies with similar relevant attributes should have similar values. 

//////////////////////////
"

.C15EXPLAIN2<-"P/E ratio 
//////////////////////////
  The price-to-earnings ratio (P/E ratio) is the ratio for
    valuing a company that measures its current share price
    relative to its per-share earnings (EPS). 

  The price-to-earnings ratio is also sometimes known as 
      the price multiple or the earnings multiple.

  P/E ratios are used by investors and analysts to determine 
     the relative value of a company's shares in an 
     apples-to-apples comparison. It can also be used 
     to compare a company against its own historical 
     record or to compare aggregate markets against one another or over time.

 KEY TAKEAWAYS
   A high P/E ratio could mean that a company's stock 
      is over-valued, or else that investors are expecting
      high growth rates in the future.

   Two kinds of P/E ratios - forward and trailing P/E - are used in practice.

                  Market value per share
     P/E Ratio =  ----------------------- 
                     Earnings per share

      https://www.investopedia.com/terms/p/price-earningsratio.asp

//////////////////////////
"

.C15EXPLAIN3<-"Price based on growing perpetuity 
//////////////////////////

                          Expected earnings 
   Price  = --------------------------------------------
             Cost of capita - Expected growth rate of earnings 

//////////////////////////
"

.C15EXPLAIN4<-"Important: P/E
//////////////////////////

  All else equal, the price-earnings ratio is higher 
      for firms with more future earnings and more 
      future earnings growth. 

//////////////////////////
"



.C15EXPLAIN5<-"PVGO (Present value of growth opportunities) 
//////////////////////////

            Expected earnings 
   Price = ---------------------  + PVGO
            Cost of capital 

//////////////////////////
"

.C15EXPLAIN6<-"Important:
//////////////////////////

  Unlike market betas and costs of capital, price-earnings ratios
         cannot be value-weighted and averaged. 

  Mergers can change P/E ratios even if they do not create value. 

  Ratios intrinsically never make sense when denominators 
         can take on negative values. 

//////////////////////////
"
.C15EXPLAIN7<-"Measures of leverage 
//////////////////////////
   Debt-equity ratio 

               Long-term Debt
      ----------------------------
        Market Value (MV) of Equity 

             Financial Debt
         ----------------------------
          Market Value (MV) of Equity 

              Financial Debt
           --------------------
           Book value (BV) of Equity 

//////////////////////////
"
.C15EXPLAIN8<-"Measures of profitability 
//////////////////////////

     Net Income
   --------------
      Sales

     Net Income
   ------------ 
     BV of Abetaets

        Sales 
     ------------ 
     BV of Abetaets

//////////////////////////
"
.C15EXPLAIN9<-"Common-size financial statements
//////////////////////////
To compare the performance of a firm over several years or compare its 
   performance with other firms in the same industry, we use so-called 
   common size financial statements. For example, last year's Cash & 
   Equivalents was $1m and this year's corresponding value is $1.1m. 
   With those two values alone, it is difficult to figure out what the 
   impact of this specific data item. If we know further that the ratio 
   of this data item over total sales are a constant over two years, then 
   it is easier to interpret our results.

                       original data
  New Data Item= -----------------------
                       Reference data 

 For a balance-sheet

                       original data
  New Data Item= -----------------------
                       Total abetaet

 For an income statement: 

                       original data
  New Data Item= -----------------------
                       Total Sales 

//////////////////////////
"

.C15EXPLAIN10<-"What is the purpose for a ratio analysis
//////////////////////////
Objective #1: compare with company itself

              look at various ratios to see improvements 
               check performance and weaknebeta

Objective #2: compare with peers in the same industry

//////////////////////////
"

.C15EXPLAIN11<-"several frequently used ratios
//////////////////////////
Short-term liquidity
--------------------
                     CA
 current ratio = ----------------
                     CL
  CA: current abetaet 
  CL: current liability
                   CA - inventory
  quick ratio   = ----------
                       CL
                    Cash + short-term securities
  cash ratio ==  ---------------------------
                            CL
leverage ratios
--------------------        D
   Debt to Total abetaets  = ---
                            A          LT Debt
   long-term debt to total abetaet   =   -----
                                         A
                              D
    Debt to equity ratio =   ----
                              E
Probability 
         NI                      NI
   ROA = ---            ROE  = ------
         A                        E
//////////////////////////
"

.C15EXPLAIN12<-"A list of accounting ratios (Profitability Ratios)
//////////////////////////
Profitability Ratios
--------------------
   Grobeta Profit Rate = Grobeta Profit / Net Sales
         Evaluates how much grobeta profit is generated from sales. 
         Grobeta profit is equal to net sales (sales minus sales 
         returns, discounts, and allowances) minus cost of sales.

   Return on Sales = Net Income / Net Sales
         Also known as \"net profit margin\" or \"net profit rate\",
         it measures the percentage of income derived from dollar 
         sales. Generally, the higher the ROS the better.

   Return on Abetaets = Net Income / Average Total Abetaets
         In financial analysis, it is the measure of the return on 
         investment. ROA is used in evaluating management's efficiency 
         in using abetaets to generate income.

  Return on Stockholders' Equity = Net Income / Average Stockholders' Equity
          Measures the percentage of income derived for every dollar of owners' equity.

//////////////////////////
"

.C15EXPLAIN13<-"A list of accounting ratios (liquidity ratios)
//////////////////////////
Liquidity Ratios
--------------------
  Current Ratio = Current Abetaets / Current Liabilities
          Evaluates the ability of a company to pay short-term obligations 
          using current abetaets (cash, marketable securities, current 
          receivables, inventory, and prepayments).

  Acid Test Ratio = Quick Abetaets / Current Liabilities
          Also known as \"quick ratio\", it measures the ability of a 
          company to pay short-term obligations using the more liquid
          types of current abetaets or \"quick abetaets\" (cash, marketable 
          securities, and current receivables).

  Cash Ratio = ( Cash + Marketable Securities ) / Current Liabilities
          Measures the ability of a company to pay its current liabilities 
          using cash and marketable securities. Marketable securities are 
          short-term debt instruments that are as good as cash.

  Net Working Capital = Current Abetaets - Current Liabilities
          Determines if a company can meet its current obligations with 
          its current abetaets; and how much excebeta or deficiency there is.

//////////////////////////
"

.C15EXPLAIN14<-"A list of accounting ratios (Management Efficiency Ratios)
//////////////////////////
Management Efficiency Ratios
--------------------
  Receivable Turnover = Net Credit Sales / Average Accounts Receivable
          Measures the efficiency of extending credit and collecting 
          the same. It indicates the average number of times in a year 
          a company collects its open accounts. A high ratio implies efficient credit and collection procebeta.

  Days Sales Outstanding = 360 Days / Receivable Turnover
          Also known as \"receivable turnover in days\", \"collection period\". 
          It measures the average number of days it takes a company to collect 
          a receivable. The shorter the DSO, the better. Take note that some 
          use 365 days instead of 360.

  Inventory Turnover = Cost of Sales / Average Inventory
          Represents the number of times inventory is sold and replaced. 
          Take note that some authors use Sales in lieu of Cost of Sales 
          in the above formula. A high ratio indicates that the company is 
          efficient in managing its inventories.

  Days Inventory Outstanding = 360 Days / Inventory Turnover
          Also known as \"inventory turnover in days\". It represents the 
          number of days inventory sits in the warehouse. In other words, 
          it measures the number of days from purchase of inventory to the 
          sale of the same. Like DSO, the shorter the DIO the better.

  Accounts Payable Turnover = Net Credit Purchases / Ave. Accounts Payable
          Represents the number of times a company pays its accounts payable 
          during a period. A low ratio is favored because it is better to 
          delay payments as much as pobetaible so that the money can be used 
          for more productive purposes.

  Days Payable Outstanding = 360 Days / Accounts Payable Turnover
          Also known as \"accounts payable turnover in days\", \"payment period\".
          It measures the average number of days spent before paying obligations 
          to suppliers. Unlike DSO and DIO, the longer the DPO the better 
          (as explained above).

  Operating Cycle = Days Inventory Outstanding + Days Sales Outstanding
          Measures the number of days a company makes 1 complete operating 
          cycle, i.e. purchase merchandise, sell them, and collect the amount 
          due. A shorter operating cycle means that the company generates sales 
          and collects cash faster.

  Cash Conversion Cycle = Operating Cycle - Days Payable Outstanding
          CCC measures how fast a company converts cash into more cash.
          It represents the number of days a company pays for purchases, 
          sells them, and collects the amount due. Generally, like operating
          cycle, the shorter the CCC the better.

  Total Abetaet Turnover = Net Sales / Average Total Abetaets
          Measures overall efficiency of a company in generating sales 
          using its abetaets. The formula is similar to ROA, except that 
          net sales is used instead of net income.
//////////////////////////
"

.C15EXPLAIN14<-"A list of accounting ratios (Leverage Ratios)
//////////////////////////
Leverage Ratios
--------------------
  Debt Ratio = Total Liabilities / Total Abetaets
         Measures the portion of company abetaets that is financed by debt 
         (obligations to third parties). Debt ratio can also be computed 
         using the formula: 1 minus Equity Ratio.

  Equity Ratio = Total Equity / Total Abetaets
        Determines the portion of total abetaets provided by equity (i.e. 
        owners' contributions and the company's accumulated profits). 
        Equity ratio can also be computed using the formula: 1 minus Debt Ratio.
        The reciprocal of equity ratio is known as equity multiplier, which is 
        equal to total abetaets divided by total equity.

  Debt-Equity Ratio = Total Liabilities / Total Equity
        Evaluates the capital structure of a company. A D/E ratio of more 
        than 1 implies that the company is a leveraged firm; lebeta than 1 
        implies that it is a conservative one.

  Times Interest Earned = EBIT / Interest Expense
        Measures the number of times interest expense is converted to income,
        and if the company can pay its interest expense using the profits 
        generated. EBIT is earnings before interest and taxes.

//////////////////////////
"

.C15EXPLAIN15<-"A list of accounting ratios (Valuation and Growth Ratios)
//////////////////////////
Valuation and Growth Ratios
--------------------
  Earnings per Share = (Net Income - Preferred Dividends ) / Average Common Shares Outstanding
        EPS shows the rate of earnings per share of common stock. Preferred 
        dividends is deducted from net income to get the earnings available 
        to common stockholders.

  Price-Earnings Ratio = Market Price per Share / Earnings per Share
        Used to evaluate if a stock is over- or underpriced. A relatively 
        low P/E ratio could indicate that the company is underpriced. 
        Conversely, investors expect high growth rate from companies with 
        high P/E ratio.

  Dividend Pay-out Ratio = Dividend per Share / Earnings per Share
        Determines the portion of net income that is distributed to owners. 
        Not all income is distributed since a significant portion is retained
        for the next year's operations.

  Dividend Yield Ratio = Dividend per Share / Market Price per Share
        Measures the percentage of return through dividends when compared 
        to the price paid for the stock. A high yield is attractive to 
        investors who are after dividends rather than long-term capital 
        appreciation.

  Book Value per Share = Common SHE / Average Common Shares
        Indicates the value of stock based on historical cost. The value of 
        common shareholders' equity in the books of the company is divided 
        by the average common shares outstanding.

 Source: 
    http://www.accountingverse.com/managerial-accounting/fs-analysis/financial-ratios.html
//////////////////////////
"
.C15EXPLAIN16<-"DuPont identity 
//////////////////////////
                          Net Income
 ROE is defined as   = ----------------
                           Equity 
             NI
       ROE= ---                      (1)
             E
 Let times equation (1) by Sales and divide sales 
             NI   Sales
       ROE= --- * ---                (2)
             E    sales  

 Let times equation (2) by total abetaets and divide it by the same value 
             NI    S    A
       ROE= --- * --- * ---           (3)
             E     s    A

  Now, let's reorganize terms
             NI    S    A
       ROE= --- * --- * ---           (4)
             S     A    E

     ROE=(net income/sales)*(sales/total abetaets)*(total abetaets/equity)
     ROE = Net Profit Margin * Abetaet Turnover * Equity Multiplier

//////////////////////////
"

.C15EXPLAIN17<-"How to find competitors and industry ratios
//////////////////////////
             current price
 PE ratio = ------------
               EPS

   EPS is the earnings per share 
          
multiples and stock evaluation
-----------------------
Many multiples, such as PE ratio, could be 
   used to evaluation a stock's performance. 

//////////////////////////
"

.C15EXPLAIN18<-".saveFinStatement() function 
///////////////////////////////
The function used to save various financial statements is 
    called saveFinStatement

  Step 1: Type getData
          >.getdata

  Step 2: type function name to find its usage
          >.saveFinStatement

 Example #1:> x=.getCFannual(\"ibm\")
              Annual Cash Flow Statement for ibm
            > .saveFinStatement(x,\"c:/temp/ibm.csv\")
              [1] \"Your saved file is ==>c:/temp/ibm.csv\"

 Example #2:> y=.getBSannual(\"msft\")
                Annual Balance Sheet for msft
            > .saveFinStatement(y)
             [1] \"Your saved file is ==>C:/Users/yany/Documents/test.csv\"

             Note: the data is saved under the current working directory
                   with a default name of test.csv

/////////////////////////////////
"
.C15EXPLAIN19<-"Youtubes
///////////////////////////////

  Dividend Investor!, 2017, The Price-to-Earnings (P/E) Ratio | Basic Investment Terms #6
    (v201k,s21k,t4:20))
    https://www.youtube.com/watch?v=PqnK0254J_0

  Edspira,2018, Price Earnings (P/E) Ratio
    (v5k,s122k,t2:54)
    https://www.youtube.com/watch?v=tQFGSfK4iZQ

/////////////////////////////////
"
.C15EXPLAIN20<-"useful links 
///////////////////////////////
Source of information:
a
 Yahoo!Finance
     http://finance.yahoo.com/

 Google finance
     https://www.google.com/finance

 Markte Watch
     http://www.marketwatch.com/

 SEC filings
     https://www.sec.gov/edgar.shtml

 SEC EGDAR Company filings
     https://www.sec.gov/edgar/searchedgar/companysearch.html

 SEC quarterly index
     https://www.sec.gov/Archives/edgar/full-index/

 CIK (Central Index Key)
     https://en.wikipedia.org/wiki/Central_Index_Key

 CIK-ticker mapping 
     http://rankandfiled.com/#/data/tickers

 SEC filing examples
     https://www.sec.gov/Archives/edgar/data/1599496/000146581817000048/0001465818-17-000048.txt
              edgar/data/1599496/0001465818-17-000048.txt
              edgar/data/1084869/0001140361-17-028809.txt
              edgar/1084869/0001140361-17-028809.txt
              edgar/data/1307969/0001683168-16-000379.txt
    https://www.sec.gov/Archives/edgar/data/1599496/000146581817000048/0001465818-17-000048.txt
 
 Financial ratios
     http://www.accountingverse.com/managerial-accounting/fs-analysis/financial-ratios.html

 6 Basic Financial Ratios And What They Reveal (YouTube,2m3s)
     http://www.investopedia.com/financial-edge/0910/6-basic-financial-ratios-and-what-they-tell-you.aspx

 Cash Flow statements
     http://harbert.auburn.edu/~colqull/FINC3610/Chap9notes.pdf

 Compustat
     https://en.wikipedia.org/wiki/Compustat
 
 Understanding the COMPUSTAT (North America) Database 
     http://web.utk.edu/~prdaves/Computerhelp/COMPUSTAT/Compustat_manuals/user_02.pdf

 CRSP/Compustat Merged Database
    http://www.crsp.com/products/research-products/crspcompustat-merged-database

/////////////////////////////////
"


#source("http://canisius.edu/~yany/R/criticalFvalue.R")
.chapter16<-function(i){
" i  Chapter 16: Normal,T,Chisq, F and other distributions 
  -  -------------------------------------
  1  A fair game, expected value vs. realized value 
  2  Density distribution and cumulative density distribution
  3  Formulae a normal distributions/standard normal distributions 
  4  Draw a standard normal distribution 
  5  What is a inverse function?
  6  Inverse functions for a standard normal distribution 
  7  Significance level vs. confidence level
  8  4 R functions for a standard/cumulative normal distributions
  9  4 R functions student-s distributions
 10  4 R functions Chisq distributions
 11  4 R functions F-distributions
 12  One sided vs. two sided
 13  Two critical values: 2 for a T-value and 5% for a p-value
 14  Critical values for 4 distributions 
 15  Test of equal distributions 
 16  Normality test 
 17  t.test(), var.test(),chisq_test()
 18  List of distributions
 19  Youtube 
 20  Links

 Example #1:>.c16     # find out the list 
 Example #2:>.c16(1)  # see the first explanation 
";.chapter16_(i)}

.n16chapter<-20

.chapter16_<-function(i){
    .printEachQ(16,i,.n16chapter)
}

.c16<-.chapter16

.C16EXPLAIN1<-"A fair game, expected vs. realized 
//////////////////////////////
 A fair game is a game that the expected value is zero for both players. 

 If we have two players against each other, i.e., zero-sum game, 

    we are indifferent between choosing one position or the other. 

  If we tobeta a fair coin, i.e., equal chance to be head or tail. 
  If we have a head, we would win $1. If a tail, we could lose $1. 

  This is a fair game. 
  For just one tobeta, we could win $1 for lose $1. 
  However, if we play a million times, the expected value will be 0. 

expected value vs. realized value 
------------------------------
    If we have a model, we could predict a value (expected)
    The realized value will be the value we observe

//////////////////////////////
"

.C16EXPLAIN2<-"density distribution vs. cumulative density function
//////////////////////////////
Cumulative density is actually cumulative properties.

 Case #1: Tobeta a dice with values from 1 to 6           
             Each number has 1/6 probability                
             What is the prob. to get a number lebeta than 4?  
                      1/6 + 1/6 + 1/6 = 3/6 =1/2                
             1/6 is probability of each number, while           
             1/2 is the cumulative probability (distribution) 
 
  Case #2: uniform distribution: abetaume density function is 1/a and choose a=5    
            from 1 to 5, the density is 1/5. total sum is 5*1/5 =1                               
            what does it mean that the density function is 1/5 (0.2)?                              
            Take a value between 0 and 5, such as x=1.5 and choose a small number 
            about called deltaX. The probability that a random number falls into  
               this small strip = f(x) * deltaX= 0.2*detlaX   

//////////////////////////////
"

.C16EXPLAIN3<-"Formula for a normal distributions
//////////////////////////////
 The normal distribution is a probability distribution that abetaociates 
    the normal random variable X with a cumulative probability. 
    The normal distribution is defined by the following equation:
                           1                                     
           f(x) = ---------------- * exp(-0.5 *[(x-mean)/(sigma))]^2)               
                 sqrt(2*pi*sigma^2)                                

The standard normal distribution is defined by the following equation: 
-------------------------------
                       1                                     
           f(x) = --------- * exp(-0.5 *x^2)               
                   sqrt(2*pi)                                

    where f(x) is the density function, x is the input
       pi is 3.1415926

 Manually, we could calculate a few values. 
    x=0    -> f(x) = 1/sqrt(2*3.1415925) ->  0.3989423

    x=1    -> f(1) = 1/sqrt(2*3.1415926)*exp(-0.5)          ->   0.2419707  
    x=-1    -> f(-1) = 1/sqrt(2*3.1415926)*exp(-0.5*(-1)^2) ->   0.2419707

//////////////////////////////
"

.C16EXPLAIN4<-"Draw a graph for the standard normal distribution 
//////////////////////////////
x<-seq(-3,3,0.1)
y<-dnorm(x)
plot(x,y)


//////////////////////////////
"
.C16EXPLAIN5<-"What is an inverse function?
//////////////////////////////
  + and -   are pair
                       A+2 =  C   -> A= C -2 
  * and \  are a pair
                       A*10 = C  -> A = c/10

  exp() and log() are pair
                           > a<-exp(2)
                           > a
                             [1] 7.389056 
                           > log(a)
                             [1] 2

//////////////////////////////
"

.C16EXPLAIN6<-"Inverse functions for a standard normal distribution 
//////////////////////////////
For a normal distributio pnorm() and qnorm() are a pair. 

Let's look at cumulative standard normal distribution, pnorm() function 
at 0. This is a cumulative standard normal distribution for a given x. 

  Examples: > pnorm(0)    -->  [1] 0.5
            > pnorm(-2)   -->  [1] 0.02275013
            > pnorm(2)    -->  [1] 0.9772499

For the first one, from 0.5 what is x?
            > qnorm(0.5)         -->   [1] 0
            > qnorm( 0.02275013) -->   [1] -2
            > qnorm(0.9772499)   -->   [1] 2.000001

//////////////////////////////
"


.C16EXPLAIN7<-"Significance level vs. confidence level 
//////////////////////////////
    Confidence level = 1 - significance level 
//////////////////////////////
"
.C16EXPLAIN8<-"4 R functions for a standard/cumulative normal distributions
//////////////////////////////
dnorm(x, mean = 0, sd = 1, log = FALSE)
pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
rnorm(n, mean = 0, sd = 1)

The first letter for those four functions
----------------------------------------
  d    : density function 
  p    : probability 
  q    : inverse
  r    : random number 

Arguments
     x, q       vector of quantiles.
     p          vector of probabilities.
     n          number of observations. If length(n) > 1, the length is taken to be the number required.
    mean        vector of means.
      sd        vector of standard deviations.
   log, log.p   logical; if TRUE, probabilities p are given as log(p).
   lower.tail   logical; if TRUE (default), probabilities are P[X <= x] otherwise, P[X >= x].

 Examples: 
     > dnorm(0)   ->  [1] 0.3989423
     > pnorm(0)   ->  [1] 0.5
     > qnorm(0.5) ->  [1] 0

//////////////////////////////
"

.C16EXPLAIN9<-"4 R functions student-s distributions
//////////////////////////////
dt(x, df, ncp, log = FALSE)
pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)
qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)
rt(n, df, ncp)

The first letter for those four functions
----------------------------------------
  d    : density function 
  p    : probability 
  q    : inverse
  r    : random number 
Arguments  x, q     vector of quantiles.
           p        vector of probabilities.
           n        number of observations. If length(n) > 1, the 
                       length is taken to be the number required.
           df       degrees of freedom (> 0, maybe non-integer). df = Inf is allowed.
           ncp      non-centrality parameter delta; currently except for rt(), only 
                       for abs(ncp) <= 37.62. If omitted, use the central t distribution.
        log, log.p  logical; if TRUE, probabilities p are given as log(p).
        lower.tail  logical; if TRUE (default), probabilities are P[X <= x], 
                       otherwise, P[X > x].

//////////////////////////////
"

.C16EXPLAIN10<-"4 R functions Chisq distributions
//////////////////////////////
dchisq(x, df, ncp = 0, log = FALSE)
pchisq(q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qchisq(p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
rchisq(n, df, ncp = 0)

The first letter for those four functions
----------------------------------------
  d    : density function 
  p    : probability 
  q    : inverse
  r    : random number 

Arguments  x, q      vector of quantiles.
            p        vector of probabilities.
            n        number of observations. If length(n) > 1, the 
                        length is taken to be the number required.
           df        degrees of freedom (non-negative, but can be
                        non-integer).
           ncp       non-centrality parameter (non-negative).
        log, log.p   logical; if TRUE, probabilities p are given 
                        as log(p).
        lower.tail   logical; if TRUE (default), probabilities are 
                        P[X <= x],otherwise, P[X > x].

//////////////////////////////
"
.C16EXPLAIN11<-"4 R functions F-distributions
//////////////////////////////
df(x, df1, df2, ncp, log = FALSE)
pf(q, df1, df2, ncp, lower.tail = TRUE, log.p = FALSE)
qf(p, df1, df2, ncp, lower.tail = TRUE, log.p = FALSE)
rf(n, df1, df2, ncp)

The first letter for those four functions
----------------------------------------
  d    : density function 
  p    : probability 
  q    : inverse
  r    : random number 

Arguments   x, q    vector of quantiles.
            p       vector of probabilities.
            n       number of observations. If length(n) > 1, the length is taken to be the number required.
           df1, df2 degrees of freedom. Inf is allowed.
           ncp      non-centrality parameter. If omitted the central F is abetaumed.
       log, log.p   logical; if TRUE, probabilities p are given as log(p).
       lower.tail   logical; if TRUE (default), probabilities are P[X <= x], otherwise, P[X > x].
        
Details: The F distribution with df1 = n1 and df2 = n2 degrees of freedom has density 
//////////////////////////////
"

.C16EXPLAIN12<-"One sided vs. two sided
//////////////////////////////
Two-tailed test.  
---------------
 Abetaume that our null hypothesis
                     mean(X) =100

 we have two ways to reject this hupthesis:
          1) if mean of x is significantly bigger than 100. 
          1) if mean of x is significantly lebeta than 100. 


One-tailed test.  
---------------
 Abetaume that our null hypothesis
                     mean(X) >100

//////////////////////////////
"
.C16EXPLAIN13<-"Remember two critical values: 2 for a T-value and 5% for a p-value
//////////////////////////////
Rule of thumbs
  If   absolute T-value > 2  -> reject the null hypothesis
                        < 2  -> accept the null hypothesis

  If   the p-value < 5%  reject the null
           p-value > 5%  accept the null    

//////////////////////////////
"

.C16EXPLAIN14<-"Critical values for 4 distributions 
//////////////////////////////
Abetaume that the significant level is 5%

    distribution  n-sided function            value 
     -------      ------  ------ ---          ----------
  1) Normal         2     > qnorm(0.05/2)     -1.959964
  2) Normal         1     > qnorm(0.05)       -1.644854

  3) student-t      2     > qt(0.05/2,60)     -2.000298
  4) student-t      1     > qt(0.05,60)       -1.670649

  5) chidq          2     > qchisq(0.05/2,10)  3.246973
  6) chidq          1     > qchisq(0.05,10)    3.940299

  5) F-dist         2     > qf(0.05/2,10,12)   0.276171
  6) F-dist         1     > qf(0.05,10,12)     0.3432914

//////////////////////////////
"


.C16EXPLAIN15<-"Test of equal distributions 
//////////////////////////////
Here is summary:
Abetaume that we have two distributions 
   frequencyA   frequencyB
   --------     ------
     a             b
     .             .
     .             .
     .             .
     .             .
     .             .


 We estimate squared percentage deviation. 
   For example, for the first one [(a-b)/b] ^2

 Summation of the above squared percentage deviation 
  is compared with the critical value of chiq.inv.rt(alpha, df)

  Decision Rule 

     if sum < chisq(alpha,df)   -> A and B from the same distribution
       
     if sum > chisq(alpha,df)   -> A and B from different distributions

//////////////////////////////
"




.C16EXPLAIN16<-"normality test 
//////////////////////////////
R package fBasics
   ksnormTest      Kolmogorov-Smirnov normality test,
   shapiroTest     Shapiro-Wilk's test for normality,
   jarqueberaTest  Jarque--Bera test for normality,
   dagoTest        D'Agostino normality test.
R package nortest
   adTest          Anderson--Darling normality test,
   cvmTest         Cramer--von Mises normality test,
   lillieTest      Lilliefors (Kolmogorov-Smirnov) normality test,
   pchiTest        Pearson chi--square normality test,
   sfTest          Shapiro--Francia normality test.

  Example #1: The data is drawn from a normal distribution
         set.seed(123)
         x = rnorm(500)
         shapiroTest(x)
         Title: Shapiro - Wilk Normality Test
         Test Results: STATISTIC: W: 0.9981
         P VALUE:0.8639 
 
  Example #2: The data is drawn from a non-normal distribution
         set.seed(333)
         y = rchisq(100,10.12)
         shapiroTest(y)
         Title: Shapiro - Wilk Normality Test
         Test Results: STATISTIC:W: 0.9419
         P VALUE: 0.0002537
          
//////////////////////////////
"

.C16EXPLAIN17<-"t.test()
//////////////////////////////
t.test() Performs one and two sample t-tests on vectors of data. 
Example #1: 
              t.test(1:10, y = c(7:20))      
  Result:
        Welch Two Sample t-test
data:  1:10 and c(7:20)
t = -5.4349, df = 21.982, p-value = 1.855e-05
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -11.052802  -4.947198
sample estimates:
mean of x mean of y 
      5.5      13.5 

Example #2: 
            t.test(1:10, y = c(7:20, 200)) 
        Welch Two Sample t-test
data:  1:10 and c(7:20, 200)
t = -1.6329, df = 14.165, p-value = 0.1245
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -47.242900   6.376233
sample estimates:
mean of x mean of y 
  5.50000  25.93333 

var.test()
-----------
F Test to Compare Two Variances: Performs an F test to compare the 
   variances of two samples from normal populations. 

 Example #1: # Do x and y have the same variance?
            x <- rnorm(50, mean = 0, sd = 2)
            y <- rnorm(30, mean = 1, sd = 1)
            var.test(x, y)
Output is shown below. 
----------------------
        F test to compare two variances
data:  x and y
F = 4.7473, num df = 49, denom df = 29, p-value = 2.708e-05
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 2.385159 8.931669
sample estimates:
ratio of variances 
          4.747311 

chisq_test()
------------
  library(coin)
  davis <- matrix(
       c(3,  6,
       2, 19),
       nrow = 2, byrow = TRUE
  )
  davis <- as.table(davis)
  ## Asymptotic Pearson chi-squared test
  chisq_test(davis)

output
-------
    Asymptotic Pearson Chi-Squared Test

data:  Var2 by Var1 (A, B)
chi-squared = 2.5714, df = 1, p-value = 0.1088
//////////////////////////////
"


.C16EXPLAIN18<-"A list of various distributions 
//////////////////////////////
  dbeta   --> beta distribution   
  dbinom  --> binomial (including Berno1ulli) distribution
  dcauchy --> Cauchy distribution see dcauchy
  dchisq  --> chi-squared distribution
  dexp    --> exponential distribution
  df      --> F distribution
  dgama   --> gamma distribution
  dgeom   --> geometric distribution
              (This is also a special case of the negative binomial.)
  dhyper  --> hypergeometric distribution
  dlnorm  --> log-normal distribution 

  dmultinom --> multinomial distribution
  dnbinom   --> negative binomial distribution 
  dnorm     --> normal distribution
  dpois     --> Poibetaon distribution
  df        --> Student's t distribution
  dunif     --> uniform distribution
  dweibull  --> Weibull distribution 
  
  For lebeta common distributions of test statistics 
      see pbirthday, dsignrank, ptukey and dwilcox 
      (and see the 'See Also' section of cor.test).
 
    https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data/normal-distributions-library/v/introduction-to-the-normal-distribution
//////////////////////////////
"

.C16EXPLAIN19<-"Youtube 
//////////////////////////////

   https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data/normal-distributions-library/v/introduction-to-the-normal-distribution

//////////////////////////////
"

.C16EXPLAIN20<-"Links 
//////////////////////////////
Normal distribution 
-------------------
    https://en.wikipedia.org/wiki/Normal_distribution
    http://mathworld.wolfram.com/NormalDistribution.html
    https://www.mathsisfun.com/data/standard-normal-distribution.html
    http://www.statisticshowto.com/probability-and-statistics/normal-distributions/
    http://stattrek.com/probability-distributions/normal.aspx

Student T-distribution
-------------------
    https://en.wikipedia.org/wiki/Student%27s_t-distribution
    http://stattrek.com/probability-distributions/t-distribution.aspx
    http://www.math.uah.edu/stat/special/Student.html
    http://statweb.stanford.edu/~naras/jsm/TDensity/TDensity.html
    Critical values of a T-distribution 
        http://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm

Uniform distribution
-------------------
    http://mathworld.wolfram.com/UniformDistribution.html
    https://en.wikipedia.org/wiki/Discrete_uniform_distribution
    https://www.mathsisfun.com/data/random-variables-continuous.html
    http://www.r-tutor.com/elementary-statistics/probability-distributions/continuous-uniform-distribution

F-distribution
-------------------
    http://www.math.uah.edu/stat/special/Fisher.html
    http://stattrek.com/probability-distributions/f-distribution.aspx
    https://www.statlect.com/probability-distributions/F-distribution
    Critical F-tables
        http://www.socr.ucla.edu/Applets.dir/F_Table.html

Chi-square distribution
-------------------
    https://en.wikipedia.org/wiki/Chi-squared_distribution
    http://stattrek.com/probability-distributions/chi-square.aspx
    http://mathworld.wolfram.com/Chi-SquaredDistribution.html
    https://onlinecourses.science.psu.edu/stat414/node/148

//////////////////////////////
"

# P-value using =chitest(realized, expected), or chiq.test()
.chapter17<-function(i){
" i  Chapter 17: Capital structure in a perfect world 
  -  -------------------------------------
  1  What is capital structure? 
  2  Definition of a 'perfect market'
  3  Objectives of a firm
  4  WACC (Weighted Average Cost of Capital)
  5  WACC with tax 
  6  Fiduciary responsibilities 
  7  Agency problem 
  8  M&M proposition 
  9  M&M view #1
 10  M&M view #2
 11  M&M proof 
 12  Graphs
 13  Perfect market abetaumption provides 2 espects 
 14  Non-financial liabilities 
 15  Important: 
 16  Average cost vs. marginal cost 
 17  Firm value = project value + Financing value 
 18  Important: 
 19  Youtubes 
 20  Links 
 
 Example #1:>.c17    # see the above list
 Example #2:>.c17(1) # see the 1st explanation

";.chapter17_(i)}

.n17chapter<-20

.chapter17_<-function(i){
    .printEachQ(17,i,.n17chapter)
}

.c17<-.chapter17

.C17EXPLAIN1<-"What is Capital Structure
/////////////////////////////////
 The capital structure is how a firm finances its overall
     operations and growth by using different sources of 
     funds.  Debt comes in the form of bond ibetaues or long-term
     notes payable, while equity is clabetaified as common stock, 
     preferred stock or retained earnings. Short-term debt such 
     as working capital requirements is also considered to be 
     part of the capital structure.

        https://www.investopedia.com/terms/c/capitalstructure.asp

/////////////////////////////////
"

.C17EXPLAIN2<-"  2  Definition of a 'perfect market'
/////////////////////////////////
 A perfect 'world' or a 'perfect market' is defined as

   1) No opinion difference

   2) No transaction costs

   3) No taxes

   4) Many buyers and sellers

/////////////////////////////////
"

.C17EXPLAIN3<-"Objectives of a firm
/////////////////////////////////
What is the objective for a firm?

  1) Maximizing a firm's sale

  2) Maximizing a firm's net income

  3) Maximizing a firm's market share 

  4) Maximizing a firm's growth rate 

  5) Maximizing a firm's number of shares 

  6) Maximizing a firm's market value 

  7) Maximizing a firm's equity price 

  8) Maximizing a firm's total value 

  9) Maximizing a firm employee's benefits

  10) Others 

/////////////////////////////////
"


.C17EXPLAIN4<-"WACC (Weighted Average Cost of Capital)
/////////////////////////////////
 WACC weighted Average of Cost of Capital 

    Rc =  W_debt *R_debt  +  W_equity*R_equity 

    Rc       : cost of capital 
    W_debt   : Weight of debt
    W_equity : Weight of equity 

    R_debt   : cost of debt 
    R_equity : required of return for equity 

/////////////////////////////////
"

.C17EXPLAIN5<-"WACC with tax 
/////////////////////////////////
 WACC weighted Average of Cost of Capital 

    Rc =  W_debt *R_debt *(1-t)  +  W_equity*R_equity 

    Rc       : cost of capital 
    W_debt   : Weight of debt
    W_equity : Weight of equity 

    R_debt   : cost of debt 
    R_equity : required of return for equity 

    t        : corporate tax 

/////////////////////////////////
"

.C17EXPLAIN6<-"Fiduciary responsibilities 
/////////////////////////////////
 A fiduciary is responsible to act only in the best interests of the
    party he was appointed to represent, Cornell University explains. 
    Fiduciaries may not profit from their roles and must avoid any 
    conflict of interest.

 The term fiduciary means an established relationship in which one 
    person appointed to be responsible for the abetaets and money 
    over another person or entity, About.com explains. The term 
    fiduciary is a Latin word that means \"trust\" or \"faith.\"

 The board of directors for a company are also considered fiduciaries, 
    states About.com. Their main responsibilities include avoiding 
    conflicts of interest within the company; acting in the interest
    of the businebeta instead of the member's personal interest; 
    providing oversight to make certain all the businebeta the company
    conducts is legal; and making decisions that best protects the 
    abetaets of the corporation.

  Generally, fiduciaries are appointed or elected because of their knowledge
     or expertise, SFGate explains. It's pobetaible that a fiduciary relationship
     may be set by the terms of a sales agreement, will, trust agreement, or 
     contract to full establish the legal relationship. Generally the establishment
     of the relationship outlines the specific duties of the fiduciary, the 
     compensation, if any, he is to receive, and any recourse if the fiduciary
     violates the terms of the document.

  https://www.reference.com/article/fiduciary-responsibility-ee5a2254395cca06?aq=fiduciary+responsibilities&qo=cdpArticles
/////////////////////////////////
"
.C17EXPLAIN7<-"Agency problem 
/////////////////////////////////
 agency problem
   A conflict arising when people (the agents) entrusted to look after 
   the interests of others (the principals) use the authority or power 
   for their own benefit instead.

   It is a pervasive problem and exists in practically every organization
   whether a businebeta, church, club, or government. Organizations try to 
   solve it by instituting measures such as tough screening procebetaes, 
   incentives for good behavior and punishments for bad behavior, watchdog
   bodies, and so on but no organization can remedy it completely because 
   the costs of doing so sooner or later outweigh the worth of the results.
      http://www.businebetadictionary.com/definition/agency-problem.html

 Agency Problem
    A situation in which agents of an organization (e.g. the management)
    use their authority for their own benefit rather than that of the 
    principals (e.g. the shareholders). The agency problem also refers 
    to simple disagreement between agents and principals. For example, 
    a publicly-traded company's board of directors may disagree with 
    shareholders on how to best invest the company's abetaets. It especially
    applies when the board wishes to invest in securities that would favor
    board members' outside interests.
       https://financial-dictionary.thefreedictionary.com/Agency+problem
/////////////////////////////////
"

.C17EXPLAIN8<-"M&M proposition 
/////////////////////////////////////

  The Modigliani-Miller propositions state that in a perfect world, 
      the value of a firm is independent of how it is financed. 

  Instead, it is the underlying projects that determine the 
       value of the firm. 

/////////////////////////////////////
"      
.C17EXPLAIN9<-"M&M view #1
/////////////////////////////////

 M&M view #1: This is simple if we abetaume a fixed investment policy
              for the moment. 

/////////////////////////////////
"
.C17EXPLAIN10<-"M&M view #2
/////////////////////////////////

  M&M view #2: Additivity of projects and financing. 
               Perfect-market financing is zero NPV. 
                   
/////////////////////////////////
"

.C17EXPLAIN11<-"M&M proof 
/////////////////////////////////
 Absence-of-arbitrage: 
    you could get rich if there was a capital structure
    worth $1 more  or $1 lebeta than what the firm is work 
    under th current structure. 

 Abetaume that the value of firm is $100 with 80% of
    equity and 20% of debt. 


////////////////////////////////
"

.C17EXPLAIN12<-"Graphs
/////////////////////////////////

/////////////////////////////////
"
.C17EXPLAIN13<-"Perfect market abetaumption provides 2 espects 
/////////////////////////////////
 Perfect market abetaumption provides 2 espects important to the M&M argument:

   1) The capital market is perfectly elastic. All financial cliams that 
      the firm could dream up would be snatched up by a perfect capital 
      market at an appropriate price. 

    2) There is no link between the firm's operations and the financial
       claims that a firm is able to ake on. (in the original M&M paper,
       the authors abetaumed that all operating decision were already made). 

/////////////////////////////////
"

.C17EXPLAIN14<-"Steps of Hypothesis Testing
/////////////////////////////////
  Step 1. Develop the null and alternative hypotheses.

  Step 2. Specify the level of significance alpha.

  Step 3. Collect the sample data and compute the value 
          of the test statistic.

          p-Value Approach

  Step 4. Use the value of the test statistic to compute the p-value.
  Step 5. Reject H0 if p-value < alpha
 
          Critical Value Approach

  Step 4. Use the level of significance a to determine the critical 
          value and the rejection rule.
  Step 5. Use the value of the test statistic and the rejection 
          rule to determine whether to reject H0.

/////////////////////////////////
"



.C17EXPLAIN16<-"Average cost vs. marginal cost 
/////////////////////////////////

 Average cost is the total cost divided the number of product. 

 Marginal cost is the cost by adding one extra product. 

/////////////////////////////////
"
.C17EXPLAIN17<-"Firm value = project value + Financing value 
/////////////////////////////////

    Firm value = project value + Financing value 

/////////////////////////////////
"
.C17EXPLAIN18<-"Important: 
/////////////////////////////////
 1) The M&M proposition is helpful for thinking abut the 
    devision of claims into debt and equity. This is because
    the markets for raiging fianceing throught these claims are 
    fairly perfect, and the firm pays for prices eight ways. 

 2) Thus, for finanical claims, managers can think about financing 
    and operaiton choices separtaely. 

 3) The M&M propostion is lebeta helpful for thinking abou the division 
    of claims between financial and non-finanicl liabilities. This is 
    becuase the markets for raising financing through non-financial 
    liabiliteis are rarely perfect. Such financing, e.g., trade credit 
    or delayed tax payments, often offer better deals but are available 
    only together with certain project choices. 

 4) Thus, for non-financial claims, managers need to think about financing 
    and opertional choices together. 

/////////////////////////////////
"

.C17EXPLAIN19<-"Youtubes 
/////////////////////////////////

 Marketplace APM, 2009, Capital structure explained
   (v143k,s62k,t6:42)
    https://www.youtube.com/watch?v=6uB1eWJz9jI

 Openmichigan,2009, Capital structure
    (v64k,s25k,t43:32)
     https://www.youtube.com/watch?v=s5QrYrv7bWY
 
  Khan Academy, 2011, Basic capital structure differences
     (v144k,s4.9m,t4:00)
     https://www.youtube.com/watch?v=YEZMReBbkP0

/////////////////////////////////
"
.C17EXPLAIN20<-"Links 
/////////////////////////////////
 Businebeta Dictionary, Agency problem
      http://www.businebetadictionary.com/definition/agency-problem.html

 CFI, Capital structure   
     https://corporatefinanceinstitute.com/resources/knowledge/finance/capital-structure-overview/

 Farlex, Agency problem 
     https://financial-dictionary.thefreedictionary.com/Agency+problem

 Investpedia, Capital Structure 
     https://www.investopedia.com/terms/c/capitalstructure.asp

/////////////////////////////////
"
.chapter2<-function(i){
" i  Chapter 2:Present value
  -  -------------------------------------
  1  Perfect Markets 
  2  Notation
  3  Small notes
  4  Rate of returns 
  5  A time line 
  6  Two formulae [FV=   PV= ]
  7  Excel sign convention 
  8  Excel pv() formula 
  9  Examples for the Excel pv() function 
 10  FV value definition 
 11  Excel fv() function 
 12  Definition of NPV (Net Present Value) and NPV rule 
 13  Excel npv() is actually a pv function
 14  VBA 4 a true NPV function 
 15  Logic for the NPV rule
 16  Total return formula
 17  APR, EAR
 18  Excel effect() function
 19  YouTube 
 20  Links 

 Example #1:> .c2    # get the above list
 Example #2:> .c2(1) # see the first explanation

";.chapter2_(i)}

.n2chapter<-20
.chapter2_<-function(i){
    .printEachQ(2,i,.n2chapter)
}

.c2<-.chapter2

.C2EXPLAIN1<-"Perfect Markets 
////////////////////////////////
A perfect market must satisfy four abetaumptions:

  1. No differences in opinion. Uncertainty is ok, 
     but everyone must agree to exactly what it is.
     We must not have different information or opinions. 

  2. No taxes.  or government interference or regulation 
     [except perfect property rights]. 

  3. No transaction costs. Neither direct nor indirect. 

  4. No big sellers/buyers. There must always be more where 
     they came from. No (few) investors or firms are special. 
     If investors differ, there must be infinitely many clones competing.

////////////////////////////////
"


.C2EXPLAIN2<-"Notations
////////////////////////////////
Time Convention: 
----------------
    0 = Today, Right Now. 
    1 = Next period (e.g., day, year, etc.) 
    t = some time period (in the future). 
    T = often to denote a final time period. 
   
Flows pertain to something accumulating over a time span, 

  C or CF = cash amount. 
  Ct = instant cash amount at time t. 
  D1, divident at time 1
  D15,20, a row of D (e.g., dividends) from time 15 through 20. 
  Return vs. Net Return vs. Rate of Return. (Interest rate.) 
  r, r1, r15,20, r8: rates of return.

////////////////////////////////
"

.C2EXPLAIN3<-"Small notes 
////////////////////////////////
  This is a bit inconsistent. 

  Dividends are really also paid at one instant in time,
    and thus should not be subscripted like a ?ow. 

  If the investment is a loan, the rate of return 
    is usually called an interest rate. We will 
    (almost always) use the name \"rate of return\" 
    and 'interest rate' interchangeably.  

  Although there is a difference between a return (CF1),
     a net return (CF1-CF0), and a (net) ret of return 
     (CF1-CF0)/CF0, in conversation, it is rarely explicit. 
     Usually, you are abetaumed to know what the speaker means.

////////////////////////////////
"

.C2EXPLAIN4<-"Rate of returns 
////////////////////////////////
 p0, p1, d1
                p1 - p0 + d2
      Return = ----------------
                    p0

                p1-p0      d1
             = -----   +  ---
                 p0        p0

             = Capital gain + dividend
               yield            yield

////////////////////////////////
"

.C2EXPLAIN5<-"A time line 
////////////////////////////////
For many cases, we can use a time-line to illustrate 
  different patterns of our cash flows. 
   1) from left(oldest) to right (newest)
   2) same interval 
   3) can go to infinity 
Case #1:                                 Case #2:
                   c                     c
   |-------|-------|                     |-------|
   0       1       2                     0       1

           c       c       c                    c       c       c -> infinity
   |-------|-------|-------|             |-------|-------|-------|-> 
   0       1       2       3             0       1       2       3 -> infinity

                   c       c       c                     c       c       c
   |-------|-------|-------|-------|     |-------|-------|-------|-------|
 2021    2022   2023     2024   2025     0       1       2       3       4

Abetaume that we borrow $100 for two years the annual 
  interest rate is 10%. Below is a time line with cash flows. 
  +100        -10         -(10+100)
   |-----------|-----------|
   0           1           2
////////////////////////////////
"

.C2EXPLAIN6<-"Two formulae [FV=   PV= ]
////////////////////////////////
1) Future value of a given present value

    fv= = pv*(1+R)^n 

     where FV is the future value
           R  is the period rate
           n is the number of periods 
           Note: R and n should be consistent, i.e., with the same frequencies. 


2) Present value for a given future value is 

                                   fv
    pv(one future cash flow)=  ----------
                                (1 + R) ^n

////////////////////////////////
"

.C2EXPLAIN7<-"Excel sign convension 
////////////////////////////////
  positive future value  -- > negative present value 
  negative future value  -- > positive present value 
  positive present value -- > negative future value 
  negative present value -- > positive future value 

There are two ways to explain the Excel sign conversion. 

1) Accounting approach
      Cash inflows (+) vs cash outflows (-). 

 Example #1: we deposit $100 for 2 year. If the annual interest 
             rate is 10%, how much is the value 2 years later?
             When deposit $100, it is a cash output, i.e., -100
            =fv(0.1,2,0,-100)   => 121  (cash inflow, i.e., a positive value)

 Example #1: we borrow $100 for 2 year. If the annual interest 
             rate is 10%, how much we have to payback 2 years later?
             When borrowing, it is a cash inflow, i.e., +100
            =fv(0.1,2,0,100)   => -121  (cash outflow, i.e., a negative value)

2) Excel is designed this way

////////////////////////////////
"

.C2EXPLAIN8<-"Excel pv() function 
////////////////////////////////
Input format    =pv(rate,nper,pmt,[fv][type])

 Case #1: pmt=0, fv not =0
          present value of one future cash flow
          pv=fv/(1+R)^n 

 Example #1: We will receive $100 in 2 years. If the annual 
             interest rate is 10%, how much is the equivalent value today?
         
         =pv(0.1,2,0,100) 

         ==> 82.64

////////////////////////////////
"

.C2EXPLAIN9<-"Examples for the Excel pv() function 
////////////////////////////////
  In year 5, the future value is $100.
  What is its present value if the annual rate is 4%?

////////////////////////////////
"

.C2EXPLAIN10<-"fv value definition 
////////////////////////////////
Future value of one present value 

     fv = pv * (1+R)^n 

   pv                                        fv
   |-----------|-----------|--------|--------|
   0           1           2                 n

////////////////////////////////
"

.C2EXPLAIN11<-"Excel fv function 
////////////////////////////////
Input format    =fv(rate,nper,pmt,[pv][type])

pmt=0, pv not =0  ==> future value of one present value 

          fv=pv * (1+R)^n 

 Example #1: we deposit $100 for 2 year. If the annual interest 
             rate is 10%, how much is the value 2 years later?
             When deposit $100, it is a cash output, i.e., -100
             =fv(0.1,2,0,-100)   => 121  (cash inflow, i.e., a positive value)

////////////////////////////////
"

.C2EXPLAIN12<-"Definition of NPV (Net Present Value) and NPV rule 
////////////////////////////////
Definition of NPV (Net Present Value)
-------------------------------------
Method I: 
           NPV = PV(all benefits) - PV(all costs)

Method II: 
          if cash outflow is defined as a negative value
             cash inflow  is defined as a positive value

          NPV = PV(all cash flows)

 NPV Rule: for an independent project
        if NPV(Project) > 0 accept

        if NPV(Project) < 0 reject

////////////////////////////////
"

.C2EXPLAIN13<-"Excel npv() is actually a pv function
////////////////////////////////
Example 1: 

    If We invest $100 today and will get $120 at the end of year one. 
    if the discount rate is 10%, what is the NPV?

   1) Manually calculate the result =(120)/(1+0.1) -100 = 9.090909091
 
   2) Using the NPV function()

        we enter the following two values at A1 and A2
           -100
            120

           =NPV(0.1,A1:A2)   ==> 8.26 

     The correct formula should be 

           =NPV(0.1,A2)+A1   ==> 9.09 
Example 2: 
time cash flow
0   -100
1    40
2    30
3    40
4    20
5   -10

///////////////////////////////////////////////
"

.C2EXPLAIN14<-"VBA 4 a true NPV function 
///////////////////////////////////////////////
Step 1: copy the following two functions (below ------- )
Step 2: Launch Excel and click on 'Developer' on the menu bar
Step 3: Click Visual Basic [on the left]
Step 4: click Insert [on the menu bar], 'Module' and paste 
Step 5: click 'File' and 'Close and return to Microsoft Excel'
---------------------------------

Function npvTRUE(rate As Double, cashFlows As Range) As Variant
    npvTRUE = Application.NPV(rate, cashFlows) * (1 + rate)
End Function

Function npvTRUEhelp() As String
  npvTRUEhelp = \"usage: =npvTRUE(rate,cashFlows)\"
End Function

///////////////////////////////////////////////
"

.C2EXPLAIN15<-"Logic for the NPV rule 
///////////////////////////////////////////////
 The logical foundation of the NPV Rule Here is how a 
     perfect world w/o uncertainty must work: 

   The NPV rule is optimal (other rules leave money on the table), 
   and positive NPV projects must be scarce, The proof is trivial. 
   For example, presume that, in our perfect market, you can borrow
   or lend money at 8% anywhere today. The NPV formula says you will
   not make money on projects that cost $1 today and yield $1.08 next year.

   It says you should take all projects that yield more than $1.08 
      next year. Now, presume that you have (infinitely) many investment
      opportunities that cost $0.99 and yield $1.08. (The NPV is positive.)

   How would you get rich? Borrow $0.99 and use it to buy the project. 
      Tomorrow, you pay $1.07, and receive $1.08. You earn $0.01. 
      If you prefer money today, borrow against the $0.01, or borrow
      $1.00 to begin with. If such projects are in limited supply, 
      you (and everyone else) would buy up all such projects, until
      the project's equilibrium price has increased to make the 
      project zero NPV. (If you can short projects, and you have
      willing buyers for negative NPV projects, you can just sell
      them and thereby invert the argument.)

///////////////////////////////////////////////
"

.C2EXPLAIN16<-"Total return formula
///////////////////////////////////////////////

 There are several ways to estimate the total returns. 

     Method I: Abetaume that we have the 'adjusted' prices, 
               shown below. P0 could be viewed as our 
               initial investment. 

               |----------|---------|  ......      |
               p0         p1       p2  ......     pn
                            pn - p0      pn
          R(total return) = --------  =  --  -1
                             p0          p0
     When a set of returns are given, then we could abetaume p0=1 and 
          estimate p1, p2 and pn. Then apply the above formula. For example, for a 
          three periods, R1, R2 and R3. Abetaume p0 =1, then p3 = 1(1+R1)(1+R2)(1+R3). 
          Total return= pn/p0 -1
         
   Method II: Total return is the product of 1+R(i). 
                 Total return = (1+R2)(1+R2) * ... * (1+Rn)-1

   Method III: apply the Excel product to 1+Ri
               Abetaume that we have a column of Ri
               Step 1: generate another column 1+R1, 1+R2, ....
               Step 2: apply =product(  ) -1
             
///////////////////////////////////////////////
"

.C2EXPLAIN17<-"APR, EAR
///////////////////////////////////////////////

    APR stands for Annual Percentage Rate 

    EAR stand for Effective Annual Rate

    There are two ways to estimate a EAR for a given APR:

  Method #1: Apply the Excel effect() function. 
             For example, if APR is 10%, compounded 
             semiannually, what is its corresponding EAR?

            =effect(0.1,2)    --> 0.1025

  Method #2: Apply the following formula
                          APR
                 EAR= (1+ --- ) ^n   -1
                           n
             For the above example, APR=0.1, n=2
                  EAR = (1+0.1/2)^2-1  = 0.1025
             
///////////////////////////////////////////////
"

.C2EXPLAIN18<-"Excel effect() function
/////////////////////////////////////

 The Excel effect() function is used to calculate
      an effective rate when an APR (Annual Percentage 
      Rate) and its compounding frequency are given. 

     =effect(nominal_rate, npery)

      nominal_rate: a given APR (Annual Percentage Rate)
         npery   : compounding frequency per year.

  Example #1: =effect(0.1, 2)    ->  0.1025

  Example #2: =effect(0.075,12)  ->  0.077632599


/////////////////////////////////////
"

.C2EXPLAIN19<-"YouTube 
///////////////////////////////////////////////
 FNCE311: chapter 2: Time value of money
      https://youtu.be/uOYT1WXdwX8

 Excel tutorial: Present value (PV) in excel 2010 (v115k,s10k,t4:1)
     https://www.youtube.com/watch?v=C3huNohGo0g

 TeachExcel,2009,Finance Basics 6 - Present Value Examples in Excel - How much something is worth today. (v70k,s79k,t7:49)
       https://www.youtube.com/watch?v=J4J5o-1JM24

///////////////////////////////////////////////
"

.C2EXPLAIN20<-"Links 
///////////////////////////////////////////////
 Time Value of Money - TVM
     https://www.investopedia.com/terms/t/timevalueofmoney.asp

 Time value of Money 
    https://www.msn.com/en-us/money/tools/timevalueofmoney

////////////////////////////////
"

.chapter20<-function(i){
" i  Chapter 20: R basics (optional)
  -  -------------------------------------
  1  From where to download R
  2  How to launch and quit R
  3  Comment line and comment paragraph 
  4  3 ways to abetaign a value/values & how to show its value
  5  Use up and down arrow keys to recall the previous commands 
  6  R is case sensitive 
  7  Normal operations: +, -, *, /, and ^ (power) 
  8  listing function ls()
  9  remove a variable or several variables 
 10  remove all variables 
 11  use meaningful variable names 
 12  current working directory 
 13  head() and tail() functions
 14  mean() for calculating mean and sd() for standard deviation 
 15  put several commands on one line
 16  the simplest function 
 17  use .nLetterFunctions(3) to show all 3-letter functions
 18  use help() to find information for a given function 
 19  several R commands
 20  Links

 Example #1:>.c20    # see the above list
 Example #2:>.c20(1) # see the first explanation

";.chapter20_(i)}

.n20chapter<-20

.chapter20_<-function(i){
    .printEachQ(20,i,.n20chapter)

}
.c20<-.chapter20

.C20EXPLAIN1<-"From where to download R
////////////////////////////////
To install R, we have the following steps:

  Step 1: go to http://r-project.org

  Step 2: click \"CRAN\" on the left
  
  Step 3: choose a server nearby

  Step 4: choose appropriate type such as Windows, Mac

  Step 5: download \"Base\"

///////////////////////////////
"

.C20EXPLAIN2<-"How to launch and quit R
////////////////////////////////

  There are several ways to quit R

  1) type q()

  2) click \"File\" -> \"Quit\"

  3) click the red x on top right

 Note: after type q(), you will be asked \"Keep the objectives\".

   If you want to keep your variables or functions, answer \"yes\".
   Otherwise, no. 

///////////////////////////////
"

.C20EXPLAIN3<-"Comment line and comment paragraph 
////////////////////////////////
A good comment would make your program more readable


Method 1:Anything after # will be a command

   > pv=10   # pv is for present value


Method II: a pair of double quotation marks


////////////////////////////////
"


.C20EXPLAIN4<-"3 ways to abetaign a value/values and how to show its value
////////////////////////////////
Three methods: 

  Method I:  >pv=100

  Method II: >r<-0.1

  Method III:>10->n 

  To show the value of a variable, type its name

    > pv=100
    > pv
      [1] 100

///////////////////////////////
"

.C20EXPLAIN5<-"Use up and down arrow keys to recall the previous commands 
////////////////////////////////

 We could use up and down arrow keys to recall 
    our previous commands. 

 Thus, we could save time by recalling the previous command and modify it a little bit. 

  > pv= 100
  > r = 0.1
  > n = 2
  > fv_f(pv,r,n)
     [1] 121

  > pv= 200
  > fv_f(pv,r,n)
    [1] 242
  > 

///////////////////////////////
"

.C20EXPLAIN6<-"R is case sensitive 
////////////////////////////////
Case sensitive means that pv is different from PV

  > pv=100

  > PV
    Error: object 'PV' not found

  > 

///////////////////////////////
"

.C20EXPLAIN7<-"Normal operations: +, -, *, /, and ^ (power) 
////////////////////////////////
  The normal simple operations will remain the same 

    > 1+5/2*15 -4^2

       [1] 22.5

///////////////////////////////
"

.C20EXPLAIN8<-"listing function ls()
////////////////////////////////
To list all variable for functions, we use the ls()

Example #1: Abetaume that we have nothing, see below. 

    > ls()
      character(0)
    >

Example #2: 

    > pv<-100
    > r<-0.1
    > n<-5
    > ls()
        [1] \"n\"  \"pv\" \"r\" 
    > 

///////////////////////////////
"

.C20EXPLAIN9<-"remove a variabie or several variables
////////////////////////////////

 1) To remove a variable, we use the rm() function 

    >rm(pv)

 2) To remove two variables such as pv and r, 

    >rm(pv,r)

////////////////////////////////
"


.C20EXPLAIN10<-"remove a variabie or several variables or all 
////////////////////////////////
To remove all variables, we ibetaue the following codes

    >rm(list=ls())

////////////////////////////////
"

.C20EXPLAIN11<-"using meaningful variables names 
////////////////////////////////
When using meaningful names, the program is easy to understand. 

    >pv=100

    >r=0.1

    >n=2

    > pv*(1+r)^n
        [1] 121

///////////////////////////////
"
.C20EXPLAIN12<-"current working directory 
////////////////////////////////
To find out the current working directory, we use getwd()

  >getwd()

To change the current working directory, we use setwd()

  >setwd(\"c:/temp\")

///////////////////////////////
"



.C20EXPLAIN13<-"head() and tail() functions 
////////////////////////////////

   > set.seed(123)

   > x=rnorm(100)

   > head(x)
      [1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774  1.71506499

   > tail(x,2)
     [1] -0.2357004 -1.0264209

///////////////////////////////
"

.C20EXPLAIN14<-"mean() for mean  and sd() for standard deviation 
////////////////////////////////

   > set.seed(123)

   > x=rnorm(100)

   > mean(x)
     [1] 0.09040591

sd() for estimating standard deviation 
    
    > set.seed(123)

    > ret<-rnorm(100)

    > sd(ret)
      [1] 0.9128159

////////////////////////////////
"

.C20EXPLAIN15<-"put several command lines together
////////////////////////////////

  We use semicolon to separate them

     > x<-10;y<-20         # several commands together           

///////////////////////////////
"


.C20EXPLAIN16<-"the simplest function 
////////////////////////////////
Here is one line function for the present value

 Example #1: double any input value

       dd=function(x)2*x

   dd is the function name
   function is the keyword
   x in the parentheses is the input value
   2*x is the output put

    > dd(2.3)
      [1] 4.6

 Example #2: 

  >pv_function<-function(fv,r,n)fv/(1+r)^n

  >pv_funtion(100,0.1,1)

   [1] 90.90909

///////////////////////////////
"

.C20EXPLAIN17<-"use .nLetterFunction() to show all n-letter functions
////////////////////////////////

  To see how to use this function, just type its name

  >.nLetterFunctions

  To find out all embedded functions with just 3-letter long

  > .nLetterFunctions(3)
    [1] \"$<-\" \"%*%\" \"%/%\" \"%o%\" \"%x%\" \".gt\" \":::\" \"@<-\" \"[<-\" \"<<-\" \"abs\" \"acf\"
   [13] \"adv\" \"AIC\" \"all\" \"any\" \"aov\" \"Arg\" \"ave\" \"BIC\" \"bmp\" \"BOD\" \"box\" \"bxp\"
   [25] \"c10\" \"c11\" \"c12\" \"c13\" \"c14\" \"c15\" \"c16\" \"c17\" \"c18\" \"c19\" \"c20\" \"c21\"
   [37] \"c22\" \"c23\" \"c24\" \"c25\" \"c26\" \"c27\" \"cat\" \"ccf\" \"cls\" \"co2\" \"CO2\" \"col\"
   [49] \"con\" \"cor\" \"cos\" \"cov\" \"cut\" \"det\" \"dim\" \"dir\" \"e10\" \"e11\" \"e12\" \"e13\"
   [61] \"e14\" \"e15\" \"e16\" \"e17\" \"e18\" \"e19\" \"e20\" \"e21\" \"e22\" \"e23\" \"e24\" \"e25\"
   [73] \"e26\" \"e27\" \"end\" \"exp\" \"fft\" \"fix\" \"for\" \"get\" \"ggf\" \"glm\" \"hat\" \"hcl\"
   [85] \"hsv\" \"IQR\" \"lag\" \"lcm\" \"log\" \"mad\" \"Map\" \"max\" \"min\" \"Mod\" \"new\" \"nlm\"
   [97] \"nls\" \"npk\" \"Ops\" \"par\" \"pdf\" \"pie\" \"PIN\" \"png\" \"ppr\" \"raw\" \"rep\" \"ret\"
  [109] \"rev\" \"rgb\" \"rle\" \"row\" \"rug\" \"seq\" \"sin\" \"betaD\" \"stl\" \"str\" \"sub\" \"sum\"
  [121] \"svd\" \"svg\" \"tan\" \"tar\" \"try\" \"tsp\" \"ttt\" \"unz\" \"url\" \"var\" \"x11\" \"X11\"
  [133] \"xor\" \"zip\"
  > 

///////////////////////////////
"

.C20EXPLAIN18<-"Using help() function 
////////////////////////////////
 For example, we want to know more about the mean() function 

 > help(mean)


///////////////////////////////
"

.C20EXPLAIN19<-"Summary: several R commands
////////////////////////////////

   just type
  
   >severalRcommands

///////////////////////////////
"


.C20EXPLAIN20<-"Links 
////////////////////////////////
Home page for R
     http://r-project.org

///////////////////////////////
"


.C20EXPLAIN212<-"100 random numbers from a standard normal distribution 
////////////////////////////////

 To generate 100 random numbers from a standard 
      normal distribution we use

   > ret<-rnorm(100)


///////////////////////////////
"
.C20EXPLAIN213<-"to generate the same random numbers we use seed() function 
////////////////////////////////
If the same seed is used, we would get the same random numbers

   > set.seed(123)

   > x=rnorm(10)

   > x
       [1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774  
       [6]  1.71506499  0.46091621 -1.26506123 -0.68685285 -0.44566197
   
///////////////////////////////
"
.chapter21<-function(i){
" i  Chapter 21: Pro Forma Financial Statements
  -  -------------------------------------
  1  Goal and logic 
  2  
  3  
  4  
  5  
  6  
  7  
  8  
  9  
 10  
 11  
 12  
 13  
 14  
 15  
 16  
 17  
 18  
 19  Youtube 
 20  Links

 Example #1:>.c21     # find out the list 
 Example #2:>.c21(1)  # see the first explanation 

";.chapter21_(i)}

.n16chapter<-20

.chapter21_<-function(i){
    .printEachQ(21,i,.n16chapter)
}

.c21<-.chapter21

.C21EXPLAIN1<-"Goal and logic 
//////////////////////////////

 Pro formas re more detailed than simple cash flow projectins. 

 This focus helps you think about the economics of businebeta. 

//////////////////////////////
"

.C21EXPLAIN2<-"density distribution vs. cumulative density function
//////////////////////////////
Cumulative density is actually cumulative properties.

 Case #1: Tobeta a dice with values from 1 to 6           
             Each number has 1/6 probability                
             What is the prob. to get a number lebeta than 4?  
                      1/6 + 1/6 + 1/6 = 3/6 =1/2                
             1/6 is probability of each number, while           
             1/2 is the cumulative probability (distribution) 
 
  Case #2: uniform distribution: abetaume density function is 1/a and choose a=5    
            from 1 to 5, the density is 1/5. total sum is 5*1/5 =1                               
            what does it mean that the density function is 1/5 (0.2)?                              
            Take a value between 0 and 5, such as x=1.5 and choose a small number 
            about called deltaX. The probability that a random number falls into  
               this small strip = f(x) * deltaX= 0.2*detlaX   

//////////////////////////////
"

.C21EXPLAIN3<-"Formula for a normal distributions
//////////////////////////////
 The normal distribution is a probability distribution that abetaociates 
    the normal random variable X with a cumulative probability. 
    The normal distribution is defined by the following equation:
                           1                                     
           f(x) = ---------------- * exp(-0.5 *[(x-mean)/(sigma))]^2)               
                 sqrt(2*pi*sigma^2)                                

The standard normal distribution is defined by the following equation: 
-------------------------------
                       1                                     
           f(x) = --------- * exp(-0.5 *x^2)               
                   sqrt(2*pi)                                

    where f(x) is the density function, x is the input
       pi is 3.1415926

 Manually, we could calculate a few values. 
    x=0    -> f(x) = 1/sqrt(2*3.1415925) ->  0.3989423

    x=1    -> f(1) = 1/sqrt(2*3.1415926)*exp(-0.5)          ->   0.2419707  
    x=-1    -> f(-1) = 1/sqrt(2*3.1415926)*exp(-0.5*(-1)^2) ->   0.2419707

//////////////////////////////
"

.C21EXPLAIN4<-"Draw a graph for the standard normal distribution 
//////////////////////////////
x<-seq(-3,3,0.1)
y<-dnorm(x)
plot(x,y)


//////////////////////////////
"
.C21EXPLAIN5<-"What is an inverse function?
//////////////////////////////
  + and -   are pair
                       A+2 =  C   -> A= C -2 
  * and \  are a pair
                       A*10 = C  -> A = c/10

  exp() and log() are pair
                           > a<-exp(2)
                           > a
                             [1] 7.389056 
                           > log(a)
                             [1] 2

//////////////////////////////
"

.C21EXPLAIN6<-"Inverse functions for a standard normal distribution 
//////////////////////////////
For a normal distributio pnorm() and qnorm() are a pair. 

Let's look at cumulative standard normal distribution, pnorm() function 
at 0. This is a cumulative standard normal distribution for a given x. 

  Examples: > pnorm(0)    -->  [1] 0.5
            > pnorm(-2)   -->  [1] 0.02275013
            > pnorm(2)    -->  [1] 0.9772499

For the first one, from 0.5 what is x?
            > qnorm(0.5)         -->   [1] 0
            > qnorm( 0.02275013) -->   [1] -2
            > qnorm(0.9772499)   -->   [1] 2.000001

//////////////////////////////
"


.C21EXPLAIN7<-"Significance level vs. confidence level 
//////////////////////////////
    Confidence level = 1 - significance level 
//////////////////////////////
"
.C21EXPLAIN8<-"4 R functions for a standard/cumulative normal distributions
//////////////////////////////
dnorm(x, mean = 0, sd = 1, log = FALSE)
pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
rnorm(n, mean = 0, sd = 1)

The first letter for those four functions
----------------------------------------
  d    : density function 
  p    : probability 
  q    : inverse
  r    : random number 

Arguments
     x, q       vector of quantiles.
     p          vector of probabilities.
     n          number of observations. If length(n) > 1, the length is taken to be the number required.
    mean        vector of means.
      sd        vector of standard deviations.
   log, log.p   logical; if TRUE, probabilities p are given as log(p).
   lower.tail   logical; if TRUE (default), probabilities are P[X <= x] otherwise, P[X >= x].

 Examples: 
     > dnorm(0)   ->  [1] 0.3989423
     > pnorm(0)   ->  [1] 0.5
     > qnorm(0.5) ->  [1] 0

//////////////////////////////
"

.C21EXPLAIN9<-"4 R functions student-s distributions
//////////////////////////////
dt(x, df, ncp, log = FALSE)
pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)
qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)
rt(n, df, ncp)

The first letter for those four functions
----------------------------------------
  d    : density function 
  p    : probability 
  q    : inverse
  r    : random number 
Arguments  x, q     vector of quantiles.
           p        vector of probabilities.
           n        number of observations. If length(n) > 1, the 
                       length is taken to be the number required.
           df       degrees of freedom (> 0, maybe non-integer). df = Inf is allowed.
           ncp      non-centrality parameter delta; currently except for rt(), only 
                       for abs(ncp) <= 37.62. If omitted, use the central t distribution.
        log, log.p  logical; if TRUE, probabilities p are given as log(p).
        lower.tail  logical; if TRUE (default), probabilities are P[X <= x], 
                       otherwise, P[X > x].

//////////////////////////////
"

.C21EXPLAIN10<-"4 R functions Chisq distributions
//////////////////////////////
dchisq(x, df, ncp = 0, log = FALSE)
pchisq(q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qchisq(p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
rchisq(n, df, ncp = 0)

The first letter for those four functions
----------------------------------------
  d    : density function 
  p    : probability 
  q    : inverse
  r    : random number 

Arguments  x, q      vector of quantiles.
            p        vector of probabilities.
            n        number of observations. If length(n) > 1, the 
                        length is taken to be the number required.
           df        degrees of freedom (non-negative, but can be
                        non-integer).
           ncp       non-centrality parameter (non-negative).
        log, log.p   logical; if TRUE, probabilities p are given 
                        as log(p).
        lower.tail   logical; if TRUE (default), probabilities are 
                        P[X <= x],otherwise, P[X > x].

//////////////////////////////
"
.C21EXPLAIN11<-"4 R functions F-distributions
//////////////////////////////
df(x, df1, df2, ncp, log = FALSE)
pf(q, df1, df2, ncp, lower.tail = TRUE, log.p = FALSE)
qf(p, df1, df2, ncp, lower.tail = TRUE, log.p = FALSE)
rf(n, df1, df2, ncp)

The first letter for those four functions
----------------------------------------
  d    : density function 
  p    : probability 
  q    : inverse
  r    : random number 

Arguments   x, q    vector of quantiles.
            p       vector of probabilities.
            n       number of observations. If length(n) > 1, the length is taken to be the number required.
           df1, df2 degrees of freedom. Inf is allowed.
           ncp      non-centrality parameter. If omitted the central F is abetaumed.
       log, log.p   logical; if TRUE, probabilities p are given as log(p).
       lower.tail   logical; if TRUE (default), probabilities are P[X <= x], otherwise, P[X > x].
        
Details: The F distribution with df1 = n1 and df2 = n2 degrees of freedom has density 
//////////////////////////////
"

.C21EXPLAIN12<-"One sided vs. two sided
//////////////////////////////
Two-tailed test.  
---------------
 Abetaume that our null hypothesis
                     mean(X) =100

 we have two ways to reject this hupthesis:
          1) if mean of x is significantly bigger than 100. 
          1) if mean of x is significantly lebeta than 100. 


One-tailed test.  
---------------
 Abetaume that our null hypothesis
                     mean(X) >100

//////////////////////////////
"
.C21EXPLAIN13<-"Remember two critical values: 2 for a T-value and 5% for a p-value
//////////////////////////////
Rule of thumbs
  If   absolute T-value > 2  -> reject the null hypothesis
                        < 2  -> accept the null hypothesis

  If   the p-value < 5%  reject the null
           p-value > 5%  accept the null    

//////////////////////////////
"

.C21EXPLAIN14<-"Critical values for 4 distributions 
//////////////////////////////
Abetaume that the significant level is 5%

    distribution  n-sided function            value 
     -------      ------  ------ ---          ----------
  1) Normal         2     > qnorm(0.05/2)     -1.959964
  2) Normal         1     > qnorm(0.05)       -1.644854

  3) student-t      2     > qt(0.05/2,60)     -2.000298
  4) student-t      1     > qt(0.05,60)       -1.670649

  5) chidq          2     > qchisq(0.05/2,10)  3.246973
  6) chidq          1     > qchisq(0.05,10)    3.940299

  5) F-dist         2     > qf(0.05/2,10,12)   0.276171
  6) F-dist         1     > qf(0.05,10,12)     0.3432914

//////////////////////////////
"


.C21EXPLAIN15<-"Test of equal distributions 
//////////////////////////////
Here is summary:
Abetaume that we have two distributions 
   frequencyA   frequencyB
   --------     ------
     a             b
     .             .
     .             .
     .             .
     .             .
     .             .


 We estimate squared percentage deviation. 
   For example, for the first one [(a-b)/b] ^2

 Summation of the above squared percentage deviation 
  is compared with the critical value of chiq.inv.rt(alpha, df)

  Decision Rule 

     if sum < chisq(alpha,df)   -> A and B from the same distribution
       
     if sum > chisq(alpha,df)   -> A and B from different distributions

//////////////////////////////
"




.C21EXPLAIN16<-"normality test 
//////////////////////////////
R package fBasics
   ksnormTest      Kolmogorov-Smirnov normality test,
   shapiroTest     Shapiro-Wilk's test for normality,
   jarqueberaTest  Jarque--Bera test for normality,
   dagoTest        D'Agostino normality test.
R package nortest
   adTest          Anderson--Darling normality test,
   cvmTest         Cramer--von Mises normality test,
   lillieTest      Lilliefors (Kolmogorov-Smirnov) normality test,
   pchiTest        Pearson chi--square normality test,
   sfTest          Shapiro--Francia normality test.

  Example #1: The data is drawn from a normal distribution
         set.seed(123)
         x = rnorm(500)
         shapiroTest(x)
         Title: Shapiro - Wilk Normality Test
         Test Results: STATISTIC: W: 0.9981
         P VALUE:0.8639 
 
  Example #2: The data is drawn from a non-normal distribution
         set.seed(333)
         y = rchisq(100,10.12)
         shapiroTest(y)
         Title: Shapiro - Wilk Normality Test
         Test Results: STATISTIC:W: 0.9419
         P VALUE: 0.0002537
          
//////////////////////////////
"

.C21EXPLAIN17<-"t.test()
//////////////////////////////
t.test() Performs one and two sample t-tests on vectors of data. 
Example #1: 
              t.test(1:10, y = c(7:20))      
  Result:
        Welch Two Sample t-test
data:  1:10 and c(7:20)
t = -5.4349, df = 21.982, p-value = 1.855e-05
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -11.052802  -4.947198
sample estimates:
mean of x mean of y 
      5.5      13.5 

Example #2: 
            t.test(1:10, y = c(7:20, 200)) 
        Welch Two Sample t-test
data:  1:10 and c(7:20, 200)
t = -1.6329, df = 14.165, p-value = 0.1245
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -47.242900   6.376233
sample estimates:
mean of x mean of y 
  5.50000  25.93333 

var.test()
-----------
F Test to Compare Two Variances: Performs an F test to compare the 
   variances of two samples from normal populations. 

 Example #1: # Do x and y have the same variance?
            x <- rnorm(50, mean = 0, sd = 2)
            y <- rnorm(30, mean = 1, sd = 1)
            var.test(x, y)
Output is shown below. 
----------------------
        F test to compare two variances
data:  x and y
F = 4.7473, num df = 49, denom df = 29, p-value = 2.708e-05
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 2.385159 8.931669
sample estimates:
ratio of variances 
          4.747311 

chisq_test()
------------
  library(coin)
  davis <- matrix(
       c(3,  6,
       2, 19),
       nrow = 2, byrow = TRUE
  )
  davis <- as.table(davis)
  ## Asymptotic Pearson chi-squared test
  chisq_test(davis)

output
-------
    Asymptotic Pearson Chi-Squared Test

data:  Var2 by Var1 (A, B)
chi-squared = 2.5714, df = 1, p-value = 0.1088
//////////////////////////////
"


.C21EXPLAIN18<-"A list of various distributions 
//////////////////////////////
  dbeta   --> beta distribution   
  dbinom  --> binomial (including Berno1ulli) distribution
  dcauchy --> Cauchy distribution see dcauchy
  dchisq  --> chi-squared distribution
  dexp    --> exponential distribution
  df      --> F distribution
  dgama   --> gamma distribution
  dgeom   --> geometric distribution
              (This is also a special case of the negative binomial.)
  dhyper  --> hypergeometric distribution
  dlnorm  --> log-normal distribution 

  dmultinom --> multinomial distribution
  dnbinom   --> negative binomial distribution 
  dnorm     --> normal distribution
  dpois     --> Poibetaon distribution
  df        --> Student's t distribution
  dunif     --> uniform distribution
  dweibull  --> Weibull distribution 
  
  For lebeta common distributions of test statistics 
      see pbirthday, dsignrank, ptukey and dwilcox 
      (and see the 'See Also' section of cor.test).
 
    https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data/normal-distributions-library/v/introduction-to-the-normal-distribution
//////////////////////////////
"

.C21EXPLAIN19<-"Youtube 
//////////////////////////////

   https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data/normal-distributions-library/v/introduction-to-the-normal-distribution

//////////////////////////////
"

.C21EXPLAIN20<-"Links 
//////////////////////////////
Normal distribution 
-------------------
    https://en.wikipedia.org/wiki/Normal_distribution
    http://mathworld.wolfram.com/NormalDistribution.html
    https://www.mathsisfun.com/data/standard-normal-distribution.html
    http://www.statisticshowto.com/probability-and-statistics/normal-distributions/
    http://stattrek.com/probability-distributions/normal.aspx

Student T-distribution
-------------------
    https://en.wikipedia.org/wiki/Student%27s_t-distribution
    http://stattrek.com/probability-distributions/t-distribution.aspx
    http://www.math.uah.edu/stat/special/Student.html
    http://statweb.stanford.edu/~naras/jsm/TDensity/TDensity.html
    Critical values of a T-distribution 
        http://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm

Uniform distribution
-------------------
    http://mathworld.wolfram.com/UniformDistribution.html
    https://en.wikipedia.org/wiki/Discrete_uniform_distribution
    https://www.mathsisfun.com/data/random-variables-continuous.html
    http://www.r-tutor.com/elementary-statistics/probability-distributions/continuous-uniform-distribution

F-distribution
-------------------
    http://www.math.uah.edu/stat/special/Fisher.html
    http://stattrek.com/probability-distributions/f-distribution.aspx
    https://www.statlect.com/probability-distributions/F-distribution
    Critical F-tables
        http://www.socr.ucla.edu/Applets.dir/F_Table.html

Chi-square distribution
-------------------
    https://en.wikipedia.org/wiki/Chi-squared_distribution
    http://stattrek.com/probability-distributions/chi-square.aspx
    http://mathworld.wolfram.com/Chi-SquaredDistribution.html
    https://onlinecourses.science.psu.edu/stat414/node/148

//////////////////////////////
"

# P-value using =chitest(realized, expected), or chiq.test()
.chapter3<-function(i){
" i  Chapter 3: Stock & Bond valuation: Annuities/perpetuities 
  -  -------------------------------------
  1  Present value formula for perpetuity 
  2  Present value formula for annuity 
  3  Perpetuity due and Annuity due
  4  PV of growing perpetuity 
  5  PV of growing annuity 
  6  VBA for pvGrowingAnnuity
  7  Definition of NPV (Net Present Value) and NPV rule
  8  Excel npv() is actually a pv function 
  9  Examples of using Excel npv() function 
 10  One-period, two-period models for today's stock price
 11  N-period model (general one) for today's stock price 
 12  What is the Gordon Growth Model (GGM)
 13  Definition of EAR and Excel effect() function 
 14  Excel function for EAR 
 15  Effective period rate 
 16  Mortgage effective monthly rate 
 17  2-step approach for effective rate conversion
 18  Principal and interest components
 19  Videos
 20  Links 

 Example #1:> .c3    # get the above list
 Example #2:> .c3(1) # see the first explanation

";.chapter3_(i)}

.n3chapter<-20
.chapter3_<-function(i){
    .printEachQ(3,i,.n3chapter)
}
.c3<-.chapter3

.C3EXPLAIN1<-"Present value formula for perpetuity 
////////////////////////////////
 The definition of perpetuity: 
      same cash flows at the same interval forever.

 Example #1: 
                          c        c   -> infinity 
   |-------|-------|-------|   ... |
   0       1       2       3           -> infinity 
   
 Example #2:
           c       c      c        c   -> infinity 
   |-------|-------|-------|   ... |
   0       1       2       3           -> infinity 

  When the first cash flow occurs at the end of the 
        first period, we have the following formula 
                     C
  pv(perpetuity) = ------
                     R

  where C is the constant cash flow
        R is the period discount rate

////////////////////////////////
"

.C3EXPLAIN2<-"Present value formula for annuity 
////////////////////////////////
Definition of annuity: same cash flows at the 
                       same interval for n periods
 Example #1: 
                           c       c 
   |-------|-------|-------|   ... |
   0       1       2       3       n
   
 Example #2:
           c       c      c        c
   |-------|-------|-------|   ... |
   0       1       2       3       n

 When cash flows happen at the end of each period and
      the first cash flow happens at the end of the first period
                 C                 1
   pv(annuity)= ---- * [1 -    -------- ]
                 R             (1+R)^n

   where C is the period cash flow
         R is the period discount rate
         n is the number of periods

////////////////////////////////
"

.C3EXPLAIN3<-"Perpetuity due
////////////////////////////////
For normal perpetuity, each cash flow would 
     happen at the end of each period. 

For perpetuity due, each cash flow would 
     happen at the beginning of each period. 
                       C
  PV(perpetuity due) = ---  * (1+R)
                       R
Annuity due
----------------
For normal annuity, each cash flow would 
     happen at the end of each period. 

For annuity due, each cash flow would 
     happen at the beginning of each period. 

There are two ways to calculate present (future) value of annuity due. 
  Method I: choose type=1 when use Excel pv() or fv() functions
          =pv(rate,nper,pmt,fv,1)           
          =fv(rate,nper,pmt,pv,1)           

  Method 2: try annuity as normal annuity, then type your result by (1+R)
         pv(annuity due) = pv(annuity)* (1+R)
         fv(annuity due) = fv(annuity)* (1+R)

////////////////////////////////
"

.C3EXPLAIN4<-"PV of growing perpetuity 
////////////////////////////////
Time line
          c       c(1+g)  c(1+g)^2    
   |------|--------|--------|-------|   ...      |   ---> inf
          1        2        3                    n   ---> inf
                             C
  PV(growing perpetuity) = ------
                            R-g
   where c: the first cash flow at the end of the first period
         R: discount rate
         g: growth rate 

   Condition: R>g

////////////////////////////////
"

.C3EXPLAIN5<-"PV of a growing annuity
/////////////////////////////
Time line
          c       c(1+g)  c(1+g)^2    
   |------|--------|--------|-------|   ...      |
          1        2        3                    n  
                        c         (1+g)^n
 pv(growing annuity) = --- [ 1 - --------   ]
                       R-g        (1+R)^n 

     c: first cash flow happening at the end of the first period
     R: discount rate
     g: growth rate 
     n: number of periods 
        Condition: R> g

////////////////////////////////
"

.C3EXPLAIN6<-"VBA for pvGrowingAnnuity
/////////////////////////////

Function pvGrowingAnnuity(C As Single, R As Single, g As Single, n As Integer) As Single
' Estimtae the fresent value of a growing annuity
' by Yuxing.yan@canisius.edu    3/1/2016
'  C : the first cash flow at the end of the first period
'  R : the discount rate
'  g : the period growth rate
'  n : the number of periods
     pvGrowingAnnuity = C / (R - g) * (1 - ((1 + g) / (1 + R)) ^ n)
End Function

Function pvGrowingAnnuityhelp() As String
  pvGrowingAnnuityHelp = \"usage: =pvGrowingAnnuity(C,R,g,n)\"
End Function

/////////////////////////////
"

.C3EXPLAIN7<-"Definition of NPV (Net Present Value) and NPV rule 
////////////////////////////////
Method I: 
           NPV = PV(all benefits) - pv(all costs)
Method II: 
          if cash outflow is defined as a negative value
             cash inflow  is defined as a positive value

          NPV = PV(all cash flows)

  NPV Rule: for an independent project

        if NPV(Project) > 0 accept
        if NPV(Project) < 0 reject

////////////////////////////////
"

.C3EXPLAIN8<-"Excel npv() is actually a pv function
////////////////////////////////
Example 1: 
    If We invest $100 today and will get $120 at the end of year one. 
    if the discount rate is 10%, what is the NPV?

   1) Manually calculate the result =(120)/(1+0.1) -100 = 9.090909091
   2) Using the NPV function()
        we enter the following two values at A1 and A2
           -100
            120

           =NPV(0.1,A1:A2)   ==> 8.26 
     The correct formula should be 
           =NPV(0.1,A2)+A1   ==> 9.09 

Example 2: 
time cashflow
0   -100
1    40
2    30
3    40
4    20
5   -10

////////////////////////////////
"

.C3EXPLAIN9<-"Examples of using Excel npv() function 
////////////////////////////////
time cashflow
0   -150
1    34
2    35
3    60
4    70
5   -20

    Rc is 0.1. NPV=?

////////////////////////////////
"

.C3EXPLAIN10<-"One-period, two-period models for today's stock price
////////////////////////////////
One-period model: (2 future cash flows)

       p0           d1+p1
       |------------|
       0            1
          d1      p1
    p =  ---   + ----
         (1+R)   (1+R)
   
Two-period model: (3 future cash flows) 

       p0           d1         d2+p2
       |------------|-----------|
       0            1           2  

          d1      d2            p2
    p =  ---   + ----     +   -----
         (1+R)   (1+R)^2      (1+R)^2

////////////////////////////////
"
.C3EXPLAIN11<-" N-period model (general one) for today's stock price
////////////////////////////////
One-period model: (2 future cash flows)
Two-period model: (3 future cash flows)
.....              ......
n-period model  : (n+1 future cash flows) 

       p0        d1         d2       d3         dn+pn   
       |----------|---------|--------|--  ....---|
       0          1         2        3           n

          d1       d2       d3              dn        pn
    p =  -----  + ----   + ------ + ... + -----   + ------
         (1+R)   (1+R)^2  (1+R)^3         (1+R)^n    (1+R)^n

                 d(n+1)    dn*(1+g)
      where pn=  ------  = --------         this is the key!!
                  R-g        R-g

////////////////////////////////
"

.C3EXPLAIN12<-"What is the Gordon Growth Model (GGM)
////////////////////////////////
 The Gordon Growth Model is used to determine the intrinsic 
     value of a stock based on a future series of dividends 
     that grow at a constant rate. It is a popular and 
     straightforward variant of a dividend discount model (DDM).

   The Formula For the Gordon Growth Model Is
                 d1
           P = --------                    (1)
                 R-g 
?   where:    P :  Current stock price
             g :  Constant growth rate expected for dividends, in perpetuity
             R :  Constant cost of equity capital for the company (or rate of return)
             d1:  value of next year's dividends
             Source: https://www.investopedia.com/terms/g/gordongrowthmodel.asp
?	
Case #2:  d0      d0((1+g)   d0(1+g)^2     -> infinity
          |----------|----------|-----------
                     1          2          -> infinity 
                   d0(1+g)
    P(stock) =  -----------               (2)
                  R - g
        d0: last period's paid dividend 

Case #3: General one
             d1       d2       d3       dn  ----> g (constant growth rate)
    |--------|--------|---------| ----   |-------|----->
             1        2        3         n       n+1 
  price (stock)= pv(d1) + pv(d2) + pv(d3) + ... pv(dn)+ pv(pn)
             dn+1     dn (1+g)
    Pn =  ----------= ----------      (3)
             R - g     R-g

////////////////////////////////
"

.C3EXPLAIN13<-"Definition of EAR and Excel effect() function 
/////////////////////////////////////
First, let's look at one simple example. We borrow $100 
   today for one year. The cost of borrowing is quoted 
   as APR is 10% compounded semi-annually. What are our 
   cash flows?

  100          -5                -5
                                 -100
  |-------------|-----------------| 

The question asked is that what the equivalent interest 
    rate is if we just pay interest once at the end of 
    the year?
  100                             ?
                                 -100
  |-------------|-----------------| 

Since we know that the rate for the 
    second 6-month is 5%. 

  100          (-5)  ===========> -5*0.05=0.25
                                  -5 
                                  -5
                                 -100
  |-------------|-----------------| 

Equivalent
  100                            -10.25
                                 -100
  |-------------|-----------------| 

Thus, the effective rate is 10.25%. 


Excel effect() function
-----------------------

  =effect(0.1,2) ==>    0.1025

Note: the effect() has two input
   nominal_rate: should be an APR
   npery       : compounding frequency per year

/////////////////////////////////////
"



.C3EXPLAIN14<-"Excel function for EAR 
////////////////////////////////
   Try the Excel =effect(norminal_rate,npery) function 

    it should be =effect(APR,freq) function 

  APR=10, compounded semiannually

   =effect(0.1,2) ==> 0.1025

   =effect(0.1,4) ==> 0.103812891

   =effect(0.045,12) ==> 0.045939825

////////////////////////////////
"

.C3EXPLAIN15<-"Effective period rate 
////////////////////////////////
In the following formulae, R is actually 
     an effective period rate. 
          FV
  pv=   ------                        (1)
         (1+R)^n

  fv= pv*(1+R) ^n                     (2)
                    C
  pv(perpetuity)=  ----               (3)
                    R
                c           1
 pv(annuity) = --- [ 1 - ------  ]    (4)
                R        (1+R)^n 

                     c       (1+g)^n
 pv(growing annuity)=---[1 - --------] (5)
                     R-g     (1+R)^n 

////////////////////////////////
"

.C3EXPLAIN16<-"Mortgage effective monthly rate 
////////////////////////////////
For the mortgage rate's quotation, the compounding frequency 
is monthly. Because of this, we divide APR by 12. 

  The mortgage rate is x, then the effective monthly rate is

    x/12

////////////////////////////////
"
.C3EXPLAIN17<-"2-step approach for effective rate conversion
////////////////////////////////
Step 1: which effective rate is given?
---------------------------------------
         APR is 10%, compounded semiannually          
                     effective semi-annual rate is given: 5% (0.1/2)
         APR is 8%, compounded quarterly        
                    effective quarterly rate is given:  2% (0.08/4) 

Step #2: From one effective rate to another effective rate  
-----------------------------------------------------------
         Note that Step 2 is independent from Step #1     
         Abetaume that the effective monthly rate is 0.2%   
         what is the corresponding effective semi-annual rate ?                                          

    We draw a time line for one year period            
           On top, it is for the given effective rate           
              1    2    3   4   5    6    7   8   9   10  11  12     
          |---|----|----|---|---|----|----|---|---|---|---|---|   

              At the bottom, it is for our target rate      
              1    2    3   4   5    6    7   8   9   10  11  12    
          |---|----|----|---|---|----|----|---|---|---|---|---|       
                                      1                        2    

    For the top part, what is one dollar's future value?:   
           FV1=1*(1+0.002)^12 
    For the bottom part, what is one dollar's future value:  
           FV2=1*(1+R)^2  
    Equal them:   FV1=FV2  and solve for R 
          (1+0.002)^12= (1+R)^2           
          R= (1+0.002)^(12/2)-1 =   0.01206016 

 Just type the following line
 .explain2stepApproach()

////////////////////////////////
"

.C3EXPLAIN18<-"Principal and interest components
////////////////////////////////
We plan to generate the following table 

      (1)               (2)              (3)                (4)               (5)
  Beginning Balance, total payment, intereat payment, principal deduction, Ending balance 
        ^                                                                        v
        |_____<<<_____________________________<<<______________________<<<_______|
  
 Beginning balance: the balance at the beginning of the period
                    (for the first period, it is the same as total borrowing)
                     For the 2nd period, it is the same as the ending balance of the 1st period) 
                     For the nth period, it is the same as the ending balance of the n-1 period)
 total payment    : the mortgage payment (a fixed value)
 interest payment : beginningBalance * effective period rate
 principal deduction: (4)= (3)-(2) 
 Ending balance     : (5)= (1) - (4)

////////////////////////////////
"

.C3EXPLAIN19<-"Videos
////////////////////////////////
 1) FNCE311 Chapter 3: Time value of Money (II), 
       Stock & Bond valuation: perpetuities and annuities
       https://youtu.be/d_r5SoK7GYo

 2) Conversion of effective interest rate (my 2-step approach)
     https://youtu.be/J2N2z4Vzwbk

 3) Harpett, 2015, Gordon Growth Model (Constant Growth)
     (v514k,s1.5m,t7:54)
     https://www.youtube.com/watch?v=Ty4OZKzqCaw

 4) Greene,Jasonm 2012, Implementing the DDM in Excel 
    (v68k,s6k,t9:23)
     https://www.youtube.com/watch?v=FBuUchkJT9A

  v: stands for viewership, s: number of subscribers,t:time

////////////////////////////////
"

.C3EXPLAIN20<-"Links 
///////////////////////////////////////////////
 Invespedia, 2019, Gordon Growth Model - GGM Definition 
     https://www.investopedia.com/terms/g/gordongrowthmodel.asp

 Mortgate rate 2019
     https://www.top10mortgageloanrefinance.com/mortgage-refinance?bkw=remortgage%20rates&bcampid=267542283&bcamp=Refinance&bagid=1180876045747880&bag=remortgage%20rates&btarid=kwd-73804809375818:loc-4116&bidm=be&bnet=o&bd=c&bmobval=0&bt=search&utm_source=bing&utm_medium=cpc&utm_term=mortgage%20rate&utm_campaign=Bing+CPC+Campaign&c=73804905500036&m=e&k=73804809375818&binterest=&bphysical=60165&bfeedid=&a=B999&ts=&topic=Ref_DT_Bing&upf=&msclkid=27fe750cf9a31dc381932833dcb79d49

////////////////////////////////
"

.chapter30<-function(i){
" i  Chapter 30: Term projects               i   Description 
  -  -------------------------------------   --  ----------------------
  1   Requirements for a term project       21   Liquidity, Pastor/Stambough(2003)
  2   52-week high trading strategy         22   Max trading strategy 
  3   Bankruptcy prediction using Z-score   23   Momentum trading strategy 
  4   Benford Law & accounting fraud        24   Readability 10-K/firms' performance    
  5   Best model(CAPM,FF3,FFC4,FF5)?        25   Retirement calculator  
  6   Black-Litterman model                 26   Reverse mortgage calculator
  7   Brandt et al. model (2009)/portfolio  27   SCF (Survey of Consumer Finance) 
  8   Building a slot machine               28   SEC 10-K (13-f) 
  9   Businebeta cycle indicator              29   SEC 10-K (Forms 3, 4 and 5)    
 10   Census Congrebetaional Districts 113    30   SEC 10-K: BS, IS or CF
 11   Census Congrebetaional Districts 115    31   SEC filings
 12   Census Demographic profile            32   SEC Mutual Fund Prospectus 
 13   Census Redistribution                 33   Simulation to mimic a slot machine     
 14   Census Summary Form 1 (SF1)	    34   Simulation to mimic Black Jack 
 15   Census Summary Form 2 (SF2)           35   Spread estimation from daily price
 16   Event Study using Excel               36   Spread estimation from TAQ 
 17   Extra high-frequency data             37   Test of the January Effect using Excel 
 18   Financial statement analysis          38   TORQ database 
 19   illiquidity measure,Amihud(2002)      39   Updating a monthly Excel data set
 20   KMV model & default probability       40   Projects taken 

 Example #1:>.c30     # see the above list
 Example #2:>.c30(1)  # see the first explanation

";.chapter30_(i)}

.n30chapter<-40
.chapter30_<-function(i){
     .printEachQ(30,i,.n30chapter)
}
.c30<-.chapter30

.C30EXPLAIN1<-"Requrement of a term project 
//////////////////////////////////////
Objective: This is an integral part of this course. It could be viewed 
           as the application of  what you have learnt from this course 
           to a real-world situation. 

Format: Group project (each group could have up to three members) 
       
Topic:  Each group chooses one topic from a list of potential term 
        projects (first come and first served since each topic should 
        be chosed by just one group). 
        To find a list of potential projects, just type 
        .c30 

Three files: Each group should submit three files 
         a) An Excel file containts your final result and final data set
         b) a short report (maximum page limit: 15, double space, font of 11)
         c) A powerPoint file  

Dropbox : submit your files to the dropbox on D2L

Presentation:
         Each group would present their term project in front of the whole clabeta 

Due date:if you want my comments, you should submit your files 
         before your presenttaion. If not, you could submit your files after 
         your presentation. 

//////////////////////////
"


.C30EXPLAIN2<-"52-week high trading strategy 
//////////////////////////////////////
George and Huang (2004) show that we could design a profitable trading 
   strategy based on the 52-Week High. First, they estimate a ratio by 
   dividing today's price by its 52-week high. Based on such a ratio, 
   all stocks are sorted from the highest to the lowest. The stocks 
   belong to the top (bottom) 30% are labeled as winners (losers). Again, 
   the trading strategy is to buy winners and sell losers. They demonstrate 
   that such a trading strategy is quite profitable with an average return 
   difference of 0.45% per month between the winner and loser portfolios. 

Several versions of this project:
   version #1: just test one or two stocks
   Version #2: test a few hundred
   Version #3: test all stocks  [you need a financial database called CRSP]

Objectives of this term project:
   1) Understand how to download daily data from Yahoo!Finance [see above versions #1 or #2]
   2) Understand how to use Excel to procebeta data 
   3) Prove or disapprove so-called 52-week High trading strategy 

 Time period: as long as pobetaible        [versions #1 or #2] 
              July 1963 to December 2001 [Version #3] 

 Basic logic: According to George and Huang (2004) it is a profitable 
              trading strategy if we based on the ratio of the current 
              stock price divided by its 52-week High

 Trading strategy: Estimate all stocks' 52-week high, estimate the ratio 
     of today's price over its 52-week High, sort them from the highest 
     to the lowest. Treat the top 30% as winners and bottom 30% as losers. 
     Buy winner and sell losers. 

Procedure for version #1:
  Step 0: formulate your trading strategy: 
             ratio > 0.8 you buy
             ratio < 0.3 you sell
                                     price - 52wLow
      Definition #1:  ratio  = ---------------
                                   (52wHigh - 52wlow)

                                  price
      Definition #2   ratio =   -----------
                                  52wHigh
Procedure for Version #1:
  Step 1: download one stock from Yahoo!finance as early as pobetaible 
  Step 2: estimate returns
  Step 3: sort data from the earlest to the latest
  Step 4: starting from 253 observation, estimate 52wHigh and 52wLow
  Step 5: calculate the ratio 
  Step 6: based on your trading strategy, you long or short for the next period
  Step 7: Generate a column for return for this trating strategy
  Step 8: test whether this is a profitable trading strategy 
          compared with the long-only strading strategy

Procedure for versions #2 and #3:
  Step 1: load data sets stockDaily and stockMonthly
  Step 2: Starting month: July 1963
  Step 3: Estimate  all stocks' 52-week High and estimate the ratio Price/52-week high  
  Step 4: Sort all stocks from highest to lowest 
  Step 5: choose top 30% as winners and bottom 30% as losers
  Step 6: estimate equal-weighted portfolios return for both winner and looser portfolios
  Step 7: Move to the next month and repeat the above steps until the last month (December 2001)
  Step 8: test 
  
 References
     George, Thomas J, and Chuan-Yang Huang, 2004, The 52-week High and Momentum 
           Investing, Journal of Finance 54, 5, 2145-2176.

//////////////////////////////////////
"

.C30EXPLAIN3<-"Bankruptcy prediction by using Z-score
//////////////////////////
The Altman's Z score is used to predict the pobetaibility of a firm goes 
    to bankruptcy. This score is a weighted average of 5 ratios based 
    on a firm's balance sheet and income statement. For public firms, 
    Altman (1968) offers the following formula. 

     Z=3.3*X1+0.99*X2+0.6*X3+1.2*X4+1.4*X5, 			(1)

    where the definitions of X1,X2,X3,X4 and X5 are given in the following table. 
      Variable	Definition 
      --        -------------
      X1        EBIT/Total Abetaets
      X2        Net Sales/Total Abetaets
      X3        Market Value of Equity/Total Liabilities
      X4        Working Capital/Total Abetaets
      X5        Retained Earnings/Total Abetaets

    Based on the ranges of z-scores, we could clabetaify public firms 
         into following 4 categories. Eidlenan (1995) finds that the 
         Z score correctly predicted 72% of bankruptcies two years 
         prior to the event.

        Z-score range	Description
        -------------   --------------
          > 3.0          Safe
          2.7 to 2.99    On Alert. 
          1.8 to 2.7     Good chances of going bankrupt within 2 years. 
          < 1.80         Probability of Financial distrebeta is very high 

    References
       Altman, Edward I.,2000,Predicting Financial Distrebeta of Companies, 
           Retrieved on September 4th, 2009 from http://pages.stern.nyu.edu/~ealtman/Zscores.pdf

       Altman, Edward I,1968,Financial Ratios, Discriminant Analysis and the 
           Prediction of Corporate Bankruptcy, Journal of Finance,189-209.
       
       Eidleman, Gregory J.,1995,Z-Scores - A Guide to Failure Prediction, 
           The CPA Journal Online, https://www.easycalculation.com/statistics/altman-z-score.php

//////////////////////////
"

.C30EXPLAIN4<-"Benford Law and accounting fraud detection
//////////////////////////////////////
 Benford Law is also called the First-Digit Law which gives different frequencies 
    for 9 first digits from 1 to 9.  Convention wisdom would conclude that each 
    (first) digit would have roughly the same frequency, i.e., 1/9=0.1111=11%.  
    
 However, according to the Benford Law, the lower is the value of a digit, 
    the higher is its probability. In other words, we will see more values 
    with leading digit of 1 than with the leading digit of 2. The probability 
    of each digit is given by the following formula. 

    Prob(d)=log10((d+1)/d)                          (1)

   where Prob() is the probability (frequency), d is the digit, and log10() 
      is the log function with a base of 10. For Excel, log10() is the same as log(). 

    Digit   Formula    probability
    ----    ----        ----
    1     =log10(2/1)   0.301
    2     =log(3/2)     0.176
    3     =log(4/3)     0.125
    4     =log(5/4)     0.097
    5     =log(6/5)     0.079
    6     =log(7/6)     0.067
    7     =log(8/7)     0.058
    8     =log(9/8)     0.051
    9     =log(10/9)    0.046
          ------------  -----
           Total        100%

 Objectives:
     1) understand Benford Law
     2) download about a dozen companies' annual reports
     3) estimate the distributions of the 1st digits
     4) report your results and discubeta

 Procedure:
    To download annual financial statements.
       Step 1: go to Yahoo!Finance  http://finance.yahoo.com/  
       Step 2: enter a ticker, such as IBM
       Step 3: find three types of financial statements. 
       Step 4: download those financial statements

   Note 1: the function to get the first digit is =left(cell, 1)
   Note 2: you could use the Excel countif() function. 

 References
    Accounting Web, 20 Ways You Can Detect Fraud, 2014, 
        http://www.accountingweb.com/aa/law-and-enforcement/20-ways-you-can-detect-fraud

    Sharma, Anuj, Prabin Kumar Panigrahi, 2012, A Review of Financial Accounting Fraud 
        Detection based on Data Mining Techniques, INternationla Journal of Computer 
        Aplication 39, 1, https://arxiv.org/ftp/arxiv/papers/1309/1309.3944.pdf

    MCGINTY, JO CRAVEN, 2014, Accountants Increasingly Use Data Analysis to Catch 
        Fraud, Auditors Wield Mathematical  Weapons to Detect Cheating, http://www.wsj.com/articles/accountants-increasingly-use-data-analysis-to-catch-fraud-1417804886

    Testing Benford Law, http://testingbenfordslaw.com/

    What is Benford Law,  https://en.wikipedia.org/wiki/Benford%27s_law#cite_note-Nigrini-19

//////////////////////////////////////
"

.C30EXPLAIN5<-"Best model? CAPM, FF3, FFC4, or FF5
//////////////////////////
Objectives of this term project
    1) understand different models: CAPM, FF3, FF4 and FF5
    2) Understand how download and procebeta data 
    3) Understand the T-value F-values and adjusted R2

a) CAPM: R(IBM) = Rf + beta*(Rm - Rf)                         (1)
            where R(IBM) is the IBM's mean return or expected return 
            Rf is the risk-free rate
            Rm is the market mean return or expected return 

b) FF3 Fama-French 3-factor model:
         R(IBM) = Rf + beta1*(Rm - Rf)+beta2*SMB + beta3*HML  (2)
            where SMB is small minus big, HML is high book-to-market 
            ratio portfolio minus low ratio portfolio 

c) FF4 is the Fama-French-Carhart 4 factor model 
         R(IBM) = ff3 + beta4*MOM                             (3)
            Where MOM is momentum factor
                      
d) FF5 is the Fama-French 5-factor model:
         R(IBM) = ff3  + beta4**RMW + beta5*CMA               (4)
            where RMW is Robust minus weak, CAM is 
               conservative minus Aggrebetaive
  Three questions:
      1)   Which criterion?
      2)   The performance is time-period independent?
      3)   In-sample estimation vs. out sample prediction

   We use the adjusted R2 as our criterion to measure the performance of each model. 
      Step 1: download monthly price data from Yahoo!Finance
      Step 2: choose a period to run various models  
      Step 3: summarize your testing results  (sample statistics)
      Step 4: (Optional: out-of-sample prediction)

source of data: 
       1) http://finance.yahoo.com
       2) http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html
//////////////////////////
"

.C30EXPLAIN6<-"Black and Litterman model (1992)
//////////////////////////////////////
Objective: 
----------
   1) Understand the shortcomings of our optimization model 
   2) understand the contributions of Black and Litterman (1992)
   3) using Excel to illustrate a few examples 
   4) Extension? 

Sources
-------
     blacklitterman.org   
         http://blacklitterman.org

     Black and Little example
         http://canisius.edu/~yany/excel/blacklitterman.xlsx

//////////////////////////////////////
"

.C30EXPLAIN7<-"Brandt, Santa-Clara and Valkanov model (2009)
//////////////////////////////////////
Objective: 
----------
   1) Understand the shortcomings and limitatons of the current optimization model 
   2) understand the contributions of Brandt et al. (2009)
   3) using Excel to illustrate a few examples 
   4) Extension? 

Sources
-------
  Michael W. Brandt, Pedro Santa-Clara, Robetaen Valkanov,2009,
    Parametric Portfolio Policies: Exploiting Characteristics in the Crobeta 
    Section of Equity Returns  

    Abstract
    We propose a novel approach to optimizing portfolios with large numbers
    of abetaets. We model directly the portfolio weight in each abetaet as a 
    function of the abetaet's characteristics. The coefficients of this 
    function are found by optimizing the investor's average utility of
    the portfolio's return over the sample period. Our approach is 
    computationally simple, easily modified and extended, produces sensible
    portfolio weights, and offers robust performance in and out of sample. 
    In contrast, the traditional approach of first modeling the joint distribution 
    of returns and then solving for the corresponding optimal portfolio weights 
    is not only difficult to implement for a large number of abetaets but also yields 
    notoriously noisy and unstable results. Our approach also provides a new test 
    of the portfolio choice implications of equilibrium abetaet pricing models. 
    We present an empirical implementation for the universe of all stocks in the CRSP-Compustat
    dataset, exploiting the size, value, and momentum anomalies.

    https://www.nber.org/papers/w10996
//////////////////////////////////////
"

.C30EXPLAIN8<-"Building a slot machine
/////////////////////////
The logic of the game 
---------------------

    Our bet is $1. We randomly choose 3 numbers from 1 to 10. 
    if they are equal, we win $90. Otherwise, we loose our bet. 

  Step 1: choose a cell to enter =randbetween(1,10)
  Step 2: format it nicely 
          a) choose several cells around it, 
             click \"merge & Center \" on the menu bar
          b) Highlight those cells -> Click \"Conditional Formatting\"
             choose \"Color Scales\" -> choose 

  Step 3: Copy the cells to another two places 
  Step 4: choose a cell to calculate win or lobeta
          if three of them are equal, win 90, otherwise -1
  Step 5: find a cell we could enter our initial cash 
  Step 6: choose a cell to calculate the cumulative lobeta
          Abetaume that our cumulative lobeta cell is I3
          our win or lobeta is in cell  F3, see step 4

  Step 7: Click \"Developer\" -> View Code -> Copy that paste the following macro 

Sub games()
Range(\"I3\").Value = Range(\"I3\").Value + Range(\"F3\").Value
End Sub
  [Note: we need some value is I3 to make it work]
/////////////////////////
"


.C30EXPLAIN9<-"businebeta cycle indicator
//////////////////////////////////////
There exist many profitable trading strategies, such as the individual stock 
momentum, first documented in Jegadeesh and Titman (1993), the industry momentum 
in Moskowitz and Grinblatt (1999), the effect of the 52-week high price in George 
and Hwang (2004), and the effect of the maximum daily return in a month in 
Bali et al. (2011). However, Yan and Zhang (2016) argue that those profitable 
trading strategies would not be profitable during difficult time. In other words, 
investors would change their behavior during a recebetaion. 

Objectives:
   1) understand the concept of businebeta cycle
   2) generate a businces cycle indicator
   3) if pobetaible run CAPM by including this indicator 

    Source of data: 
      1) Businebeta cycle data is from the National Bureau of Economic Research center. 
             The original starting date is June 1854.  
      2) stock data is from Yahoo!Finance. 

    Comments on your result

References
   Bali, Turan G., Nusret Cakici, and Robert F. Whitelaw, 2011, Maxing Out: 
         Stocks as Lotteries and the Crobeta-Section of Expected Returns, 
         Journal of Financial Economics 99 427-446.

   George, Thomas J, and Chuan-Yang Hwang, 2004, The 52-week High and Momentum 
         Investing, Journal of Finance 54, 5, 2145-2176.

   Grinblatt, Mark, and Bing Han, 2005, Prospect theory, mental accounting, 
         and momentum, Journal of Financial Economic 78, 311-339.

   Jegadeesh, N., and S. Titman, 1993, Returns to Buying Winners and Selling 
         Losers: Implications for Stock Market Efficiency, Journal of Finance 48, 65-91.

   Moskowitz, Tobias, and Mark Grinblatt, 1999, Do industries explain momentum? 
         Journal of Finance 54, 2017-2069.

   Yan, Yuxing and Shaojun Zhang, 2016, Businebeta cycle, investors' preferences 
         and trading strategies, Frontiers of Businebeta Research in China (forthcoming)  

  Table 1 from Yan and Zhang(2016)
        For a peak, we abetaign a positive 1 while for a trough, we abetaign a 
        negative 1. Any months between those peaks and troughs, we linearly 
        interpolate, see Panel B below. P for Peak and T for Trough. T(t-1) 
        is for the pervious Trough and P(t-1) is for the previous Peak. 

   Contraction        Expansion	cycle
     Peak (P)	      Trough (T)	P to T	T(t-1) to P  T(-1) to T    P(t-1) to P
  -----------         -----------------  ------  ----------  -----------   -----
  May 1923(II)        July 1924 (III)      14    22           36           40
  October 1926(III)   November 1927 (IV)   13    27           40           41
  August 1929(III)    March 1933 (I)       43    21           64           34
  May 1937(II)        June 1938 (II)       13    50           63           93
  February 1945(I)    October 1945 (IV)     8    80           88           93
  November 1948(IV)   October 1949 (IV)    11    37           48           45
  July 1953(II)       May 1954 (II)        10    45           55           56
  August 1957(III)    April 1958 (II)       8    39           47           49
  April 1960(II)      February 1961 (I)    10    24           34           32
  December 1969(IV)   November 1970 (IV)   11   106          117          116
  November 1973(IV)   March 1975 (I)       16    36           52           47
  January 1980(I)     July 1980 (III)       6    58           64           74
  July 1981(III)      November 1982 (IV)   16    12           28           18
  July 1990(III)      March 1991(I)         8    92          100          108
  March 2001(I)       November 2001 (IV)    8   120          128          128
  December 2007(IV)   June 2009 (II)       18    73           91           81
//////////////////////////////////////
"

.C30EXPLAIN10<-"Census Congrebetaional Districts113
//////////////////////////
 To download all data, type
    .dumpCensusCongrebetaionalDistricts113 

 Source of data 
     https://www2.census.gov/census_2010/08-SF1_Congrebetaional_Districts_113/

//////////////////////////
"

.C30EXPLAIN11<-"Census Congrebetaional Districts115
//////////////////////////
 To download all data, type
    .dumpCensusCongrebetaionalDistricts115 

 Source of data 
    https://www2.census.gov/census_2010/08-SF1_Congrebetaional_Districts_115/

//////////////////////////
"

.C30EXPLAIN12<-"Census Demographic profile
//////////////////////////
A short intro 
-------------
   The Demographic Profile Summary File contains 100 percent data asked of 
   all people and about every housing unit on topics such as sex, age, race, 
   Hispanic or Latino origin, household relationship, household type, group 
   quarters population, housing occupancy, and housing tenure. 

   GEOGRAPHIC CONTENT
     The Demographic Profile Summary File is released as individual files for 
     the United States, each of the 50 states, the District of Columbia, and 
     Puerto Rico. The data items are identical for all files, but the geographic
    coverage differs.

    The summary level sequence chart outlines the hierarchical and geographic 
    summaries in their entirety. 
 
  To download all data, type
  ---------------------------
    .dumpCensusDemographicProfile

  Source of the data 
      https://www2.census.gov/census_2010/03-Demographic_Profile/
  Manual 
     https://www.census.gov/prod/cen2010/doc/dpsf.pdf
  Manual about the data structure 
     https://www2.census.gov/census_2010/03-Demographic_Profile/0README_DPSF.pdf

//////////////////////////
"

.C30EXPLAIN13<-"Census Redistribution
//////////////////////////
  To download all data, type
    .dumpCensusRedistribution

  source of data 
     https://www2.census.gov/census_2010/redistricting_file--pl_94-171/

//////////////////////////
"

.C30EXPLAIN14<-"Census Summary Form 1 (SF1)
//////////////////////////
What is SF 1?
  Summary File 1 (SF 1) contains the data compiled from the questions asked of 
  all people and about every housing unit. Population items include sex, age, 
  race, Hispanic or Latino origin, household relationship, household type, 
  household size, family type, family size, and group quarters. 

  Housing items include occupancy status, vacancy status, and tenure (whether 
  a housing unit is owner-occupied or renter-occupied).

  There are 177 population tables (identified with a \"P\") and 58 housing tables
  (identified with an \"H\") shown down to the block level; 82 population tables 
  (identified with a \"PCT\") and 4 housing tables (identified with an \"HCT\") 
  shown down to the census tract level; and 10 population tables (identified with 
  a \"PCO\") shown down to the county level, for a total of 331 tables. The SF 1 
  Urban/Rural Update added 2 PCT tables,increasing the total number to 333 tables. 
  There are 14 population tables and 4 housing tables shown down to the block level 
  and 5 population tables shown down to the census tract level that are repeated by
  the major race and Hispanic or Latino groups.
  
  SF 1 includes population and housing characteristics for the total population,
  population totals for an extensive list of race (American Indian and Alaska 
  Native tribes, Asian, and Native Hawaiian and Other Pacific Islander) and 
  Hispanic or Latino groups, and population and housing characteristics for 
  a limited list of race and Hispanic or Latino groups. Population and housing 
  items may be crobeta-tabulated. Selected aggregates and medians also are provided.

  A complete listing of subjects in this file is found in the \"Subject Locator\"  chapter.

  To download all data, type
     .dumpCensubetaF1   

  source of data: https://www2.census.gov/census_2010/04-Summary_File_1/
  Manual: https://www.census.gov/prod/cen2010/doc/sf1.pdf   

//////////////////////////
"

.C30EXPLAIN15<-"Census Summary Form 2 (SF2)
//////////////////////////
What is SF2?
   Summary File 2 (SF 2) contains the data compiled from the questions asked of 
   all people and about every housing unit. SF 2 includes population characteristics,
   such as sex, age, average household size, household type, and relationship to 
   householder such as nonrelative or child. The file includes housing characteristics,
   such as tenure (whether a housing unit is owner-occupied or renter-occupied), 
   age of householder, and household size for occupied housing units. 

  Selected aggregates and medians also are provided. A complete listing of 
  subjects in SF 2 is found in Chapter 3, Subject Locator. The layout of the 
  tables in SF 2 is similar to those in SF 1. 

  These data are presented in 47 population tables (identified with a \"PCT\") 
  and 14 housing tables (identified with an \"HCT\") shown down to the census 
  tract level; and 10 population tables (identified with a \"PCO\") shown 
  down to the county level, for a total of 71 tables. Each table is iterated 
  for 331 population groups: the total population, 75 race categories, 114 
  American Indian and Alaska Native categories (reflecting 60 tribal groupings), 
  47 Asian categories (reflecting 24 Asian groups), 43 Native Hawaiian and Other 
  Pacific Islander categories (reflecting 22 Native Hawaiian and Other Pacific
  Islander groups) and 51 Hispanic/not Hispanic groups. The presentation of SF 2 
  tables for any of the 331 population groups is subject to a population threshold 
  of 100 or more people. That is, if there are fewer than 100 people in a specific
  population group in a specific geographic area, their population and housing 
  characteristics data are not available for that geographic area in SF 2. 

  To download all data, type
     .dumpCensubetaF2   

  Source of data 
     https://www2.census.gov/census_2010/05-Summary_File_2/

  Manual 
     https://www.census.gov/prod/cen2010/doc/sf2.pdf

//////////////////////////
"

.C30EXPLAIN16<-"Event Study using Excel 
//////////////////////////////////////
 Based on Event Study, we test the impact of HSIC added to the S&P500 on March 18, 2015. 
 Source of data: http://canisius.edu/~yany/excel/eventStudy.xlsx
  
 The basic idea for Event Study is to test whether our AR (Abnormal Return) is 
     statistically significant. The definition of abnormal return is given below. 

           AP=realized return - expected return        (1)

  To estimate our expected return, we apply the following linear regrebetaion. 

	y = alpha + beta* x                           (2)

   where, y is the expected return and x is the market return on that day. 
      To estimate two parameters, alpha and beta, we run a linear regrebetaion or apply 
      related formulae by choosing an evaluation period of 252-day long, 
      starting the day before our event window counting backward, see below. 
             
             Estimation period                          Event-window
    |-------------------------------|-------------|----------|
	                   n days before      event-day   m-day after
 Here is the design. 
     i) The event day is 3/18/2015			
    ii) Our event window: 10 days before and 10 days after			
   iii) The estimation period: from 253 days before to one-day before our event window

 Thus, roughly we could download daily data from 2/1/2014 to 4/22/2015.
   Step 1: download daily price data from HSIC and S&P500 (^GSPC). 
   Step 2: Choose only adjusted price, see the left panel below.
             Then sort data from oldest to the latest, see the right panel below. 			
   Step 3: estimate daily returns, see the formula in D3.  				
   Step 4: Highlight our event day, a window around the event and the estimation period 
             For example, we could use red color for event day, 10-day before and 
             10-day after our event day. In addition, we could highlight our 
             estimation period green. 
   Step 5: Based on the estimation period, apply following formulae to estimate 
             intercept, slope, R2 and standard error				
             abetaume B column is for stock returns, C column is S&P500 returns
	    i) intercept      =intercept(B,C)
           ii) slope          =slope    (B,C)
          iii) R2             =rsq      (B,C)
           iv) standard error =steyx    (B,C)

    Step 6: Estimate, expected return, AR (abnormal return), 
            CAP (cumulative abnormal return) and T-AP (T-value for abnormal return)				

         Expected return            AP      CAR     T-value for AR
	  --------------            --      ---     --------------
			
	Expected return                        = intercept + slope * market			
	AR (abnormal return)                   = realized return - expected return			
	CAR (cumulative abnormal return)       = sum of all ARs up to today			
	T-value for AR                         = AR/standard error			

   Note: to make our spread sheet clean, we have two choices:
 	i) Hide many rows			
	ii) Copy above four output values to a place near our event window			
   Comment on your results. 			

 Source of S&P500 added and deleted
     https://en.wikipedia.org/wiki/List_of_S%26P_500_companies#Recent_changes_to_the_list_of_S&P_500_Components
     http://canisius.edu/~yan/excel/sp500added_deleted.xlsx
//////////////////////////////////////
"

.C30EXPLAIN17<-"Extra high-frequency data 
//////////////////////////
  Extra high-frequency data 
    ftp://ftp.nyxdata.com/Historical%20Data%20Samples/

//////////////////////////
"


.C30EXPLAIN18<-"Financial statement analysis
//////////////////////////////////////
Objective: 
   1) Understand the importance of financial statement analysis 
   2) understand the definitions of various ratios, such as
       Debt/equity ratio, ROE, ROA, DuPoint Identity
   3) Compare the performance of the firm with itself and with peers
   4) Given your recommendations 

   Note: If you could \"automate\" your procebeta, it will be more 
         meaningful. For example, you spend one day to finaish one company. 
         How long you would finish the next one or 10th one?

  Here are potential helps. 
        1) get financial statement easily, see type
           c28
        2) You can use some simple macro, such as record your operation
           c26
Procedure: 
   1) Download a compay's several years' financial statements 
   2) Conduct analysis such as ratio analysis
   3) Compare its performance with itself and with peers
   4) Write your comments and recommendation 

//////////////////////////////////////
"

.C30EXPLAIN19<-"illiquidity measure, Amihud (2002)
//////////////////////////////////////
Objective: estimate 12 stocks' illiquidity measures for each month in 2016. 
     Note: you choose the last 6 stock yourself. Comments on your findings

     6 stock symbols are given below. 
        Company name            Ticker	Industry
        ----------------------  ------  ------------------
   1	Microsoft Corporation   MSFT    Application software
   2	Apple Inc.              AAPL    Personal Computer
   3	Citigroup Inc.             C    Money Center Banks
   4	Wal-Mart Stores, Inc.    WMT    Discount, Variety Stores
   5	Home Depot, Inc.          HD    Home improvement services
   ..   .................       ...     ......
  12	General Electric Corp     GE	Technology

 Amihud (2002) illiquidity measure uses the absolute daily return over 
   its corresponding trading dollar volume. A monthly stock illiquidity 
   measure is the mean of daily illiquidity measure.  
                   1                |Ri|
       illiq(t)=  --- * sum (--------------- )      (1)
                   n             pi * Vi

   where illiq(t) is a monthly illiquidity measure, n is the number of 
         trading days within the month, Ri is daily return on day i, 
         Vi is the trading volume on day i and Pi is the closing 
         price of the underlying stock on day i. 

   The Amihud illiquidity measure includes two components: 
        spread and the impact of trading. Illiquidity is the 
        opposite of liquidity, i.e., a higher value indicates a low 
        liquidity and a small value indicates a higher liquidity level. Why?

   Step 1: download daily price data from Yahoo Finance 
   Step 2: estimate daily returns and dollar trading volume
   Step 3: estimate the ratio
   Step 4: estimate monthly illiquidity measures
 References
    Amihud,Yakov,2002,Illiquidity and Stock returns,
       Journal of Financial Markets 5, 31-56.

//////////////////////////////////////
"


.C30EXPLAIN20<-"KMV model and default probability
//////////////////////////////////////
Objective: 
   1) Estimate market value and its volatility for KMV model
   2) estmate default point
   3) estimate default probablity 

 KMV stands for Kealhofer, McQuown and Vasicek who found a company focusing 
    on measuring default risk. KMV methodology is one of the most important 
    methods to estimate the probability of default for a given company by 
    using its balance sheet information and the equity market information.  

 The objective here is to estimate the market value of total abetaets (A) and 
    its corresponding volatility (sigmaA). The result will be used to estimate 
    default distance and default probability. 

 The basic idea is to treat the equity of a firm as a call option and the debt is 
    its strike price. Let us look at the following simplest example. For a firm, 
    if its debt is $80 and equity is $20 then the total abetaets will be $100. 

 Abetaume that the abetaets jump to $110 and the debt remains the same, the equity 
    increases to $30. On the other hand, if the abetaets drop to $90, the equity 
    will be only $10. Since the equity holders are the residual claimer, their 
    value has the following exprebetaion. 

           E  = max?(abetaets - debt,0)=max?(A-D,0)          (1)

    Recall for a call option, we have the following payoff function. 

       Payoff(call) = max?(sT-K,0)                        (2)

   This means that we could treat equity as a call option with debt as 
      our exercise price.  With appropriate notations, we will have the 
      following formulae for a firm's equity. KMV model is defined below. 

             E=A*N(d1 )-e^(-rT) N(d2)

               ln?(A/D)+(r+0.5*sigma^2 )T
        d1 =   ---------------------------               (3)
                   sigmaA * sqrt(T)
        d2 =d1- sigmaA *sqrt(T)                         

  On the other hand, the following relationship between the volatilities 
     of the equity and the total abetaets holds. In the following equation, 
     we have  delta=dE/(dVA )=N(d1 ). 

         sigmaE=A/E
                       N(d1)*A*sigmaA
        delta_sigmaA=   -------------                    (4)
                           E
   Since d1 and d2 are defined by the above equations, we have two equations 
      for two unknown (A and sgimaA), see below. Thus, we could use a 
      trial-and-error or simultaneous equation method to solve for those 
     two unknowns.  Eventually, we want to solve the following two equations for A and s_A.

                 E=A*N(d1)-e^(-rT) *N(d2 )
                           A
                 sigmaE=  --- * N(d1)*siamgA             (5)
                           E
   We should pay attention that the estimated A (Market value of total abetaets) 
      from Equation (5) is different from the summation of market value of abetaets 
      plus the book value of the debt. The usages of those two derived values 
      (A and sigmaA) will be used by Equations (6-8). 

   Here is a KMV example: E=110,688 (shares outstanding*price of stock), 
      D=64,062 (total debt), Rf=0.07 (risk-free rate), T=1 (1 year).  
      The result is A=170,558 sA=0.29.  Based on the following codes 
      we got A=170,393 and sigmaE=0.2615. The output is : A=170,393.78 
      and sigmaE is 0.2615. Please pay attention that the summation of 
      the book value of debt and the market value of equity is 174,750 (?170,558). 

  Distance to Default
     Distance to default (DD) is defined by the following formula, where A 
     is the market value of the total abetaets and sigmaA  is its risk. 
     The interpretation of this measure is clear, the higher DD, the safer is the firm. 

               A - Default Point 
       DD= -----------------------                      (6)
                  A *sigmaA                              

  In terms of Default Point, there is no theoretical fixed default point. 
     However, we could use all short-term debts plus the half of long-term 
     debts as our default point.  After we have the values of MV of abetaets 
     and its volatility, we could use the following equation to estimate the 
     Distance to Default. The A and s_A are from the output from Equation (5). 
     On the other hand, if the default point equals to E, we would have the following formula. 

                  ln(VA/D)+(r-0.5*sigmaA^2)T
          DD= -  -------------------------------        (7)
                    sigmaA*sqrt(T) 				

    Note that there is a negative sign in front of the ratio
    According to Black-Scholes model, the relationship between DD and Default Probability
           is given below. 
        DP(Default Probability) = N(-DD)                (8)

//////////////////////////////////////
"

.C30EXPLAIN21<-"Liquidity measure, Pastor and Stambough (2003)
//////////////////////////////////////
Objectives: 
    1) Understand the logic of the measure
    2) Learn how to download and procebeta data from Yahoo!Finance
    3) estimate individual stock's liquidity 

  Basic logic:Pastor and Stambaugh (2003) design the following 
        regrebetaion to estimate individual stock's liquidity.  

            y(t)=alpha +beta1*x1(t-1)+ beta2*x2(t-1)+error(t)           (1)

    where,y(t) is the excebeta stock return on day t, the excebeta return is 
          defined as R(t)-Rm(t),  R(t) is the stock return, Rm(t) is the 
          market return at time t; x1(t-1) is the lagged stock return, 
          i.e., R(t-1), X2(t-1) is the lagged dollar trading volume, i.e., 
          x2(t-1)=P(t-1)*V(t-1), P(t-1) is the daily closing price of the stock 
          at t-1 and V(t-1) is the daily trading volume at t-1. 
          
    The regrebetaion is based on the daily data within each month with a 
         minimum number of observations of 15. The liquidity measure for an 
         individual stock in each month is defined as:
 
            	liquidity measure=beta2       (2)

     For the first trial, we ignore other constraints.  The Market liquidity 
         is the equally weighted individual stock's liquidity and scaled by 
         the market capitalization.
Procedure:
	Step 1: Retrieve daily data
	Step 2: generate y, x1, x2 for each stocks 
	Step 3: Run regrebetaion (1) to estimate beta2 for each month
References
    Pastor, L. & Stambaugh, R., 2003, Liquidity risk and expected stock returns. 
    Journal of Political Economy 111, 642-685.

//////////////////////////////////////
"

.C30EXPLAIN22<-"Max trading strategy 
//////////////////////////////////////
 Bali, Cakici and Whitelaw (2011) find that sorting stocks by their 
    maximum daily returns (MAX) in the previous month could produce a 
    monthly return difference of more than 1% between the lowest and 
    highest MAX deciles.  

    In addition, the alphas from running Fama-French-Carhart 4-factor
    model for those two extreme portfolios are significantly different. 
    Thus, we could design a profitable trading strategies based on stocks'
    last month extreme daily returns. 

There are several versions of this term project:
   version #1: just test 20 to 40 stocks
   Version #2: test a few hundred
   Version #3: test all stocks   [you need a financial database called CRSP]

Objectives of this term project (version #1):
   1) Understand how to download data from Yahoo!Finance
   2) Prove or disapprove so-called the max-trading strategy

Objectives of this term project (version s #2 and #3):
   1) Understand the CRSP database
   2) Understand how to use Excel or R to retrieve and procebeta data 
   3) Prove or disapprove so-called the max-trading strategy by 
        replicating Table 1 of Bali et al. (2011).

 Prerequisites (version #3):  stockDaily and stockMonthly.RData 
    Basic logic: According to Bali et al. (2011) some investors like stocks with 
              lottery-type payoffs which have big past returns with a small probability. 
    Period:	July 1962 to December 2005

 Trading strategy: Estimate all stocks' maximum returns in the last month, 
    sort stocks into 10 groups (deciles) according to their last month's 
    maximum daily returns. Long the top decile (winners) and short the 
    bottom decile (losers) for one month. 

Procedure (for versions #1): Abetaume that you have 40 stocks 
     Step 0: donwload daily/monthly price data for those stocks
     Step 1: estimate daily returns 
     Step 2: Using pivoTable to generte some thing below 
                           stock1   stock2  stock3 ..    stock40
                YYYYMM1    maxValue   x       x            x
                YYYYMM2     x         x       x            x 

             Note: maxValue is the maxium value for stock1 in the previous month. 

    Step 3: choose your portfolio: long 10% and short bottom 10%. 
            In other words, long 4 stocks with highest max returns in the previous month. 
            short 4 stocks with the lowest max returns in the previous
    Step 4: Eestimate portfolio returns of your long short portfolio 
    Step 6: move to the next month and repeat 
    Step 7: test your result. 

Procedure (for versions #3):
	Step 0: Starting month: July 1962
	Step 1: load stockDaily 
	Step 2: Estimate the maximum daily returns of the previous month, i.e., May 1962
	Step 3: Sort all stocks into deciles according to their maximum last month daily returns 
	Step 4: Long the top 10% and short the bottom 10%
	Step 5: load stockMonthly and estimate portfolio returns and their difference
      Step 6: Move to the next month and repeat the above steps until the last month (December, 2005)

  References
     Bali, Turan G., Nusret Cakici, and Robert F. Whitelaw, 2011, Maxing Out: 
        Stocks as Lotteries and the Crobeta-Section of Expected Returns, Journal 
        of Financial Economics 99 427-446.

//////////////////////////////////////
"


.C30EXPLAIN23<-"Momentum trading strategy 
//////////////////////////
We could use a simple phrase to summarize the so-called momentum trading strategy: 
      buy winners and sell losers. 

Here, we have an implied abetaumption: within a short-term (between 3 months 
     and 12 months), the winner will remain a winner while a loser would 
     continue to be a loser. Two related questions: 1) how to define a winner 
     from a loser? 2) how to conduct a test?

Objectives of this term project:
     1) learn how to download a few hundred stock data 
     2) Understand how to use Excel to retrieve and procebeta data 
     3) Prove or disapprove so-called momentum strategy 
        by replicating Table 1 of Jegadeesh and Titman (1993) 
        [They use all stocks, while you would use just a few hundred stocks]

  Prerequisites:  accebeta to an Excel ata set called monthlyYan.xlsx (I will supply this data set)
  Ba sic logic:   According to Jegadeesh and Titman (1993) it is a profitable trading 
                  strategy if we buy the past winners and sell the past losers.  

   Notations: 	Check the past K-month returns, and then form a portfolio for L months, 
     Where K=3,6,9 and 12 and L=3, 6, 9 and 12. Below we use K=L=6 as an example. 
     Trading strategy: Estimate all stocks' past 6- month returns and sort stocks 
      into 10 groups (deciles) according to their 6-month total returns. Long 
       the top decile (winners) and short the bottom decile (losers) for the next 6 months. 
   
   Procedure:
       Step 0: Starting month: January 1927
       Step 1: Retrieve CRSP data (PERMNO, DATE and RET)
       Step 2: Estimate past 6-month cumulative returns R_t^6month
       Step 3: Sort all stocks into deciles according to their cumulative 6-month returns
       Step 4: Long winners (best return group) and short losers for the next 6-month
       Step 5: Estimate portfolio returns
       Step 6: Move to the next month and repeat the above steps until the 
               last month 
 References
      Jegadeesh Narasimhan and Sheridan Titman, 1993, Returns to Buying Winners and 
           Selling Losers: Implications for Stock Market Efficiency, Journal of Finance 
           48 (1), 65-91.
 
     Appendix A: Table 1 from Jegadeesh and Titman (1993).

//////////////////////////
"


.C30EXPLAIN24<-"Readability of 10-K filings and firm's performance
//////////////////////////////////////
Objectives:
      1) Understand the usage of 10-K
      2) learn how to parse 10-K
      3) understand the Fog-index and learn how to calculate it for each 10-K filing
      4) Comments on your result

Source of data
      a) SEC EDGAR (Electronic Data Gathering , Analysis and Retrieval)
      b) I have all 10-K filings from Q1 1993 to Q2 2016 (the number of filings is 
           210,842 and the size is 440G)

Structure vs. unstructured data
    The unstructured information has a lion share of all information, 
    70% to 80% and it is reported that 80% of structured information 
    came from unstructured one. On the other-hand, SEC filings is an 
    important source of information (gold mine) since public companies, 
    certain insiders, and broker-dealers are required to make regular SEC filings. 

Text analysis
    Text is one of the most important informant belongs to unstructured 
       information. Text analysis, also called text mining, also referred 
       to as text data mining, roughly equivalent to text analytics, refers 
       to the procebeta of deriving high-quality information from text. 
       For example, we could look at the frequency of each words, keywords, 
       number of lines, sentences, frequency of positive words vs. negative, 
       tone of the speech etc. For example, let's look at the top used words 
       by Reagan in 1994 and Obama 2008, see below. Which one belongs to Obama?

 Text analysis for finance and accounting
      Applying text analysis to finance and accounting does not have a long history. 
      Li (2008) shows that the readability of 10-K filings has a statistically 
      significant impact on the performance of a firm's subsequent performance. 
      The readability measure used by Li (2008) is call Fog index defined below. 

              Fog index=0.4*(n+p)                  (1)  

    where, n is the average number of words per sentence, while p is  
           the percentage of complex words.  A complex word is a word has 
           more than two syllables.

    Because of defining and measuring readability in the context of financial 
       disclosures becomes important with the increasing use of textual analysis 
       and the SEC's plain English initiative, Lougran and McDonald (2015) show 
       that  the Fog Index - the most commonly applied readability measure - is poorly 
       specified in financial applications. Of Fog's two components, one is 
       mibetapecified and the other is difficult to measure. They suggest to use 
       the size of 10-K filing as a simple readability proxy and show that it 
       outperforms the Fog Index. Another added advantage is that it does not 
       require document parsing, thus facilitates replication. 

    According to Loughran and McDonald (2014), there are 632 different forms.  
       On the other hand, most researchers used only one or two forms, such 
.       as 10-K. Thus, the SEC filings \"database\" is a gold mine waiting to 
       be explored. 

 Reference
       Li, Feng, 2008, Annual report readability, current earnings, and earnings 
           persistence, Journal of Accounting and Economics 45, 221 - 247.
   source(\"http://canisius.edu/~yany/textAnalysis.R\")

//////////////////////////////////////
"

.C30EXPLAIN25<-"Retirement calculator 
//////////////////////////////////////
Source: http://money.cnn.com/calculator/retirement/retirement-need/
Step 1: estimate John Doe's final annual salary when he retires
	Input variables: 
         a) current salary
         b) salary growth rate (factor in the inflation rate)
         c) number of years before his retirement 

  For example, if John is 35 year-old and earning $50,000 now. If he plans  to retire 
      at 67, his final annual salary will be 50000*(1+g)^(67-35),g is the annual salary growth rate. 

Step 2: Estimate the required annual cash inflow for the first retirement year.
        For example, we could abetaume that the expected cash inflow for the 
        first year after retirement is 80% or 85% of his/her last annual salary. 

Step 3: estimate how many years after a person's retirement.  
        For instance, this value is 25 if John's life expectancy is 92 and retries at 67 (92-67). 

Step 4: estimate the present value, at the time he retires, of a growing annuity
	Input values: the 1st cash flow, a growth rate and an appropriate discount rate

Step 5: Factor in the social security benefit (this could be another data case)
	Estimate the present value, at time of your retirement, of your Social Security benefit
	Input values:
	Monthly benefit
	Discount rate

Step 6: John's net required cumulative wealth when he retires 
        (the result of Step 4 minus the result of Step 5)

Step 7: estimate John's required saving from now to that year. 
	Such as the annual saving or percentage saving

Note: for Social benefits
PIA (Primary Insurance Amount) 
   (a) 90% of the first $896 of his/her average in dexed monthly earnings, plus
   (b) 32% of his/her average indexed monthly earnings over $896 and through $5,399, plus
   (c) 15% of his/her average indexed monthly earnings over $5,399.
        https://www.betaa.gov/oact/COLA/piaformula.html
//////////////////////////
"

.C30EXPLAIN26<-"Reverse mortgage calculator
//////////////////////////////////////
EXAMPLE #1: John Bosworth, Age 68
            Home Value - $250,000
            Home Equity - $210,000
            Approximate Mortgage Balance - $40,000
 Challenge: John is a widower who lives at home alone. He would like to 
            keep his home, but is having trouble making payments and meeting expenses. 
            His monthly mortgage payment is $611. Even with both Social Security 
            income and pension, he is still short by $187 per month...
 Solution:  John takes out a tax free reverse mortgage for $142,496. He takes a 
            lump sum of $40,000 and applies it to his existing mortgage and the 
            balance in monthly payments of $681. After paying the mortgage off 
            entirely, John's monthly income rises to $1,291. That's $611 per 
            month for the mortgage payment, plus another $681 from the reverse mortgage.
EXAMPLE #2
    Craig Jenkins, Age 82, and Sylvia Jenkins, Age 79 (reverse mortgages are 
    calculated using the age of the youngest home owner)
  	Home Value - $375,000
 	Home Equity - $375,000
  Challenge:
      Craig and Sylvia both take medication to stay in good health. The cost 
      of monthly meds and treatments makes it difficult for them to find the 
      money needed to maintain the quality of life they once enjoyed.
  Solution:
     They take out a tax free reverse mortgage with the option of one lump sum 
     totaling $218,419, or a monthly income of $1,495. The extra cash flow from 
     their reverse mortgage more than covers their monthly cost for medication, 
     and allows Craig and Sylvia more freedom with much lebeta strebeta.

 EXAMPLE #3
    Kathy Tobias, Age 63, and Rinaldi Tobias, Age 71 (reverse mortgages are 
     calculated using the age of the youngest home owner)
         Home Value - $165,000
         Home Equity - $165,000
    Challenge:
       Kathy and Rinaldi would like to spend their retirement traveling around 
       the U.S. in their RV, but don't have extra money they would need to help  
       pay for rising gas prices and other added travel expenses.
    Solution:
      They take out a tax free reverse mortgage of $82,419. This will give them  
      an extra $519 per month which they can use any way they'd like, and more 
      than supplements their need for gas and RV maintenance. 
EXAMPLE #4
       Gordon Penilla, Age 62, and Joanne Penilla, Age 65 (reverse mortgages are 
       calculated using the age of the youngest home owner)
           Home Value - $850,000
           Home Equity - $850,000
    Challenge:
        Gordon and Joanne have no real debts, and their monthly income is  
        adequate for them to live life as planned, but they would like to 
        help out with the cost of college tuition for a grand child. For that, 
        their income monthly and savings do not suffice.
    Solution:
       Gordon and Joanne take out a tax free reverse mortgage credit line allowing 
       up to $265,411. Each grandparent can now bestow a monetary gift to the grandchild, 
       the amount being that which is currently allowed by law.

  Note 1: Reverse mortgage proceeds are based upon the current interest rates at the time the 
          loan closes, the age of the youngest borrower, and the equity in the home. The examples 
          above are based on an interest rate of 6.26%.
  Note 2: Borrowers can lock rates in for 60 days from the date of application to the closing. 
          All rates adjust weekly, and the rate for closing is determined by the weekly rate  
          set on Tuesdays of each week (excluding Federal Holidays) and stay valid until the following Monday.

  http://www.seacoastreversemortgage.com/loanOptions/Custom%20Pages/Scenario%20Examples/
  http://www.kiplinger.com/article/retirement/T035-C000-S001-reverse-mortgages-risky-for-boomers.html

//////////////////////////////////////
"

.C30EXPLAIN27<-"SCF (Survey of Consumer Finances)
//////////////////////////
 To download all data, type
  .dumpSCF 

 Source of data 
    https://www.federalreserve.gov/econres/scfindex.htm

//////////////////////////
"

.C30EXPLAIN28<-"SEC 10-K (13-f) 
//////////////////////////////////////
What is 13-f?
--------------
  Form 13F-?Reports Filed by Institutional Investment Managers
  An institutional investment manager that uses the U.S. mail (or other means
  or instrumentality of interstate commerce) in the course of its businebeta, 
  and exercises investment discretion over $100 million or more in Section 
  13(f) securities (explained below) must report its holdings on Form 13F 
  with the Securities and Exchange Commibetaion (SEC).

  In general, an institutional investment manager is: (1) an entity that 
  invests in, or buys and sells, securities for its own account; or (2) 
  a natural person or an entity that exercises investment discretion over
  the account of any other natural person or entity. Institutional 
  investment managers can include investment advisers, banks, insurance 
  companies, broker-dealers, pension funds, and corporations.

  Form 13F is required to be filed within 45 days of the end of a calendar 
  quarter. The Form 13F report requires disclosure of the name of the 
  institutional investment manager that files the report, and, with respect
  to each section 13(f) security over which it exercises investment discretion, 
  the name and clabeta, the CUSIP number, the number of shares as of the end of 
  the calendar quarter for which the report is filed, and the total market value.

  Today, the financial statement analysis does not consider the holdings
    of financial institutions. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 Step 2: unzip one and write a SAS program to retrive data 
 Step 3: work on one zip file 
 Step 4: write SAS programs to generate many 
         individual SAS data sets for Forms 3, 4 and 5 
 Step 5: Make your data sets quite user friendly 
              
  Advantages with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate all insiders trades  
        d) you could generate some SAS, R or Python data sets
  https://www.sec.gov/fast-answers/answers-form13fhtm.html

//////////////////////////
"

.C30EXPLAIN29<-"SEC Forms 3, 4 and 5 
//////////////////////////////////////
What are Forms 3, 4, and 5?
.   Corporate insiders - meaning a company's officers and directors, and any beneficial owners 
   of more than ten percent of a clabeta of the company's equity securities registered under 
'  Section 12 of the Securities Exchange Act of 1934 - must file with the SEC a statement 
   of ownership regarding those securities. On August 27, 2002, the SEC adopted rules and 
   amendments to Section 16 of the Exchange Act, implementing the provisions of the 
   Sarbanes-Oxley Act of 2002 that accelerated the deadline for filing most insider 
   ownership reports.

   The initial filing is on Form 3. An insider of an ibetauer that is registering equity
   securities for the first time under Section 12 of the Exchange Act must file this 
   Form no later than the effective date of the registration statement. If the ibetauer 
   is already registered under Section 12, the insider must file a Form 3 within ten 
   days of becoming an officer, director, or beneficial owner.

  Changes in ownership are reported on Form 4 and must be reported to the SEC within 
  two businebeta days. You can find the limited categories of transactions not subject 
  to the two-day reporting requirement in the new rule.

  Insiders must file a Form 5 to report any transactions that should have been reported 
  earlier on a Form 4 or were eligible for deferred reporting. If a Form must be filed, 
  it is due 45 days after the end of the company's fiscal year.
 
  Today, the financial statement analysis has nothing to do with 
     insider trading. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 
 Step 2: unzip one and write a SAS program to retrive data 

 Step 3: work on one zip file 

 Step 4: write SAS programs to generate many 
         individual SAS data sets for Forms 3, 4 and 5 

 Step 5: Make your data sets quite user friendly 
              
  Advantages with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate all insiders trades  
        d) you could generate some SAS, R or Python data sets
  https://www.sec.gov/fast-answers/answersform345htm.html

//////////////////////////
"


.C30EXPLAIN30<-"SEC 10-K: BS, IS or CF 
//////////////////////////////////////
 This is a very intereting projects. 
 If you could generate BS or IS, it will be more than enough. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 
 Step 2: unzip one and write a SAS program to retrive data 

 Step 3: work on one zip file 

 Step 4: write SAS programs to generate many 
         individual SAS data sets or generate 
         one big SAS data set, 

 Step 5: Generate your own BS
         Method I: download latest several years 
                   BS from Yahoo!Finance
                   replicate with your data 
              
         Method II: generate your own BS

  Advantage with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate industry means such as 
                           CA
            Quick Ratio ----------
                           CL 

              CA is the current abetaets
              CL is the current liability 
         d) you could generate some SAS, R or Python 
            data sets
//////////////////////////
"


.C30EXPLAIN31<-"SEC filings 
//////////////////////////////////////
Objectives: 
----------
   1) Understand what is the usages of SEC filings 
   2) understand how to search SEC EDGAR platform
   3) download one quarterly file  and using Excel to explore 
      a) How many company
      b) how many CIK
      c) how many forms
      e) frequency of those forms
      f) others
   4) potential applications 

Sources
-------
   https://www.sec.gov/edgar.shtml
   https://www.sec.gov/forms
   https://www.sec.gov/Archives/edgar/full-index/

The first several lines from Q3 2017
-------------------------------------------
Description:           Master Index of EDGAR Dibetaemination Feed by Company Name
Last Data Received:    September 30, 2017
Comments:              webmaster@sec.gov
Anonymous FTP:         ftp://ftp.sec.gov/edgar/
  
Company Name                                                  Form Type   CIK         Date Filed  File Name
---------------------------------------------------------------------------------------------------------------------------------------------
(OurCrowd Investment in MST) L.P.                             D           1599496     2017-08-24  edgar/data/1599496/0001465818-17-000048.txt         
1 800 FLOWERS COM INC                                         10-K        1084869     2017-09-15  edgar/data/1084869/0001437749-17-015969.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028807.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028809.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028810.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028811.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028812.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028813.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028814.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028815.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028816.txt

Note: combine a) and b) below 
    a) https://www.sec.gov/Archives/

    b) 2017-08-24  edgar/data/1599496/0001465818-17-000048.txt 

   we have 
      https://www.sec.gov/Archives/edgar/data/1599496/0001465818-17-000048.txt
    
//////////////////////////////////////
"

.C30EXPLAIN32<-"SEC Mutual Fund Prospectus Risk/Return Summary Data Sets	
//////////////////////////
The Mutual Fund Prospectus Risk/Return Summary Data Sets provides text and
  numeric information extracted from the risk/return summary section of 
  mutual fund prospectuses. The data is extracted from exhibits to mutual 
  fund prospectuses tagged in eXtensible Businebeta Reporting Language (XBRL).
  The information is presented without change from the \"as filed\" submibetaions
  by each registrant as of the date of the submibetaion. The data is presented 
  in a flattened format to help users analyze and compare corporate disclosure 
  information over time and acrobeta registrants.

  The data sets will be updated quarterly. Data contained in documents filed 
  after 5:30PM Eastern on the last businebeta day of a quarter will be included
  in the subsequent quarterly posting.

  https://www.sec.gov/dera/data/mutual-fund-prospectus-risk-return-summary-data-sets

  The Mutual Fund Prospectus Risk-Return Summary Data Sets (PDF, 207 kb) 
  https://www.sec.gov/dera/data/rr1.pdf 
  provides documentation of scope, organization, file formats and table definitions.

//////////////////////////
"

.C30EXPLAIN33<-"Simulation to mimic a slot machine
//////////////////////////////////////
Objectives:
     1) understand related statistics
     2) apply the Excel randbetween() function 
     3) learn to link picture to a cell and 
     4) using the vlookup() function to search a table of pictures 

Task #1: A simple case with just three numbers
     Abetaume that we have three objects: apple, banana and eggplant, see below. 
 
    We enter three numbers and try to output three corresponding fruits by using the Excel vlookup() function. 
 
   Q1: What is the probability of winning, defined as matching three?
   Q2: Abetaume the cost of one play is $1, what is the winning price if this is a fair game ?
   Q3: What is the expected value, if the cost of one play is $1 and our winning price is $7?

Task #2: Design a slot machine with 3 objects with pictures. 
   Step 1: generate the following entries. 
           Below, we use C16 for apple as an example. Searching online 
           to find a apple image. Right click the picture of apple, then choose \"format picture\". 
 	 
   Step 2: we manually enter three numbers in cells B3, C3 and D3, 
           Our objective is to search our picture table (fruit pictures) 
           to output corresponding three fruits. In this case, we expect 
           to see apple, apple and banana.
 
   Step 3: Click cell C16 (not apple but the cell), copy, then select 
           our destination cell, i.e., F3, then from Paste link to choose 
           \"Lined Picture (I)\", see the right image below. 
 	 
    Step 4: Click \"Formula\", \"Define Name\", see below, where X will 
            be our image column, i.e., C16:C18, Y is our indicator, B3, 
            Z is our number columns, i.e., B16:B18. Below, we define a 
            name called firstNumber.  
 	 
    Step 5: Click picture in F3 and we replace =$C$16 with =firstNumber 
           (or other name you defined), see the right image above. Repeat 
           the same procedure for other two cells. 

 Task 3: Build a slot machine with 10 different fruits and abetaume that 
         the machine would have a slight advantage to the owner of the 
         machine, such as for 1 million plays, the casino would have a profit of $100. 

  Q4: What is the winning price if we have three same pictures?
  Q5:  What is your result after playing 100 times? 

  References 
      http://en.wikipedia.org/wiki/Slot_machine

//////////////////////////////////////
"

.C30EXPLAIN34<-"Simulation to mimic Black Jack 
//////////////////////////////////////
This is a 2-player game: a dealer and a player. Below, we abetaume 
     that you are the player. 

  Rule #1: cards 2 to 10 have their face value, while J, Q, and K 
            are worth 10 points and Ace is worth either 1 or 11 
            points (player's choice).
  Terminology:
    Blackjack          : one A plus any card worth 10 points. 
    Lose               : the player's bet is taken by the dealer.
    Win                : the player wins as much as he bet.
    Blackjack (natural): the player wins 1.5 times the bet.
    Push               : the player keeps his bet, neither winning nor losing money.

 Step 1: the dealer draw two cards, one face up, while the player draw two cards (face up) 

  Step 2: the player could draw the third card 

   Win or lose: if the sum of your cards is lebeta than 21 and 
         is bigger than dealer's, you win. 

    http://www.pagat.com/banking/blackjack.html

//////////////////////////////////////
"

.C30EXPLAIN35<-"Spread estimation from daily price 
//////////////////////////////////////
  Spread is defined as the difference between ask and bid

  Generally, the difference between two prices or interest rates. In stock trading, 
    the difference between the current bid and ask prices for a stock (the bid/ask or 
    bid/offer spread). In futures trading, the price difference between delivery 
    months for the same commodity or abetaet. In bond trading, the difference between 
    yields of bonds with similar quality and different maturities, or of different 
    quality and the same maturity. In underwriting, the difference between what the 
    ibetauer receives from the underwriter and what the underwriter receives from the 
    public (underwriting spread).

         http://lexicon.ft.com/Term?term=spread

Roll (1984) designs a method to estimate the spreads by using the 
    first order covariance of price changes. 

       S=2 *sqrt(-cov(A, B) )                         (1)

          where A= deltaP(t-1)
                B= deltaPP(t)	

 Objectives for this term-project
      1) understad how to download and procebeta daily data from Yahoo!finance
      2) understand the logic behind the above forumla
      3) estimate Roll's spread for a dozen stocks 	
      4) comment on your results

   The first 6 stock symbols are given below. 
        Company name               Ticker Industry
        --------------             ----   ------
   1 Microsoft Corporation	   MSFT   Application software
   2 Apple Inc.                    AAPL   Personal Computer
   3 Citigroup Inc.                C      Money Center Banks
   4 Wal-Mart Stores, Inc.         WMT    Discount, Variety Stores
   5 Home Depot, Inc.              HD     Home improvement services
   6 ...                           ...    ...
   12 General Electric Corporation GE     Technology
//////////////////////////////////////
"

.C30EXPLAIN36<-"Spread estimation from TAQ (Trade and Quote) high-frequency data 
//////////////////////////////////////
Objectives:
   1)  Understand the structure of TAQ database
   2)  Using Excel to retrieve data from one day's data sets
   3)  estimate the spread for 10 stocks

  High-Frequency trading has attracted lots of attention because of its 
  huge profits and because of  it is not clear whether it is fair to small 
  investors and its impact on the health of the stock market. According to 
  Investopedia, HFT (High-Frequency Trading) is defined as: A program trading 
  platform that uses powerful computers to transact a large number of orders 
  at very fast speeds. High-frequency trading uses complex algorithms to analyze 
  multiple markets and execute orders based on market conditions. Typically, the 
  traders with the fastest execution speeds will be more profitable than traders 
  with slower execution speeds. As of 2009, it is estimated more than 50% of exchange 
  volume comes from high-frequency trading orders.  To understand HFT, we have to 
  understand TAQ (Trade and Quote) database. 

  Data Sets: November 1, 2004 is randomly selected as our day, see its 4 
     data sets below. Two index files have an extension of \".idx\", while 
     two data files have an extension of \".bin\".
  
  12/01/2004  04:03 PM     1,800,548,334 Q200411a.bin
  12/01/2004  04:03 PM           182,424 Q200411a.idx
  12/01/2004  04:08 PM       184,899,853 T200411a.bin
  12/01/2004  04:08 PM           169,334 T200411a.idx
                4 File(s)  1,985,799,945 bytes
    References
   Philips, Matthew, What Michael Lewis Gets Wrong About High-Frequency Trading, 4/1/2014
   http://www.bloomberg.com/bw/articles/2014-04-01/what-michael-lewis-gets-wrong-about-high-frequency-trading

   Appendix A: first several lines from CQ (consolidated Quotes) from TAQ
   symbol	date	time	bid	ofr	bidsiz	ofrsiz	mode	EX	MMID
   A	20040401	8:00:02	30.62	32.64	1	1	12	P	 
   A	20040401	8:11:40	29.68	33.58	20	20	12	P	 
   A	20040401	8:12:56	30.7	33.58	2	20	12	P	 
   A	20040401	8:30:02	0	0	0	0	12	T	BRUT
   A	20040401	8:30:02	1	100	1	1	12	T	CAES
  A	20040401	8:30:02	0	0	0	0	12	T	DATA
  A	20040401	8:30:02	0	0	0	0	12	T	MADF

  Table 1: structure of a binary index file. The size (bit) of an index file is 22 with 4 variables.
   #	Name of the variable	Meaning	Size	Type
   1	Ticker	Stock symbol	10	Character
   2	Date	Trading date	4	Integer
   3	Begrec	Beginning record	4	Integer
   4	Endrec	Ending record	4	Integer

  Table 2: Structure of binary CT (Consolidated Trade) file. The size is 29 with 8 variables.
   #	Name of the variable	Meaning	Size	Type
   1	Time 	Trading time	4	Integer
   2	Price	Trading price	8	Float
   3	Tseq	Sequence number 	4	Integer
   4	Size	Trading size	4	Integer
   5	G127	G127 rule	2	Integer
   6	CORR	Correction 	2	Integer
   7	COND	Sale condition	4	Character
  8	Ex	Exchange	1	Character

  Table 3: Structure of a binary CQ (Consolidated Quote) file. The size is 39 with 9 variables.
  #	Name of the variable	Meaning	Size	Type
  1	Time 	Trading time	4	Integer
  2	Bid	Bid price	8	Float
  3	Ofr	Ask price  	8	Float
  4	Qseq	Sequence number	4	Integer
  5	Bidsiz	Bid size	4	Integer
  6	Asksiz	Ask size 	4	Integer
  7	MODE	quote condition  	2	Integer
  8	EX	Exchange	1	Character
  9	MMID	NASDAQ market maker	4	Character
 
//////////////////////////////////////
"

.C30EXPLAIN37<-"Test of the January Effect using Excel 
//////////////////////////
If the Efficient Market Hypothesis (EMH) holds, we should not expect many market 
anomalies such as January Effect, Weekday Effect, momentum strategy (buy winners 
and sell losers). However, many researchers and profebetaionals have found that 
returns in January are quite different from other months. 

Question:  Are January returns statistically different from other months?
            
          mean return for January = mean return of none-January  (1)

   Choose about a dozen stocks to test the existence of so-called 
   January effect. A few companies are listed below. Note that S&P500 
    is listed as well. 

    I   Company name      Ticker   Industry
    --  -------------     -----   -------
    1	Wal-Mart          WMT     Superstore
    2	Apple Inc.        AAPL    Computer 
    3	Citi Group        C       Financial Company
    4	International
        Businebeta Machine IBM      Computer 
    5	Microsoft        MSFT     Computer 
    6	...              ...      ...		
    13  S&P500           ^GSPC    Market index

 Step 1: Download monthly price data from Yahoo 
             finance (http://finance.yahoo.com)
 Step 2: Estimate monthly returns

 Step 3:  Sort those monthly returns into two groups: returns 
             in January and returns in other months. 

 Step 4: For each stock/index, test whether its two means 
         are equal, see the above equation. 

 Comments on your results. 

//////////////////////////
"

.C30EXPLAIN38<-"TORQ database 
//////////////////////////////////////
 The TORQ database contains transactions, quotes, order procebetaing data 
     and audit trail data for a sample of 144 NYSE stocks for the three
     months November, 1990 through January 1991. This document covers 
     installation,formatting and use of the data.

 Conceptual and institutional details concerning the data are given 
      in a companion publication Hasbrouck and Sosebee (1992).

 Manual, by Joe Hasbrouck
    http://people.stern.nyu.edu/jhasbrou/Research/Working%20Papers/TORQDOC3.PDF

//////////////////////////////////////
"

.C30EXPLAIN39<-"Updating a monthly Excel data set and write an instruction 
//////////////////////////
First, let's download the Excel data set
     http://canisius.edu/~yany/data/monthlyYan.xlsx

The structure of this date set is very simple:
      Three columns: ID, Date and Value, see the first selvera lines below. 

    ID    date         value
    --    ---------    ------
    A     11/30/1999   38.96
    A     12/31/1999   71.39
    A     1/31/2000    61.12
    A     2/29/2000    95.91
    A     3/31/2000    96.03
    A     4/28/2000    81.83
    A     5/31/2000    67.98
    A     6/30/2000    68.1
    A     7/31/2000    37.63
    A     8/31/2000    56.33

  Note 
  (1) The frequency of the data set is monthly. 
  (2) \"A\" is the stock ticker 
  (3) For stocks, the last column called value 
      is the monthly adjusted price. 
  (3) for SMB (Fama-French factor), value is for factor, 
         i.e., return

  Do the following things:
     (a) find out all unique ID's
     (b) update the data set
     (c) write a 2-page manual on how to use this data set
         i) how to estimate monthly returns
         ii) how to estimate annual returns
         iii) how to generate a n-stock matrix, such as 5-stocks matrix

//////////////////////////
"

.C30EXPLAIN40<-"Projects taken already 
/////////////////////////////////////////////////////////////
  Name of topic                     Group                            Presentation 
 ------------------------          ------------------               ------------
 Testing the January-Effect         Matt,Elena,Muhammad              11/21
 Financial Statement Analysis       Claire,Paige,Julia,Monica
 Retirement calculator              Chris, Zach, Paul                12/5
 Bankruptcy prediction/Z-score      Msaada, Brannon, Mark
 Benford Law & Accounting Fraud     Mason, Patrick 
 Simulation to mimic a slot machine Lauren, Julie, Jebeta, and Jill    11/21
 SEC 10-K: BS, IS or CF topic.      Patrick, Ben,Ben,Mellibetaa        12/5
 SEC Filing                         Gabriella, Caitlin, Maria        12/5
 Black Jack Machine                 Joseph
 Updating a monthly Excel data set  Brian                         

/////////////////////////////////////////////////////////////
"

.C31EXPLAIN40<-.C30EXPLAIN40

.tp<-.chapter30
.termProjects<-.chapter30


"
 Census Congrebetaional Districts 115
  Census Congrebetaional Districts 113 
         Census Demographic profile
     Census Redistribution
  TORQ database 
         SEC 10-K: BS, IS or CF
  Census Summary Form 2 (SF2)
 SEC 10-K (Forms 3, 4 and 5)    
  SEC 10-K (13-f) 
  SEC Mutual Fund Prospectus 
 Census Summary Form 1 (SF1)	
 00Requirements for a term project   
 Retirement calculator  
 Best model(CAPM,FF3,FFC4,FF5)?         
 Test of the January Effect using Excel 
 Bankruptcy prediction by using Z-score
 Updating a monthly Excel data set
  Momentum trading strategy 
  52-week high trading strategy 
  Max trading strategy 
  Spread estimation from daily price
 Event Study using Excel                
  Simulation to mimic a slot machine     
  Simulation to mimic Black Jack 
  Benford Law & accounting fraud         
  Readability 10-K/firms' performance    
 Businebeta cycle indicator
  illiquidity measure,Amihud(2002)       
  Liquidity, Pastor/Stambough(2003)
  Spread estimation from TAQ 
  Reverse mortgage calculator
  KMV model & default probability
  Financial statement analysis
  Black-Litterman model 
  Brandt et al. model (2009) for portfolio 
  SEC filings
 SCF (Survey of Consumer Finance) 
 Extra high-frequency data 
  Building a slot machine 
  ZZProjects taken 



"

# x<-readLines("clipboard")
#  a<-gsub("^ *","",x)

#  b<-sort(a)
#  d<-paste(1:40," ",b)
# e<-cbind(d[1:20],d[21:40])
#  write.table(e,file="c:/temp/t.txt",row.names=F,col.names=F,quote=F)


.chapter30<-function(i){
" i  Chapter 30: Term projects               i   Description 
  -  -------------------------------------   --  ----------------------
  1   Requirements for a term project       21   Liquidity, Pastor/Stambough(2003)
  2   52-week high trading strategy         22   Max trading strategy 
  3   Bankruptcy prediction using Z-score   23   Momentum trading strategy 
  4   Benford Law & accounting fraud        24   Readability 10-K/firms' performance    
  5   Best model(CAPM,FF3,FFC4,FF5)?        25   Retirement calculator  
  6   Black-Litterman model                 26   Reverse mortgage calculator
  7   Brandt et al. model (2009)/portfolio  27   SCF (Survey of Consumer Finance) 
  8   Building a slot machine               28   SEC 10-K (13-f) 
  9   Businebeta cycle indicator              29   SEC 10-K (Forms 3, 4 and 5)    
 10   Census Congrebetaional Districts 113    30   SEC 10-K: BS, IS or CF
 11   Census Congrebetaional Districts 115    31   SEC filings
 12   Census Demographic profile            32   SEC Mutual Fund Prospectus 
 13   Census Redistribution                 33   Simulation to mimic a slot machine     
 14   Census Summary Form 1 (SF1)	    34   Simulation to mimic Black Jack 
 15   Census Summary Form 2 (SF2)           35   Spread estimation from daily price
 16   Event Study using Excel               36   Spread estimation from TAQ 
 17   Extra high-frequency data             37   Test of the January Effect using Excel 
 18   Financial statement analysis          38   TORQ database 
 19   illiquidity measure,Amihud(2002)      39   Updating a monthly Excel data set
 20   KMV model & default probability       40   Projects taken 

 Example #1:>.c30     # see the above list
 Example #2:>.c30(1)  # see the first explanation

";.chapter30_(i)
}

.n30chapter<-40
.chapter30_<-function(i){
     .printEachQ(30,i,.n30chapter)
}
.c30<-.chapter30

.C30EXPLAIN1<-"Requrement of a term project 
//////////////////////////////////////
Objective: This is an integral part of this course. It could be viewed 
           as the application of  what you have learnt from this course 
           to a real-world situation. 

Format: Group project (each group could have up to three members) 
       
Topic:  Each group chooses one topic from a list of potential term 
        projects (first come and first served since each topic should 
        be chosed by just one group). 
        To find a list of potential projects, just type 
        .c30 

Three files: Each group should submit three files 
         a) An Excel file containts your final result and final data set
         b) a short report (maximum page limit: 15, double space, font of 11)
         c) A powerPoint file  

Dropbox : submit your files to the dropbox on D2L

Presentation:
         Each group would present their term project in front of the whole clabeta 

Due date:if you want my comments, you should submit your files 
         before your presenttaion. If not, you could submit your files after 
         your presentation. 

//////////////////////////
"

.C30EXPLAIN25<-"Retirement calculator 
//////////////////////////////////////
Source: http://money.cnn.com/calculator/retirement/retirement-need/
Step 1: estimate John Doe's final annual salary when he retires
	Input variables: 
         a) current salary
         b) salary growth rate (factor in the inflation rate)
         c) number of years before his retirement 

  For example, if John is 35 year-old and earning $50,000 now. If he plans  to retire 
      at 67, his final annual salary will be 50000*(1+g)^(67-35),g is the annual salary growth rate. 

Step 2: Estimate the required annual cash inflow for the first retirement year.
        For example, we could abetaume that the expected cash inflow for the 
        first year after retirement is 80% or 85% of his/her last annual salary. 

Step 3: estimate how many years after a person's retirement.  
        For instance, this value is 25 if John's life expectancy is 92 and retries at 67 (92-67). 

Step 4: estimate the present value, at the time he retires, of a growing annuity
	Input values: the 1st cash flow, a growth rate and an appropriate discount rate

Step 5: Factor in the social security benefit (this could be another data case)
	Estimate the present value, at time of your retirement, of your Social Security benefit
	Input values:
	Monthly benefit
	Discount rate

Step 6: John's net required cumulative wealth when he retires 
        (the result of Step 4 minus the result of Step 5)

Step 7: estimate John's required saving from now to that year. 
	Such as the annual saving or percentage saving

Note: for Social benefits
PIA (Primary Insurance Amount) 
   (a) 90% of the first $896 of his/her average in dexed monthly earnings, plus
   (b) 32% of his/her average indexed monthly earnings over $896 and through $5,399, plus
   (c) 15% of his/her average indexed monthly earnings over $5,399.
        https://www.betaa.gov/oact/COLA/piaformula.html
//////////////////////////
"

.C30EXPLAIN5<-"Best model? CAPM, FF3, FFC4, or FF5
//////////////////////////
Objectives of this term project
    1) understand different models: CAPM, FF3, FF4 and FF5
    2) Understand how download and procebeta data 
    3) Understand the T-value F-values and adjusted R2

a) CAPM: R(IBM) = Rf + beta*(Rm - Rf)                         (1)
            where R(IBM) is the IBM's mean return or expected return 
            Rf is the risk-free rate
            Rm is the market mean return or expected return 

b) FF3 Fama-French 3-factor model:
         R(IBM) = Rf + beta1*(Rm - Rf)+beta2*SMB + beta3*HML  (2)
            where SMB is small minus big, HML is high book-to-market 
            ratio portfolio minus low ratio portfolio 

c) FF4 is the Fama-French-Carhart 4 factor model 
         R(IBM) = ff3 + beta4*MOM                             (3)
            Where MOM is momentum factor
                      
d) FF5 is the Fama-French 5-factor model:
         R(IBM) = ff3  + beta4**RMW + beta5*CMA               (4)
            where RMW is Robust minus weak, CAM is 
               conservative minus Aggrebetaive
  Three questions:
      1)   Which criterion?
      2)   The performance is time-period independent?
      3)   In-sample estimation vs. out sample prediction

   We use the adjusted R2 as our criterion to measure the performance of each model. 
      Step 1: download monthly price data from Yahoo!Finance
      Step 2: choose a period to run various models  
      Step 3: summarize your testing results  (sample statistics)
      Step 4: (Optional: out-of-sample prediction)

source of data: 
       1) http://finance.yahoo.com
       2) http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html

//////////////////////////
"

.C30EXPLAIN37<-"Test of the January Effect using Excel 
//////////////////////////
If the Efficient Market Hypothesis (EMH) holds, we should not expect many market 
anomalies such as January Effect, Weekday Effect, momentum strategy (buy winners 
and sell losers). However, many researchers and profebetaionals have found that 
returns in January are quite different from other months. 

Question:  Are January returns statistically different from other months?
            
          mean return for January = mean return of none-January  (1)

   Choose about a dozen stocks to test the existence of so-called 
   January effect. A few companies are listed below. Note that S&P500 
    is listed as well. 

    I   Company name      Ticker   Industry
    --  -------------     -----   -------
    1	Wal-Mart          WMT     Superstore
    2	Apple Inc.        AAPL    Computer 
    3	Citi Group        C       Financial Company
    4	International
        Businebeta Machine IBM      Computer 
    5	Microsoft        MSFT     Computer 
    6	...              ...      ...		
    13  S&P500           ^GSPC    Market index

 Step 1: Download monthly price data from Yahoo 
             finance (http://finance.yahoo.com)
 Step 2: Estimate monthly returns

 Step 3:  Sort those monthly returns into two groups: returns 
             in January and returns in other months. 

 Step 4: For each stock/index, test whether its two means 
         are equal, see the above equation. 

 Comments on your results. 

//////////////////////////
"

.C30EXPLAIN3<-"Bankruptcy prediction by using Z-score
//////////////////////////
The Altman's Z score is used to predict the pobetaibility of a firm goes 
    to bankruptcy. This score is a weighted average of 5 ratios based 
    on a firm's balance sheet and income statement. For public firms, 
    Altman (1968) offers the following formula. 

     Z=3.3*X1+0.99*X2+0.6*X3+1.2*X4+1.4*X5, 			(1)

    where the definitions of X1,X2,X3,X4 and X5 are given in the following table. 
      Variable	Definition 
      --        -------------
      X1        EBIT/Total Abetaets
      X2        Net Sales/Total Abetaets
      X3        Market Value of Equity/Total Liabilities
      X4        Working Capital/Total Abetaets
      X5        Retained Earnings/Total Abetaets

    Based on the ranges of z-scores, we could clabetaify public firms 
         into following 4 categories. Eidlenan (1995) finds that the 
         Z score correctly predicted 72% of bankruptcies two years 
         prior to the event.

        Z-score range	Description
        -------------   --------------
          > 3.0          Safe
          2.7 to 2.99    On Alert. 
          1.8 to 2.7     Good chances of going bankrupt within 2 years. 
          < 1.80         Probability of Financial distrebeta is very high 

    References
       Altman, Edward I.,2000,Predicting Financial Distrebeta of Companies, 
           Retrieved on September 4th, 2009 from http://pages.stern.nyu.edu/~ealtman/Zscores.pdf

       Altman, Edward I,1968,Financial Ratios, Discriminant Analysis and the 
           Prediction of Corporate Bankruptcy, Journal of Finance,189-209.
       
       Eidleman, Gregory J.,1995,Z-Scores - A Guide to Failure Prediction, 
           The CPA Journal Online, https://www.easycalculation.com/statistics/altman-z-score.php

//////////////////////////
"

.C30EXPLAIN39<-"Updating a monthly Excel data set and write an instruction 
//////////////////////////
First, let's download the Excel data set
     http://canisius.edu/~yany/data/monthlyYan.xlsx

The structure of this date set is very simple:
      Three columns: ID, Date and Value, see the first selvera lines below. 

    ID    date         value
    --    ---------    ------
    A     11/30/1999   38.96
    A     12/31/1999   71.39
    A     1/31/2000    61.12
    A     2/29/2000    95.91
    A     3/31/2000    96.03
    A     4/28/2000    81.83
    A     5/31/2000    67.98
    A     6/30/2000    68.1
    A     7/31/2000    37.63
    A     8/31/2000    56.33

  Note 
  (1) The frequency of the data set is monthly. 
  (2) \"A\" is the stock ticker 
  (3) For stocks, the last column called value 
      is the monthly adjusted price. 
  (3) for SMB (Fama-French factor), value is for factor, 
         i.e., return

  Do the following things:
     (a) find out all unique ID's
     (b) update the data set
     (c) write a 2-page manual on how to use this data set
         i) how to estimate monthly returns
         ii) how to estimate annual returns
         iii) how to generate a n-stock matrix, such as 5-stocks matrix

//////////////////////////
"

.C30EXPLAIN23<-"Momentum trading strategy 
//////////////////////////
We could use a simple phrase to summarize the so-called momentum trading strategy: 
      buy winners and sell losers. 

Here, we have an implied abetaumption: within a short-term (between 3 months 
     and 12 months), the winner will remain a winner while a loser would 
     continue to be a loser. Two related questions: 1) how to define a winner 
     from a loser? 2) how to conduct a test?

Objectives of this term project:
     1) learn how to download a few hundred stock data 
     2) Understand how to use Excel to retrieve and procebeta data 
     3) Prove or disapprove so-called momentum strategy 
        by replicating Table 1 of Jegadeesh and Titman (1993) 
        [They use all stocks, while you would use just a few hundred stocks]

  Prerequisites:  accebeta to an Excel ata set called monthlyYan.xlsx (I will supply this data set)
  Ba sic logic:   According to Jegadeesh and Titman (1993) it is a profitable trading 
                  strategy if we buy the past winners and sell the past losers.  

   Notations: 	Check the past K-month returns, and then form a portfolio for L months, 
     Where K=3,6,9 and 12 and L=3, 6, 9 and 12. Below we use K=L=6 as an example. 
     Trading strategy: Estimate all stocks' past 6- month returns and sort stocks 
      into 10 groups (deciles) according to their 6-month total returns. Long 
       the top decile (winners) and short the bottom decile (losers) for the next 6 months. 
   
   Procedure:
       Step 0: Starting month: January 1927
       Step 1: Retrieve CRSP data (PERMNO, DATE and RET)
       Step 2: Estimate past 6-month cumulative returns R_t^6month
       Step 3: Sort all stocks into deciles according to their cumulative 6-month returns
       Step 4: Long winners (best return group) and short losers for the next 6-month
       Step 5: Estimate portfolio returns
       Step 6: Move to the next month and repeat the above steps until the 
               last month 
 References
      Jegadeesh Narasimhan and Sheridan Titman, 1993, Returns to Buying Winners and 
           Selling Losers: Implications for Stock Market Efficiency, Journal of Finance 
           48 (1), 65-91.
 
     Appendix A: Table 1 from Jegadeesh and Titman (1993).

//////////////////////////
"

.C30EXPLAIN2<-"52-week high trading strategy 
//////////////////////////////////////
George and Huang (2004) show that we could design a profitable trading 
   strategy based on the 52-Week High. First, they estimate a ratio by 
   dividing today's price by its 52-week high. Based on such a ratio, 
   all stocks are sorted from the highest to the lowest. The stocks 
   belong to the top (bottom) 30% are labeled as winners (losers). Again, 
   the trading strategy is to buy winners and sell losers. They demonstrate 
   that such a trading strategy is quite profitable with an average return 
   difference of 0.45% per month between the winner and loser portfolios. 

Several versions of this project:
   version #1: just test one or two stocks
   Version #2: test a few hundred
   Version #3: test all stocks  [you need a financial database called CRSP]

Objectives of this term project:
   1) Understand how to download daily data from Yahoo!Finance [see above versions #1 or #2]
   2) Understand how to use Excel to procebeta data 
   3) Prove or disapprove so-called 52-week High trading strategy 

 Time period: as long as pobetaible        [versions #1 or #2] 
              July 1963 to December 2001 [Version #3] 

 Basic logic: According to George and Huang (2004) it is a profitable 
              trading strategy if we based on the ratio of the current 
              stock price divided by its 52-week High

 Trading strategy: Estimate all stocks' 52-week high, estimate the ratio 
     of today's price over its 52-week High, sort them from the highest 
     to the lowest. Treat the top 30% as winners and bottom 30% as losers. 
     Buy winner and sell losers. 

Procedure for version #1:
  Step 0: formulate your trading strategy: 
             ratio > 0.8 you buy
             ratio < 0.3 you sell
                                     price - 52wLow
      Definition #1:  ratio  = ---------------
                                   (52wHigh - 52wlow)

                                  price
      Definition #2   ratio =   -----------
                                  52wHigh
Procedure for Version #1:
  Step 1: download one stock from Yahoo!finance as early as pobetaible 
  Step 2: estimate returns
  Step 3: sort data from the earlest to the latest
  Step 4: starting from 253 observation, estimate 52wHigh and 52wLow
  Step 5: calculate the ratio 
  Step 6: based on your trading strategy, you long or short for the next period
  Step 7: Generate a column for return for this trating strategy
  Step 8: test whether this is a profitable trading strategy 
          compared with the long-only strading strategy

Procedure for versions #2 and #3:
  Step 1: load data sets stockDaily and stockMonthly
  Step 2: Starting month: July 1963
  Step 3: Estimate  all stocks' 52-week High and estimate the ratio Price/52-week high  
  Step 4: Sort all stocks from highest to lowest 
  Step 5: choose top 30% as winners and bottom 30% as losers
  Step 6: estimate equal-weighted portfolios return for both winner and looser portfolios
  Step 7: Move to the next month and repeat the above steps until the last month (December 2001)
  Step 8: test 
  
 References
     George, Thomas J, and Chuan-Yang Huang, 2004, The 52-week High and Momentum 
           Investing, Journal of Finance 54, 5, 2145-2176.

//////////////////////////////////////
"

.C30EXPLAIN32<-"Max trading strategy 
//////////////////////////////////////
 Bali, Cakici and Whitelaw (2011) find that sorting stocks by their 
    maximum daily returns (MAX) in the previous month could produce a 
    monthly return difference of more than 1% between the lowest and 
    highest MAX deciles.  

    In addition, the alphas from running Fama-French-Carhart 4-factor
    model for those two extreme portfolios are significantly different. 
    Thus, we could design a profitable trading strategies based on stocks'
    last month extreme daily returns. 

There are several versions of this term project:
   version #1: just test 20 to 40 stocks
   Version #2: test a few hundred
   Version #3: test all stocks   [you need a financial database called CRSP]

Objectives of this term project (version #1):
   1) Understand how to download data from Yahoo!Finance
   2) Prove or disapprove so-called the max-trading strategy

Objectives of this term project (version s #2 and #3):
   1) Understand the CRSP database
   2) Understand how to use Excel or R to retrieve and procebeta data 
   3) Prove or disapprove so-called the max-trading strategy by 
        replicating Table 1 of Bali et al. (2011).

 Prerequisites (version #3):  stockDaily and stockMonthly.RData 
    Basic logic: According to Bali et al. (2011) some investors like stocks with 
              lottery-type payoffs which have big past returns with a small probability. 
    Period:	July 1962 to December 2005

 Trading strategy: Estimate all stocks' maximum returns in the last month, 
    sort stocks into 10 groups (deciles) according to their last month's 
    maximum daily returns. Long the top decile (winners) and short the 
    bottom decile (losers) for one month. 

Procedure (for versions #1): Abetaume that you have 40 stocks 
     Step 0: donwload daily/monthly price data for those stocks
     Step 1: estimate daily returns 
     Step 2: Using pivoTable to generte some thing below 
                           stock1   stock2  stock3 ..    stock40
                YYYYMM1    maxValue   x       x            x
                YYYYMM2     x         x       x            x 

             Note: maxValue is the maxium value for stock1 in the previous month. 

    Step 3: choose your portfolio: long 10% and short bottom 10%. 
            In other words, long 4 stocks with highest max returns in the previous month. 
            short 4 stocks with the lowest max returns in the previous
    Step 4: Eestimate portfolio returns of your long short portfolio 
    Step 6: move to the next month and repeat 
    Step 7: test your result. 

Procedure (for versions #3):
	Step 0: Starting month: July 1962
	Step 1: load stockDaily 
	Step 2: Estimate the maximum daily returns of the previous month, i.e., May 1962
	Step 3: Sort all stocks into deciles according to their maximum last month daily returns 
	Step 4: Long the top 10% and short the bottom 10%
	Step 5: load stockMonthly and estimate portfolio returns and their difference
      Step 6: Move to the next month and repeat the above steps until the last month (December, 2005)

  References
     Bali, Turan G., Nusret Cakici, and Robert F. Whitelaw, 2011, Maxing Out: 
        Stocks as Lotteries and the Crobeta-Section of Expected Returns, Journal 
        of Financial Economics 99 427-446.

//////////////////////////////////////
"

.C30EXPLAIN35<-"Spread estimation from daily price 
//////////////////////////////////////
  Spread is defined as the difference between ask and bid

  Generally, the difference between two prices or interest rates. In stock trading, 
    the difference between the current bid and ask prices for a stock (the bid/ask or 
    bid/offer spread). In futures trading, the price difference between delivery 
    months for the same commodity or abetaet. In bond trading, the difference between 
    yields of bonds with similar quality and different maturities, or of different 
    quality and the same maturity. In underwriting, the difference between what the 
    ibetauer receives from the underwriter and what the underwriter receives from the 
    public (underwriting spread).

         http://lexicon.ft.com/Term?term=spread

Roll (1984) designs a method to estimate the spreads by using the 
    first order covariance of price changes. 

       S=2 *sqrt(-cov(A, B) )                         (1)

          where A= deltaP(t-1)
                B= deltaPP(t)	

 Objectives for this term-project
      1) understad how to download and procebeta daily data from Yahoo!finance
      2) understand the logic behind the above forumla
      3) estimate Roll's spread for a dozen stocks 	
      4) comment on your results

   The first 6 stock symbols are given below. 
        Company name               Ticker Industry
        --------------             ----   ------
   1 Microsoft Corporation	   MSFT   Application software
   2 Apple Inc.                    AAPL   Personal Computer
   3 Citigroup Inc.                C      Money Center Banks
   4 Wal-Mart Stores, Inc.         WMT    Discount, Variety Stores
   5 Home Depot, Inc.              HD     Home improvement services
   6 ...                           ...    ...
   12 General Electric Corporation GE     Technology

//////////////////////////////////////
"

.C30EXPLAIN16<-"Event Study using Excel 
//////////////////////////////////////
 Based on Event Study, we test the impact of HSIC added to the S&P500 on March 18, 2015. 
 Source of data: http://canisius.edu/~yany/excel/eventStudy.xlsx
  
 The basic idea for Event Study is to test whether our AR (Abnormal Return) is 
     statistically significant. The definition of abnormal return is given below. 

           AP=realized return-expected return        (1)

  To estimate our expected return, we apply the following linear regrebetaion. 

	y = alpha + beta* x                           (2)

   where, y is the expected return and x is the market return on that day. 
      To estimate two parameters, alpha and beta, we run a linear regrebetaion or apply 
      related formulae by choosing an evaluation period of 252-day long, 
      starting the day before our event window counting backward, see below. 
             
             Estimation period                          Event-window
    |-------------------------------|-------------|----------|
	                   n days before      event-day   m-day after
 Here is the design. 
     i) The event day is 3/18/2015			
    ii) Our event window: 10 days before and 10 days after			
   iii) The estimation period: from 253 days before to one-day before our event window

 Thus, roughly we could download daily data from 2/1/2014 to 4/22/2015.
   Step 1: download daily price data from HSIC and S&P500 (^GSPC). 
   Step 2: Choose only adjusted price, see the left panel below.
             Then sort data from oldest to the latest, see the right panel below. 			
   Step 3: estimate daily returns, see the formula in D3.  				
   Step 4: Highlight our event day, a window around the event and the estimation period 
             For example, we could use red color for event day, 10-day before and 
             10-day after our event day. In addition, we could highlight our 
             estimation period green. 
   Step 5: Based on the estimation period, apply following formulae to estimate 
             intercept, slope, R2 and standard error				
             abetaume B column is for stock returns, C column is S&P500 returns
	    i) intercept      =intercept(B,C)
           ii) slope          =slope    (B,C)
          iii) R2             =rsq      (B,C)
           iv) standard error =steyx    (B,C)

    Step 6: Estimate, expected return, AR (abnormal return), 
            CAP (cumulative abnormal return) and T-AP (T-value for abnormal return)				

         Expected return            AP      CAR     T-value for AR
	  --------------            --      ---     --------------
			
	Expected return                        = intercept + slope * market			
	AR (abnormal return)                   = realized return - expected return			
	CAR (cumulative abnormal return)       = sum of all ARs up to today			
	T-value for AR                         = AR/standard error			

   Note: to make our spread sheet clean, we have two choices:
 	i) Hide many rows			
	ii) Copy above four output values to a place near our event window			
   Comment on your results. 			

 Source of S&P500 added and deleted
     https://en.wikipedia.org/wiki/List_of_S%26P_500_companies#Recent_changes_to_the_list_of_S&P_500_Components
     http://canisius.edu/~yan/excel/sp500added_deleted.xlsx
//////////////////////////////////////
"

.C30EXPLAIN33<-"Simulation to mimic a slot machine
//////////////////////////////////////
Objectives:
     1) understand related statistics
     2) apply the Excel randbetween() function 
     3) learn to link picture to a cell and 
     4) using the vlookup() function to search a table of pictures 

Task #1: A simple case with just three numbers
     Abetaume that we have three objects: apple, banana and eggplant, see below. 
 
    We enter three numbers and try to output three corresponding fruits by using the Excel vlookup() function. 
 
   Q1: What is the probability of winning, defined as matching three?
   Q2: Abetaume the cost of one play is $1, what is the winning price if this is a fair game ?
   Q3: What is the expected value, if the cost of one play is $1 and our winning price is $7?


Task #2: Design a slot machine with 3 objects with pictures. 
   Step 1: generate the following entries. 
           Below, we use C16 for apple as an example. Searching online 
           to find a apple image. Right click the picture of apple, then choose \"format picture\". 
 	 
   Step 2: we manually enter three numbers in cells B3, C3 and D3, 
           Our objective is to search our picture table (fruit pictures) 
           to output corresponding three fruits. In this case, we expect 
           to see apple, apple and banana.
 
   Step 3: Click cell C16 (not apple but the cell), copy, then select 
           our destination cell, i.e., F3, then from Paste link to choose 
           \"Lined Picture (I)\", see the right image below. 
 	 
    Step 4: Click \"Formula\", \"Define Name\", see below, where X will 
            be our image column, i.e., C16:C18, Y is our indicator, B3, 
            Z is our number columns, i.e., B16:B18. Below, we define a 
            name called firstNumber.  
 	 
    Step 5: Click picture in F3 and we replace =$C$16 with =firstNumber 
           (or other name you defined), see the right image above. Repeat 
           the same procedure for other two cells. 

 Task 3: Build a slot machine with 10 different fruits and abetaume that 
         the machine would have a slight advantage to the owner of the 
         machine, such as for 1 million plays, the casino would have a profit of $100. 

  Q4: What is the winning price if we have three same pictures?
  Q5:  What is your result after playing 100 times? 

  References 
      http://en.wikipedia.org/wiki/Slot_machine

//////////////////////////////////////
"

.C30EXPLAIN34<-"Simulation to mimic Black Jack 
//////////////////////////////////////
This is a 2-player game: a dealer and a player. Below, we abetaume 
     that you are the player. 

  Rule #1: cards 2 to 10 have their face value, while J, Q, and K 
            are worth 10 points and Ace is worth either 1 or 11 
            points (player's choice).
  Terminology:
    Blackjack          : one A plus any card worth 10 points. 
    Lose               : the player's bet is taken by the dealer.
    Win                : the player wins as much as he bet.
    Blackjack (natural): the player wins 1.5 times the bet.
    Push               : the player keeps his bet, neither winning nor losing money.

 Step 1: the dealer draw two cards, one face up, while the player draw two cards (face up) 

  Step 2: the player could draw the third card 

   Win or lose: if the sum of your cards is lebeta than 21 and 
         is bigger than dealer's, you win. 

    http://www.pagat.com/banking/blackjack.html

//////////////////////////////////////
"
.C30EXPLAIN4<-"Benford Law and accounting fraud detection
//////////////////////////////////////
 Benford Law is also called the First-Digit Law which gives different frequencies 
    for 9 first digits from 1 to 9.  Convention wisdom would conclude that each 
    (first) digit would have roughly the same frequency, i.e., 1/9=0.1111=11%.  
    
 However, according to the Benford Law, the lower is the value of a digit, 
    the higher is its probability. In other words, we will see more values 
    with leading digit of 1 than with the leading digit of 2. The probability 
    of each digit is given by the following formula. 

    Prob(d)=log10((d+1)/d)                          (1)

   where Prob() is the probability (frequency), d is the digit, and log10() 
      is the log function with a base of 10. For Excel, log10() is the same as log(). 

    Digit   Formula    probability
    ----    ----        ----
    1     =log10(2/1)   0.301
    2     =log(3/2)     0.176
    3     =log(4/3)     0.125
    4     =log(5/4)     0.097
    5     =log(6/5)     0.079
    6     =log(7/6)     0.067
    7     =log(8/7)     0.058
    8     =log(9/8)     0.051
    9     =log(10/9)    0.046
          ------------  -----
           Total        100%

 Objectives:
     1) understand Benford Law
     2) download about a dozen companies' annual reports
     3) estimate the distributions of the 1st digits
     4) report your results and discubeta

 Procedure:
    To download annual financial statements.
       Step 1: go to Yahoo!Finance  http://finance.yahoo.com/  
       Step 2: enter a ticker, such as IBM
       Step 3: find three types of financial statements. 
       Step 4: download those financial statements

   Note 1: the function to get the first digit is =left(cell, 1)
   Note 2: you could use the Excel countif() function. 

 References
    Accounting Web, 20 Ways You Can Detect Fraud, 2014, 
        http://www.accountingweb.com/aa/law-and-enforcement/20-ways-you-can-detect-fraud

    Sharma, Anuj, Prabin Kumar Panigrahi, 2012, A Review of Financial Accounting Fraud 
        Detection based on Data Mining Techniques, INternationla Journal of Computer 
        Aplication 39, 1, https://arxiv.org/ftp/arxiv/papers/1309/1309.3944.pdf

    MCGINTY, JO CRAVEN, 2014, Accountants Increasingly Use Data Analysis to Catch 
        Fraud, Auditors Wield Mathematical  Weapons to Detect Cheating,                 http://www.wsj.com/articles/accountants-increasingly-use-data-analysis-to-catch-fraud-1417804886

    Testing Benford Law, http://testingbenfordslaw.com/

    What is Benford Law,  https://en.wikipedia.org/wiki/Benford%27s_law#cite_note-Nigrini-19

//////////////////////////////////////
"

.C30EXPLAIN24<-"Readability of 10-K filings and firm's performance
//////////////////////////////////////
Objectives:
      1) Understand the usage of 10-K
      2) learn how to parse 10-K
      3) understand the Fog-index and learn how to calculate it for each 10-K filing
      4) Comments on your result

Source of data
      a) SEC EDGAR (Electronic Data Gathering , Analysis and Retrieval)
      b) I have all 10-K filings from Q1 1993 to Q2 2016 (the number of filings is 
           210,842 and the size is 440G)

Structure vs. unstructured data
    The unstructured information has a lion share of all information, 
    70% to 80% and it is reported that 80% of structured information 
    came from unstructured one. On the other-hand, SEC filings is an 
    important source of information (gold mine) since public companies, 
    certain insiders, and broker-dealers are required to make regular SEC filings. 

Text analysis
    Text is one of the most important informant belongs to unstructured 
       information. Text analysis, also called text mining, also referred 
       to as text data mining, roughly equivalent to text analytics, refers 
       to the procebeta of deriving high-quality information from text. 
       For example, we could look at the frequency of each words, keywords, 
       number of lines, sentences, frequency of positive words vs. negative, 
       tone of the speech etc. For example, let's look at the top used words 
       by Reagan in 1994 and Obama 2008, see below. Which one belongs to Obama?

 Text analysis for finance and accounting
      Applying text analysis to finance and accounting does not have a long history. 
      Li (2008) shows that the readability of 10-K filings has a statistically 
      significant impact on the performance of a firm's subsequent performance. 
      The readability measure used by Li (2008) is call Fog index defined below. 

              Fog index=0.4*(n+p)                  (1)  

    where, n is the average number of words per sentence, while p is  
           the percentage of complex words.  A complex word is a word has 
           more than two syllables.

    Because of defining and measuring readability in the context of financial 
       disclosures becomes important with the increasing use of textual analysis 
       and the SEC's plain English initiative, Lougran and McDonald (2015) show 
       that  the Fog Index-the most commonly applied readability measure - is poorly 
       specified in financial applications. Of Fog's two components, one is 
       mibetapecified and the other is difficult to measure. They suggest to use 
       the size of 10-K filing as a simple readability proxy and show that it 
       outperforms the Fog Index. Another added advantage is that it does not 
       require document parsing, thus facilitates replication. 

    According to Loughran and McDonald (2014), there are 632 different forms.  
       On the other hand, most researchers used only one or two forms, such 
.       as 10-K. Thus, the SEC filings \"database\" is a gold mine waiting to 
       be explored. 

 Reference
       Li, Feng, 2008, Annual report readability, current earnings, and earnings 
           persistence, Journal of Accounting and Economics 45, 221 - 247.
   source(\"http://canisius.edu/~yany/textAnalysis.R\")

//////////////////////////////////////
"

.C30EXPLAIN9<-"businebeta cycle indicator
//////////////////////////////////////
There exist many profitable trading strategies, such as the individual stock 
momentum, first documented in Jegadeesh and Titman (1993), the industry momentum 
in Moskowitz and Grinblatt (1999), the effect of the 52-week high price in George 
and Hwang (2004), and the effect of the maximum daily return in a month in 
Bali et al. (2011). However, Yan and Zhang (2016) argue that those profitable 
trading strategies would not be profitable during difficult time. In other words, 
investors would change their behavior during a recebetaion. 

Objectives:
   1) understand the concept of businebeta cycle
   2) generate a businces cycle indicator
   3) if pobetaible run CAPM by including this indicator 

    Source of data: 
      1) Businebeta cycle data is from the National Bureau of Economic Research center. 
             The original starting date is June 1854.  
      2) stock data is from Yahoo!Finance. 

    Comments on your result

References
   Bali, Turan G., Nusret Cakici, and Robert F. Whitelaw, 2011, Maxing Out: 
         Stocks as Lotteries and the Crobeta-Section of Expected Returns, 
         Journal of Financial Economics 99 427-446.

   George, Thomas J, and Chuan-Yang Hwang, 2004, The 52-week High and Momentum 
         Investing, Journal of Finance 54, 5, 2145-2176.

   Grinblatt, Mark, and Bing Han, 2005, Prospect theory, mental accounting, 
         and momentum, Journal of Financial Economic 78, 311-339.

   Jegadeesh, N., and S. Titman, 1993, Returns to Buying Winners and Selling 
         Losers: Implications for Stock Market Efficiency, Journal of Finance 48, 65-91.

   Moskowitz, Tobias, and Mark Grinblatt, 1999, Do industries explain momentum? 
         Journal of Finance 54, 2017-2069.

   Yan, Yuxing and Shaojun Zhang, 2016, Businebeta cycle, investors' preferences 
         and trading strategies, Frontiers of Businebeta Research in China (forthcoming)  

  Table 1 from Yan and Zhang(2016)
        For a peak, we abetaign a positive 1 while for a trough, we abetaign a 
        negative 1. Any months between those peaks and troughs, we linearly 
        interpolate, see Panel B below. P for Peak and T for Trough. T(t-1) 
        is for the pervious Trough and P(t-1) is for the previous Peak. 

   Contraction        Expansion	cycle
     Peak (P)	      Trough (T)	P to T	T(t-1) to P  T(-1) to T    P(t-1) to P
  -----------         -----------------  ------  ----------  -----------   -----
  May 1923(II)        July 1924 (III)      14    22           36           40
  October 1926(III)   November 1927 (IV)   13    27           40           41
  August 1929(III)    March 1933 (I)       43    21           64           34
  May 1937(II)        June 1938 (II)       13    50           63           93
  February 1945(I)    October 1945 (IV)     8    80           88           93
  November 1948(IV)   October 1949 (IV)    11    37           48           45
  July 1953(II)       May 1954 (II)        10    45           55           56
  August 1957(III)    April 1958 (II)       8    39           47           49
  April 1960(II)      February 1961 (I)    10    24           34           32
  December 1969(IV)   November 1970 (IV)   11   106          117          116
  November 1973(IV)   March 1975 (I)       16    36           52           47
  January 1980(I)     July 1980 (III)       6    58           64           74
  July 1981(III)      November 1982 (IV)   16    12           28           18
  July 1990(III)      March 1991(I)         8    92          100          108
  March 2001(I)       November 2001 (IV)    8   120          128          128
  December 2007(IV)   June 2009 (II)       18    73           91           81
//////////////////////////////////////
"

.C30EXPLAIN19<-"illiquidity measure, Amihud (2002)
//////////////////////////////////////
Objective: estimate 12 stocks' illiquidity measures for each month in 2016. 
     Note: you choose the last 6 stock yourself. Comments on your findings

     6 stock symbols are given below. 
        Company name            Ticker	Industry
        ----------------------  ------  ------------------
   1	Microsoft Corporation   MSFT    Application software
   2	Apple Inc.              AAPL    Personal Computer
   3	Citigroup Inc.             C    Money Center Banks
   4	Wal-Mart Stores, Inc.    WMT    Discount, Variety Stores
   5	Home Depot, Inc.          HD    Home improvement services
   ..   .................       ...     ......
  12	General Electric Corp     GE	Technology

 Amihud (2002) illiquidity measure uses the absolute daily return over 
   its corresponding trading dollar volume. A monthly stock illiquidity 
   measure is the mean of daily illiquidity measure.  
                   1                |Ri|
       illiq(t)=  --- * sum (--------------- )      (1)
                   n             pi * Vi

   where illiq(t) is a monthly illiquidity measure, n is the number of 
         trading days within the month, Ri is daily return on day i, 
         Vi is the trading volume on day i and Pi is the closing 
         price of the underlying stock on day i. 

   The Amihud illiquidity measure includes two components: 
        spread and the impact of trading. Illiquidity is the 
        opposite of liquidity, i.e., a higher value indicates a low 
        liquidity and a small value indicates a higher liquidity level. Why?

   Step 1: download daily price data from Yahoo Finance 
   Step 2: estimate daily returns and dollar trading volume
   Step 3: estimate the ratio
   Step 4: estimate monthly illiquidity measures
 References
    Amihud,Yakov,2002,Illiquidity and Stock returns,
       Journal of Financial Markets 5, 31-56.

//////////////////////////////////////
"
.C30EXPLAIN21<-"Liquidity measure, Pastor and Stambough (2003)
//////////////////////////////////////
Objectives: 
    1) Understand the logic of the measure
    2) Learn how to download and procebeta data from Yahoo!Finance
    3) estimate individual stock's liquidity 

  Basic logic:Pastor and Stambaugh (2003) design the following 
        regrebetaion to estimate individual stock's liquidity.  

            y(t)=alpha +beta1*x1(t-1)+ beta2*x2(t-1)+error(t)           (1)

    where,y(t) is the excebeta stock return on day t, the excebeta return is 
          defined as R(t)-Rm(t),  R(t) is the stock return, Rm(t) is the 
          market return at time t; x1(t-1) is the lagged stock return, 
          i.e., R(t-1), X2(t-1) is the lagged dollar trading volume, i.e., 
          x2(t-1)=P(t-1)*V(t-1), P(t-1) is the daily closing price of the stock 
          at t-1 and V(t-1) is the daily trading volume at t-1. 
          
    The regrebetaion is based on the daily data within each month with a 
         minimum number of observations of 15. The liquidity measure for an 
         individual stock in each month is defined as:
 
            	liquidity measure=beta2       (2)

     For the first trial, we ignore other constraints.  The Market liquidity 
         is the equally weighted individual stock's liquidity and scaled by 
         the market capitalization.
Procedure:
	Step 1: Retrieve daily data
	Step 2: generate y, x1, x2 for each stocks 
	Step 3: Run regrebetaion (1) to estimate beta2 for each month
References
    Pastor, L. & Stambaugh, R., 2003, Liquidity risk and expected stock returns. 
    Journal of Political Economy 111, 642-685.

//////////////////////////////////////
"

.C30EXPLAIN36<-"Spread estimation from TAQ (Trade and Quote) high-frequency data 
//////////////////////////////////////
Objectives:
   1)  Understand the structure of TAQ database
   2)  Using Excel to retrieve data from one day's data sets
   3)  estimate the spread for 10 stocks

  High-Frequency trading has attracted lots of attention because of its 
  huge profits and because of  it is not clear whether it is fair to small 
  investors and its impact on the health of the stock market. According to 
  Investopedia, HFT (High-Frequency Trading) is defined as: A program trading 
  platform that uses powerful computers to transact a large number of orders 
  at very fast speeds. High-frequency trading uses complex algorithms to analyze 
  multiple markets and execute orders based on market conditions. Typically, the 
  traders with the fastest execution speeds will be more profitable than traders 
  with slower execution speeds. As of 2009, it is estimated more than 50% of exchange 
  volume comes from high-frequency trading orders.  To understand HFT, we have to 
  understand TAQ (Trade and Quote) database. 

  Data Sets: November 1, 2004 is randomly selected as our day, see its 4 
     data sets below. Two index files have an extension of \".idx\", while 
     two data files have an extension of \".bin\".
  
  12/01/2004  04:03 PM     1,800,548,334 Q200411a.bin
  12/01/2004  04:03 PM           182,424 Q200411a.idx
  12/01/2004  04:08 PM       184,899,853 T200411a.bin
  12/01/2004  04:08 PM           169,334 T200411a.idx
                4 File(s)  1,985,799,945 bytes
    References
   Philips, Matthew, What Michael Lewis Gets Wrong About High-Frequency Trading, 4/1/2014
   http://www.bloomberg.com/bw/articles/2014-04-01/what-michael-lewis-gets-wrong-about-high-frequency-trading

   Appendix A: first several lines from CQ (consolidated Quotes) from TAQ
   symbol	date	time	bid	ofr	bidsiz	ofrsiz	mode	EX	MMID
   A	20040401	8:00:02	30.62	32.64	1	1	12	P	 
   A	20040401	8:11:40	29.68	33.58	20	20	12	P	 
   A	20040401	8:12:56	30.7	33.58	2	20	12	P	 
   A	20040401	8:30:02	0	0	0	0	12	T	BRUT
   A	20040401	8:30:02	1	100	1	1	12	T	CAES
  A	20040401	8:30:02	0	0	0	0	12	T	DATA
  A	20040401	8:30:02	0	0	0	0	12	T	MADF

  Table 1: structure of a binary index file. The size (bit) of an index file is 22 with 4 variables.
   #	Name of the variable	Meaning	Size	Type
   1	Ticker	Stock symbol	10	Character
   2	Date	Trading date	4	Integer
   3	Begrec	Beginning record	4	Integer
   4	Endrec	Ending record	4	Integer

  Table 2: Structure of binary CT (Consolidated Trade) file. The size is 29 with 8 variables.
   #	Name of the variable	Meaning	Size	Type
   1	Time 	Trading time	4	Integer
   2	Price	Trading price	8	Float
   3	Tseq	Sequence number 	4	Integer
   4	Size	Trading size	4	Integer
   5	G127	G127 rule	2	Integer
   6	CORR	Correction 	2	Integer
   7	COND	Sale condition	4	Character
  8	Ex	Exchange	1	Character

  Table 3: Structure of a binary CQ (Consolidated Quote) file. The size is 39 with 9 variables.
  #	Name of the variable	Meaning	Size	Type
  1	Time 	Trading time	4	Integer
  2	Bid	Bid price	8	Float
  3	Ofr	Ask price  	8	Float
  4	Qseq	Sequence number	4	Integer
  5	Bidsiz	Bid size	4	Integer
  6	Asksiz	Ask size 	4	Integer
  7	MODE	quote condition  	2	Integer
  8	EX	Exchange	1	Character
  9	MMID	NASDAQ market maker	4	Character
 
//////////////////////////////////////
"

.C30EXPLAIN26<-"Reverse mortgage calculator
//////////////////////////////////////
EXAMPLE #1: John Bosworth, Age 68
            Home Value - $250,000
            Home Equity - $210,000
            Approximate Mortgage Balance - $40,000
 Challenge: John is a widower who lives at home alone. He would like to 
            keep his home, but is having trouble making payments and meeting expenses. 
            His monthly mortgage payment is $611. Even with both Social Security 
            income and pension, he is still short by $187 per month...
 Solution:  John takes out a tax free reverse mortgage for $142,496. He takes a 
            lump sum of $40,000 and applies it to his existing mortgage and the 
            balance in monthly payments of $681. After paying the mortgage off 
            entirely, John's monthly income rises to $1,291. That's $611 per 
            month for the mortgage payment, plus another $681 from the reverse mortgage.
EXAMPLE #2
    Craig Jenkins, Age 82, and Sylvia Jenkins, Age 79 (reverse mortgages are 
    calculated using the age of the youngest home owner)
  	Home Value - $375,000
 	Home Equity - $375,000
  Challenge:
      Craig and Sylvia both take medication to stay in good health. The cost 
      of monthly meds and treatments makes it difficult for them to find the 
      money needed to maintain the quality of life they once enjoyed.
  Solution:
     They take out a tax free reverse mortgage with the option of one lump sum 
     totaling $218,419, or a monthly income of $1,495. The extra cash flow from 
     their reverse mortgage more than covers their monthly cost for medication, 
     and allows Craig and Sylvia more freedom with much lebeta strebeta.

 EXAMPLE #3
    Kathy Tobias, Age 63, and Rinaldi Tobias, Age 71 (reverse mortgages are 
     calculated using the age of the youngest home owner)
         Home Value - $165,000
         Home Equity - $165,000
    Challenge:
       Kathy and Rinaldi would like to spend their retirement traveling around 
       the U.S. in their RV, but don't have extra money they would need to help  
       pay for rising gas prices and other added travel expenses.
    Solution:
      They take out a tax free reverse mortgage of $82,419. This will give them  
      an extra $519 per month which they can use any way they'd like, and more 
      than supplements their need for gas and RV maintenance. 
EXAMPLE #4
       Gordon Penilla, Age 62, and Joanne Penilla, Age 65 (reverse mortgages are 
       calculated using the age of the youngest home owner)
           Home Value - $850,000
           Home Equity - $850,000
    Challenge:
        Gordon and Joanne have no real debts, and their monthly income is  
        adequate for them to live life as planned, but they would like to 
        help out with the cost of college tuition for a grand child. For that, 
        their income monthly and savings do not suffice.
    Solution:
       Gordon and Joanne take out a tax free reverse mortgage credit line allowing 
       up to $265,411. Each grandparent can now bestow a monetary gift to the grandchild, 
       the amount being that which is currently allowed by law.

  Note 1: Reverse mortgage proceeds are based upon the current interest rates at the time the 
          loan closes, the age of the youngest borrower, and the equity in the home. The examples 
          above are based on an interest rate of 6.26%.
  Note 2: Borrowers can lock rates in for 60 days from the date of application to the closing. 
          All rates adjust weekly, and the rate for closing is determined by the weekly rate  
          set on Tuesdays of each week (excluding Federal Holidays) and stay valid until the following Monday.

  http://www.seacoastreversemortgage.com/loanOptions/Custom%20Pages/Scenario%20Examples/
  http://www.kiplinger.com/article/retirement/T035-C000-S001-reverse-mortgages-risky-for-boomers.html

//////////////////////////////////////
"

.C30EXPLAIN20<-"KMV model and default probability
//////////////////////////////////////
Objective: 
   1) Estimate market value and its volatility for KMV model
   2) estmate default point
   3) estimate default probablity 

 KMV stands for Kealhofer, McQuown and Vasicek who found a company focusing 
    on measuring default risk. KMV methodology is one of the most important 
    methods to estimate the probability of default for a given company by 
    using its balance sheet information and the equity market information.  

 The objective here is to estimate the market value of total abetaets (A) and 
    its corresponding volatility (sigmaA). The result will be used to estimate 
    default distance and default probability. 

 The basic idea is to treat the equity of a firm as a call option and the debt is 
    its strike price. Let us look at the following simplest example. For a firm, 
    if its debt is $80 and equity is $20 then the total abetaets will be $100. 

 Abetaume that the abetaets jump to $110 and the debt remains the same, the equity 
    increases to $30. On the other hand, if the abetaets drop to $90, the equity 
    will be only $10. Since the equity holders are the residual claimer, their 
    value has the following exprebetaion. 

           E  = max?(abetaets - debt,0)=max?(A-D,0)          (1)

    Recall for a call option, we have the following payoff function. 

       Payoff(call) = max?(sT-K,0)                        (2)

   This means that we could treat equity as a call option with debt as 
      our exercise price.  With appropriate notations, we will have the 
      following formulae for a firm's equity. KMV model is defined below. 

             E=A*N(d1 )-e^(-rT) N(d2)

               ln?(A/D)+(r+0.5*sigma^2 )T
        d1 =   ---------------------------               (3)
                   sigmaA * sqrt(T)
        d2 =d1- sigmaA *sqrt(T)                         

  On the other hand, the following relationship between the volatilities 
     of the equity and the total abetaets holds. In the following equation, 
     we have  delta=dE/(dVA )=N(d1 ). 

         sigmaE=A/E
                       N(d1)*A*sigmaA
        delta_sigmaA=   -------------                    (4)
                           E
   Since d1 and d2 are defined by the above equations, we have two equations 
      for two unknown (A and sgimaA), see below. Thus, we could use a 
      trial-and-error or simultaneous equation method to solve for those 
     two unknowns.  Eventually, we want to solve the following two equations for A and s_A.

                 E=A*N(d1)-e^(-rT) *N(d2 )
                           A
                 sigmaE=  --- * N(d1)*siamgA             (5)
                           E
   We should pay attention that the estimated A (Market value of total abetaets) 
      from Equation (5) is different from the summation of market value of abetaets 
      plus the book value of the debt. The usages of those two derived values 
      (A and sigmaA) will be used by Equations (6-8). 

   Here is a KMV example: E=110,688 (shares outstanding*price of stock), 
      D=64,062 (total debt), Rf=0.07 (risk-free rate), T=1 (1 year).  
      The result is A=170,558 sA=0.29.  Based on the following codes 
      we got A=170,393 and sigmaE=0.2615. The output is : A=170,393.78 
      and sigmaE is 0.2615. Please pay attention that the summation of 
      the book value of debt and the market value of equity is 174,750 (?170,558). 

  Distance to Default
     Distance to default (DD) is defined by the following formula, where A 
     is the market value of the total abetaets and sigmaA  is its risk. 
     The interpretation of this measure is clear, the higher DD, the safer is the firm. 

               A - Default Point 
       DD= -----------------------                      (6)
                  A *sigmaA                              

  In terms of Default Point, there is no theoretical fixed default point. 
     However, we could use all short-term debts plus the half of long-term 
     debts as our default point.  After we have the values of MV of abetaets 
     and its volatility, we could use the following equation to estimate the 
     Distance to Default. The A and s_A are from the output from Equation (5). 
     On the other hand, if the default point equals to E, we would have the following formula. 

                  ln(VA/D)+(r-0.5*sigmaA^2)T
          DD= -  -------------------------------        (7)
                    sigmaA*sqrt(T) 				

    Note that there is a negative sign in front of the ratio
    According to Black-Scholes model, the relationship between DD and Default Probability
           is given below. 
        DP(Default Probability) = N(-DD)                (8)

//////////////////////////////////////
"

.C30EXPLAIN18<-"Financial statement analysis
//////////////////////////////////////
Objective: 
   1) Understand the importance of financial statement analysis 
   2) understand the definitions of various ratios, such as
       Debt/equity ratio, ROE, ROA, DuPoint Identity
   3) Compare the performance of the firm with itself and with peers
   4) Given your recommendations 

   Note: If you could \"automate\" your procebeta, it will be more 
         meaningful. For example, you spend one day to finaish one company. 
         How long you would finish the next one or 10th one?

  Here are potential helps. 
        1) get financial statement easily, see type
           c28
        2) You can use some simple macro, such as record your operation
           c26
Procedure: 
   1) Download a compay's several years' financial statements 
   2) Conduct analysis such as ratio analysis
   3) Compare its performance with itself and with peers
   4) Write your comments and recommendation 

//////////////////////////////////////
"

.C30EXPLAIN6<-"Black and Litterman model (1992)
//////////////////////////////////////
Objective: 
----------
   1) Understand the shortcomings of our optimization model 
   2) understand the contributions of Black and Litterman (1992)
   3) using Excel to illustrate a few examples 
   4) Extension? 

Sources
-------
     blacklitterman.org   
         http://blacklitterman.org

     Black and Little example
         http://canisius.edu/~yany/excel/blacklitterman.xlsx

//////////////////////////////////////
"

.C30EXPLAIN7<-"Brandt, Santa-Clara and Valkanov model (2009)
//////////////////////////////////////
Objective: 
----------
   1) Understand the shortcomings and limitatons of the current optimization model 
   2) understand the contributions of Brandt et al. (2009)
   3) using Excel to illustrate a few examples 
   4) Extension? 

Sources
-------
  Michael W. Brandt, Pedro Santa-Clara, Robetaen Valkanov,2009,
    Parametric Portfolio Policies: Exploiting Characteristics in the Crobeta 
    Section of Equity Returns  

    Abstract
    We propose a novel approach to optimizing portfolios with large numbers
    of abetaets. We model directly the portfolio weight in each abetaet as a 
    function of the abetaet's characteristics. The coefficients of this 
    function are found by optimizing the investor's average utility of
    the portfolio's return over the sample period. Our approach is 
    computationally simple, easily modified and extended, produces sensible
    portfolio weights, and offers robust performance in and out of sample. 
    In contrast, the traditional approach of first modeling the joint distribution 
    of returns and then solving for the corresponding optimal portfolio weights 
    is not only difficult to implement for a large number of abetaets but also yields 
    notoriously noisy and unstable results. Our approach also provides a new test 
    of the portfolio choice implications of equilibrium abetaet pricing models. 
    We present an empirical implementation for the universe of all stocks in the CRSP-Compustat
    dataset, exploiting the size, value, and momentum anomalies.

    https://www.nber.org/papers/w10996
//////////////////////////////////////
"

.C30EXPLAIN31<-"SEC filings 
//////////////////////////////////////
Objectives: 
----------
   1) Understand what is the usages of SEC filings 
   2) understand how to search SEC EDGAR platform
   3) download one quarterly file  and using Excel to explore 
      a) How many company
      b) how many CIK
      c) how many forms
      e) frequency of those forms
      f) others
   4) potential applications 

Sources
-------
   https://www.sec.gov/edgar.shtml
   https://www.sec.gov/forms
   https://www.sec.gov/Archives/edgar/full-index/

The first several lines from Q3 2017
-------------------------------------------
Description:           Master Index of EDGAR Dibetaemination Feed by Company Name
Last Data Received:    September 30, 2017
Comments:              webmaster@sec.gov
Anonymous FTP:         ftp://ftp.sec.gov/edgar/
  
Company Name                                                  Form Type   CIK         Date Filed  File Name
---------------------------------------------------------------------------------------------------------------------------------------------
(OurCrowd Investment in MST) L.P.                             D           1599496     2017-08-24  edgar/data/1599496/0001465818-17-000048.txt         
1 800 FLOWERS COM INC                                         10-K        1084869     2017-09-15  edgar/data/1084869/0001437749-17-015969.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028807.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028809.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028810.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028811.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028812.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028813.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028814.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028815.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028816.txt

Note: combine a) and b) below 
    a) https://www.sec.gov/Archives/

    b) 2017-08-24  edgar/data/1599496/0001465818-17-000048.txt 

   we have 
      https://www.sec.gov/Archives/edgar/data/1599496/0001465818-17-000048.txt
    
//////////////////////////////////////
"

.C30EXPLAIN38<-"TORQ database 
//////////////////////////////////////
 The TORQ database contains transactions, quotes, order procebetaing data 
     and audit trail data for a sample of 144 NYSE stocks for the three
     months November, 1990 through January 1991. This document covers 
     installation,formatting and use of the data.

 Conceptual and institutional details concerning the data are given 
      in a companion publication Hasbrouck and Sosebee (1992).

 Manual, by Joe Hasbrouck
    http://people.stern.nyu.edu/jhasbrou/Research/Working%20Papers/TORQDOC3.PDF

//////////////////////////////////////
"

.C30EXPLAIN30<-"SEC 10-K: BS, IS or CF 
//////////////////////////////////////
 This is a very intereting projects. 
 If you could generate BS or IS, it will be more than enough. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 
 Step 2: unzip one and write a SAS program to retrive data 

 Step 3: work on one zip file 

 Step 4: write SAS programs to generate many 
         individual SAS data sets or generate 
         one big SAS data set, 

 Step 5: Generate your own BS
         Method I: download latest several years 
                   BS from Yahoo!Finance
                   replicate with your data 
              
         Method II: generate your own BS

  Advantage with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate industry means such as 
                           CA
            Quick Ratio ----------
                           CL 

              CA is the current abetaets
              CL is the current liability 
         d) you could generate some SAS, R or Python 
            data sets
//////////////////////////
"
.C30EXPLAIN29<-"SEC Forms 3, 4 and 5 
//////////////////////////////////////
What are Forms 3, 4, and 5?
.   Corporate insiders - meaning a company's officers and directors, and any beneficial owners 
   of more than ten percent of a clabeta of the company's equity securities registered under 
.   Section 12 of the Securities Exchange Act of 1934 - must file with the SEC a statement 
   of ownership regarding those securities. On August 27, 2002, the SEC adopted rules and 
   amendments to Section 16 of the Exchange Act, implementing the provisions of the 
   Sarbanes-Oxley Act of 2002 that accelerated the deadline for filing most insider 
   ownership reports.

   The initial filing is on Form 3. An insider of an ibetauer that is registering equity
   securities for the first time under Section 12 of the Exchange Act must file this 
   Form no later than the effective date of the registration statement. If the ibetauer 
   is already registered under Section 12, the insider must file a Form 3 within ten 
   days of becoming an officer, director, or beneficial owner.

  Changes in ownership are reported on Form 4 and must be reported to the SEC within 
  two businebeta days. You can find the limited categories of transactions not subject 
  to the two-day reporting requirement in the new rule.

  Insiders must file a Form 5 to report any transactions that should have been reported 
  earlier on a Form 4 or were eligible for deferred reporting. If a Form must be filed, 
  it is due 45 days after the end of the company's fiscal year.
 
  Today, the financial statement analysis has nothing to do with 
     insider trading. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 
 Step 2: unzip one and write a SAS program to retrive data 

 Step 3: work on one zip file 

 Step 4: write SAS programs to generate many 
         individual SAS data sets for Forms 3, 4 and 5 

 Step 5: Make your data sets quite user friendly 
              
  Advantages with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate all insiders trades  
        d) you could generate some SAS, R or Python data sets
  https://www.sec.gov/fast-answers/answersform345htm.html

//////////////////////////
"

.C30EXPLAIN28<-"SEC 10-K (13-f) 
//////////////////////////////////////
What is 13-f?
--------------
  Form 13F-?Reports Filed by Institutional Investment Managers
  An institutional investment manager that uses the U.S. mail (or other means
  or instrumentality of interstate commerce) in the course of its businebeta, 
  and exercises investment discretion over $100 million or more in Section 
  13(f) securities (explained below) must report its holdings on Form 13F 
  with the Securities and Exchange Commibetaion (SEC).

  In general, an institutional investment manager is: (1) an entity that 
  invests in, or buys and sells, securities for its own account; or (2) 
  a natural person or an entity that exercises investment discretion over
  the account of any other natural person or entity. Institutional 
  investment managers can include investment advisers, banks, insurance 
  companies, broker-dealers, pension funds, and corporations.

  Form 13F is required to be filed within 45 days of the end of a calendar 
  quarter. The Form 13F report requires disclosure of the name of the 
  institutional investment manager that files the report, and, with respect
  to each section 13(f) security over which it exercises investment discretion, 
  the name and clabeta, the CUSIP number, the number of shares as of the end of 
  the calendar quarter for which the report is filed, and the total market value.

  Today, the financial statement analysis does not consider the holdings
    of financial institutions. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 Step 2: unzip one and write a SAS program to retrive data 
 Step 3: work on one zip file 
 Step 4: write SAS programs to generate many 
         individual SAS data sets for Forms 3, 4 and 5 
 Step 5: Make your data sets quite user friendly 
              
  Advantages with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate all insiders trades  
        d) you could generate some SAS, R or Python data sets
  https://www.sec.gov/fast-answers/answers-form13fhtm.html

//////////////////////////
"
.C30EXPLAIN32<-"SEC Mutual Fund Prospectus Risk/Return Summary Data Sets	
//////////////////////////
The Mutual Fund Prospectus Risk/Return Summary Data Sets provides text and
  numeric information extracted from the risk/return summary section of 
  mutual fund prospectuses. The data is extracted from exhibits to mutual 
  fund prospectuses tagged in eXtensible Businebeta Reporting Language (XBRL).
  The information is presented without change from the \"as filed\" submibetaions
  by each registrant as of the date of the submibetaion. The data is presented 
  in a flattened format to help users analyze and compare corporate disclosure 
  information over time and acrobeta registrants.

  The data sets will be updated quarterly. Data contained in documents filed 
  after 5:30PM Eastern on the last businebeta day of a quarter will be included
  in the subsequent quarterly posting.

  https://www.sec.gov/dera/data/mutual-fund-prospectus-risk-return-summary-data-sets

  The Mutual Fund Prospectus Risk-Return Summary Data Sets (PDF, 207 kb) 
  https://www.sec.gov/dera/data/rr1.pdf 
  provides documentation of scope, organization, file formats and table definitions.

//////////////////////////
"

.C30EXPLAIN14<-"Census Summary Form 1 (SF1)
//////////////////////////
What is SF 1?
  Summary File 1 (SF 1) contains the data compiled from the questions asked of 
  all people and about every housing unit. Population items include sex, age, 
  race, Hispanic or Latino origin, household relationship, household type, 
  household size, family type, family size, and group quarters. 

  Housing items include occupancy status, vacancy status, and tenure (whether 
  a housing unit is owner-occupied or renter-occupied).

  There are 177 population tables (identified with a \"P\") and 58 housing tables
  (identified with an \"H\") shown down to the block level; 82 population tables 
  (identified with a \"PCT\") and 4 housing tables (identified with an \"HCT\") 
  shown down to the census tract level; and 10 population tables (identified with 
  a \"PCO\") shown down to the county level, for a total of 331 tables. The SF 1 
  Urban/Rural Update added 2 PCT tables,increasing the total number to 333 tables. 
  There are 14 population tables and 4 housing tables shown down to the block level 
  and 5 population tables shown down to the census tract level that are repeated by
  the major race and Hispanic or Latino groups.
  
  SF 1 includes population and housing characteristics for the total population,
  population totals for an extensive list of race (American Indian and Alaska 
  Native tribes, Asian, and Native Hawaiian and Other Pacific Islander) and 
  Hispanic or Latino groups, and population and housing characteristics for 
  a limited list of race and Hispanic or Latino groups. Population and housing 
  items may be crobeta-tabulated. Selected aggregates and medians also are provided.

  A complete listing of subjects in this file is found in the \"Subject Locator\"  chapter.

  To download all data, type
     .dumpCensubetaF1   

  source of data: https://www2.census.gov/census_2010/04-Summary_File_1/
  Manual: https://www.census.gov/prod/cen2010/doc/sf1.pdf   

//////////////////////////
"
.C30EXPLAIN15<-"Census Summary Form 2 (SF2)
//////////////////////////
What is SF2?
   Summary File 2 (SF 2) contains the data compiled from the questions asked of 
   all people and about every housing unit. SF 2 includes population characteristics,
   such as sex, age, average household size, household type, and relationship to 
   householder such as nonrelative or child. The file includes housing characteristics,
   such as tenure (whether a housing unit is owner-occupied or renter-occupied), 
   age of householder, and household size for occupied housing units. 

  Selected aggregates and medians also are provided. A complete listing of 
  subjects in SF 2 is found in Chapter 3, Subject Locator. The layout of the 
  tables in SF 2 is similar to those in SF 1. 

  These data are presented in 47 population tables (identified with a \"PCT\") 
  and 14 housing tables (identified with an \"HCT\") shown down to the census 
  tract level; and 10 population tables (identified with a \"PCO\") shown 
  down to the county level, for a total of 71 tables. Each table is iterated 
  for 331 population groups: the total population, 75 race categories, 114 
  American Indian and Alaska Native categories (reflecting 60 tribal groupings), 
  47 Asian categories (reflecting 24 Asian groups), 43 Native Hawaiian and Other 
  Pacific Islander categories (reflecting 22 Native Hawaiian and Other Pacific
  Islander groups) and 51 Hispanic/not Hispanic groups. The presentation of SF 2 
  tables for any of the 331 population groups is subject to a population threshold 
  of 100 or more people. That is, if there are fewer than 100 people in a specific
  population group in a specific geographic area, their population and housing 
  characteristics data are not available for that geographic area in SF 2. 

  To download all data, type
     .dumpCensubetaF2   

  Source of data 
     https://www2.census.gov/census_2010/05-Summary_File_2/

  Manual 
     https://www.census.gov/prod/cen2010/doc/sf2.pdf

//////////////////////////
"

.C30EXPLAIN12<-"Census Demographic profile
//////////////////////////
A short intro 
-------------
   The Demographic Profile Summary File contains 100 percent data asked of 
   all people and about every housing unit on topics such as sex, age, race, 
   Hispanic or Latino origin, household relationship, household type, group 
   quarters population, housing occupancy, and housing tenure. 

   GEOGRAPHIC CONTENT
     The Demographic Profile Summary File is released as individual files for 
     the United States, each of the 50 states, the District of Columbia, and 
     Puerto Rico. The data items are identical for all files, but the geographic
    coverage differs.

    The summary level sequence chart outlines the hierarchical and geographic 
    summaries in their entirety. 
 
  To download all data, type
  ---------------------------
    .dumpCensusDemographicProfile

  Source of the data 
      https://www2.census.gov/census_2010/03-Demographic_Profile/
  Manual 
     https://www.census.gov/prod/cen2010/doc/dpsf.pdf
  Manual about the data structure 
     https://www2.census.gov/census_2010/03-Demographic_Profile/0README_DPSF.pdf

//////////////////////////
"
.C30EXPLAIN13<-"Census Redistribution
//////////////////////////
  To download all data, type
    .dumpCensusRedistribution

  source of data 
     https://www2.census.gov/census_2010/redistricting_file--pl_94-171/

//////////////////////////
"

.C30EXPLAIN10<-"Census Congrebetaional Districts113
//////////////////////////
 To download all data, type
    .dumpCensusCongrebetaionalDistricts113 

 Source of data 
     https://www2.census.gov/census_2010/08-SF1_Congrebetaional_Districts_113/

//////////////////////////
"

.C30EXPLAIN11<-"Census Congrebetaional Districts115
//////////////////////////
 To download all data, type
    .dumpCensusCongrebetaionalDistricts115 

 Source of data 
    https://www2.census.gov/census_2010/08-SF1_Congrebetaional_Districts_115/

//////////////////////////
"
.C30EXPLAIN27<-"SCF (Survey of Consumer Finances)
//////////////////////////
 To download all data, type
  .dumpSCF 

 Source of data 
    https://www.federalreserve.gov/econres/scfindex.htm

//////////////////////////
"

.C30EXPLAIN17<-"Extra high-frequency data 
//////////////////////////
  Extra high-frequency data 
    ftp://ftp.nyxdata.com/Historical%20Data%20Samples/

//////////////////////////
"
.C30EXPLAIN8<-"Building a slot machine
/////////////////////////
The logic of the game 
---------------------

    Our bet is $1. We randomly choose 3 numbers from 1 to 10. 
    if they are equal, we win $90. Otherwise, we loose our bet. 

  Step 1: choose a cell to enter =randbetween(1,10)
  Step 2: format it nicely 
          a) choose several cells around it, 
             click \"merge & Center \" on the menu bar
          b) Highlight those cells -> Click \"Conditional Formatting\"
             choose \"Color Scales\" -> choose 

  Step 3: Copy the cells to another two places 
  Step 4: choose a cell to calculate win or lobeta
          if three of them are equal, win 90, otherwise -1
  Step 5: find a cell we could enter our initial cash 
  Step 6: choose a cell to calculate the cumulative lobeta
          Abetaume that our cumulative lobeta cell is I3
          our win or lobeta is in cell  F3, see step 4

  Step 7: Click \"Developer\" -> View Code -> Copy that paste the following macro 

Sub games()
Range(\"I3\").Value = Range(\"I3\").Value + Range(\"F3\").Value
End Sub
  [Note: we need some value is I3 to make it work]
/////////////////////////
"
.C30EXPLAIN40<-"Projects taken already 
/////////////////////////////////////////////////////////////
  Name of topic                     Group                            Presentation 
 ------------------------          ------------------               ------------
 Testing the January-Effect         Matt,Elena,Muhammad              11/21
 Financial Statement Analysis       Claire,Paige,Julia,Monica
 Retirement calculator              Chris, Zach, Paul                12/5
 Bankruptcy prediction/Z-score      Msaada, Brannon, Mark
 Benford Law & Accounting Fraud     Mason, Patrick 
 Simulation to mimic a slot machine Lauren, Julie, Jebeta, and Jill    11/21
 SEC 10-K: BS, IS or CF topic.      Patrick, Ben,Ben,Mellibetaa        12/5
 SEC Filing                         Gabriella, Caitlin, Maria        12/5
 Black Jack Machine                 Joseph
 Updating a monthly Excel data set  Brian                         

/////////////////////////////////////////////////////////////
"


.C31EXPLAIN40<-.C30EXPLAIN40

.tp<-.chapter30
.termProjects<-.chapter30


.termProjects<-function(i){
" i              Term projects              i   Description 
  -  -------------------------------------  --  ----------------------
  1  Requirements for a term project        26  TORQ database 
  2  Retirement calculator                  27  SEC 10-K: BS, IS or CF
  3  Best model(CAPM,FF3,FFC4,FF5)?         28  SEC 10-K (Forms 3, 4 and 5)    
  4  Test of the January Effect using Excel 29  SEC 10-K (13-f) 
  5  Bankruptcy prediction by using Z-score 30  SEC Mutual Fund Prospectus 
  6  Updating a monthly Excel data set      31  Census Summary Form 1 (SF1)	
  7  Momentum trading strategy              32  Census Summary Form 2 (SF2)
  8  52-week high trading strategy          33  Census Demographic profile
  9  Max trading strategy replication       34  Census Redistribution
 10  Spread estimation from daily price     35  Census Congrebetaional Districts 113 
 11  Event Study using Excel                36  Census Congrebetaional Districts 115
 12  Simulation to mimic a slot machine     37  SCF (Survey of Consumer Finance) 
 13  Simulation to mimic Black Jack         38  Extra high-frequency data 
 14  Benford Law & accounting fraud         39  Build a slot machine 
 15  Readability 10-K/firms' performance    40  Projects taken 
`16  Businebeta cycle indicator
 17  illiquidity measure,Amihud(2002)
 18  Liquidity, Pastor/Stambough(2003)
 19  Spread estimation from TAQ 
 20  A reverse mortgage calculator
 21  KMV model & default probability
 22  Financial statement analysis
 23  Black-Litterman model 
 24  Brandt et al. model (2009) for portfolio 
 25  SEC filings
 
 Example #1:>.tp     # see the above list
 Example #2:>.tp(1)  # see the first explanation

";.termProjects_(i)}

.n31chapter<-40
.termProjects_<-function(i){
     .printEachQ(31,i,.n31chapter)
}
.c31<-.termProjects

.C31EXPLAIN1<-"Requrement of a term project 
//////////////////////////////////////
Objective: This is an integral part of this course. It could be viewed 
           as the application of  what you have learnt from this course 
           to a real-world situation. 

Format: Group project (each group could have up to three members) 
       
Topic:  Each group chooses one topic from a list of potential term 
        projects (first come and first served since each topic should 
        be chosed by just one group). 
        To find a list of potential projects, just type 
        .c31 

Three files: Each group should submit three files 
         a) An Excel file containts your final result and final data set
         b) a short report (maximum page limit: 15, double space, font of 11)
         c) A powerPoint file  

Dropbox : submit your files to the dropbox on D2L

Presentation:
         Each group would present their term project in front of the whole clabeta 

Due date:if you want my comments, you should submit your files 
         before your presenttaion. If not, you could submit your files after 
         your presentation. 

//////////////////////////
"

.C31EXPLAIN2<-"Retirement calculator 
//////////////////////////////////////
Source: http://money.cnn.com/calculator/retirement/retirement-need/

Step 1: estimate John Doe's final annual salary when he retires
	Input variables: 
         a) current salary
         b) salary growth rate (factor in the inflation rate)
         c) number of years before his retirement 

        For example, if John is 35 year-old and earning $50,000 now. If he plans 
            to retire at 67, his final annual salary will be 50000*(1+g)(67-35), 
            where g is the annual salary growth rate. 

Step 2: Estimate the required annual cash inflow for the first retirement year.
        For example, we could abetaume that the expected cash inflow for the 
        first year after retirement is 80% or 85% of his/her last annual salary. 

Step 3: estimate how many years after a person's retirement.  
        For instance, this value is 25 if John's life expectancy is 92 and retries at 67 (92-67). 

Step 4: estimate the present value, at the time he retires, of a growing annuity
	Input values: the 1st cash flow, a growth rate and an appropriate discount rate

Step 5: Factor in the social security benefit (this could be another data case)
	Estimate the present value, at time of your retirement, of your Social Security benefit
	Input values:
	Monthly benefit
	Discount rate

Step 6: John's net required cumulative wealth when he retires 
        (the result of Step 4 minus the result of Step 5)

Step 7: estimate John's required saving from now to that year. 
	Such as the annual saving or percentage saving

Note: for Social benefits

PIA (Primary Insurance Amount) 
   (a) 90% of the first $896 of his/her average in dexed monthly earnings, plus
   (b) 32% of his/her average indexed monthly earnings over $896 and through $5,399, plus
   (c) 15% of his/her average indexed monthly earnings over $5,399.
        https://www.betaa.gov/oact/COLA/piaformula.html


//////////////////////////
"

.C31EXPLAIN3<-"Which one is the best? CAPM, FF3, FFC4, or FF5
//////////////////////////
Objectives of this term project
    1) understand different models: CAPM, FF3, FF4 and FF5
    2) Understand how download and procebeta data 
    3) Understand the T-value F-values and adjusted R2

a) CAPM: R(IBM) = Rf + beta*(Rm - Rf)                         (1)
            where R(IBM) is the IBM's mean return or expected return 
            Rf is the risk-free rate
            Rm is the market mean return or expected return 

b) FF3 Fama-French 3-factor model:
         R(IBM) = Rf + beta1*(Rm - Rf)+beta2*SMB + beta3*HML  (2)
            where SMB is small minus big, HML is high book-to-market 
            ratio portfolio minus low ratio portfolio 

c) FF4 is the Fama-French-Carhart 4 factor model 
         R(IBM) = ff3 + beta4*MOM                             (3)
            Where MOM is momentum factor
                      
d) FF5 is the Fama-French 5-factor model:
         R(IBM) = ff3  + beta4**RMW + beta5*CMA               (4)
            where RMW is Robust minus weak, CAM is 
               conservative minus Aggrebetaive
  Three questions:
      1)   Which criterion?
      2)   The performance is time-period independent?
      3)   In-sample estimation vs. out sample prediction

   We use the adjusted R2 as our criterion to measure the performance of each model. 
      Step 1: download monthly price data from Yahoo!Finance
      Step 2: choose a period to run various models  
      Step 3: summarize your testing results  (sample statistics)
      Step 4: (Optional: out-of-sample prediction)

source of data: 
       1) http://finance.yahoo.com
       2) http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html

//////////////////////////
"

.C31EXPLAIN4<-"Test of the January Effect using Excel 
//////////////////////////
If the Efficient Market Hypothesis (EMH) holds, we should not expect many market 
anomalies such as January Effect, Weekday Effect, momentum strategy (buy winners 
and sell losers). However, many researchers and profebetaionals have found that 
returns in January are quite different from other months. 

Question:  Are January returns statistically different from other months?
            
          mean return for January = mean return of none-January  (1)

   Choose about a dozen stocks to test the existence of so-called 
   January effect. A few companies are listed below. Note that S&P500 
    is listed as well. 

    I   Company name      Ticker   Industry
    --  -------------     -----   -------
    1	Wal-Mart          WMT     Superstore
    2	Apple Inc.        AAPL    Computer 
    3	Citi Group        C       Financial Company
    4	International
        Businebeta Machine IBM      Computer 
    5	Microsoft        MSFT     Computer 
    6	...              ...      ...		
    13  S&P500           ^GSPC    Market index

 Step 1: Download monthly price data from Yahoo 
             finance (http://finance.yahoo.com)
 Step 2: Estimate monthly returns

 Step 3:  Sort those monthly returns into two groups: returns 
             in January and returns in other months. 

 Step 4: For each stock/index, test whether its two means 
         are equal, see the above equation. 

 Comments on your results. 

//////////////////////////
"

.C31EXPLAIN5<-"Bankruptcy prediction by using Z-score
//////////////////////////
The Altman's Z score is used to predict the pobetaibility of a firm goes 
    to bankruptcy. This score is a weighted average of 5 ratios based 
    on a firm's balance sheet and income statement. For public firms, 
    Altman (1968) offers the following formula. 

     Z=3.3*X1+0.99*X2+0.6*X3+1.2*X4+1.4*X5, 			(1)

    where the definitions of X1,X2,X3,X4 and X5 are given in the following table. 
      Variable	Definition 
      --        -------------
      X1        EBIT/Total Abetaets
      X2        Net Sales/Total Abetaets
      X3        Market Value of Equity/Total Liabilities
      X4        Working Capital/Total Abetaets
      X5        Retained Earnings/Total Abetaets

    Based on the ranges of z-scores, we could clabetaify public firms 
         into following 4 categories. Eidlenan (1995) finds that the 
         Z score correctly predicted 72% of bankruptcies two years 
         prior to the event.

        Z-score range	Description
        -------------   --------------
          > 3.0          Safe
          2.7 to 2.99    On Alert. 
          1.8 to 2.7     Good chances of going bankrupt within 2 years. 
          < 1.80         Probability of Financial distrebeta is very high 

    References
       Altman, Edward I.,2000,Predicting Financial Distrebeta of Companies, 
           Retrieved on September 4th, 2009 from http://pages.stern.nyu.edu/~ealtman/Zscores.pdf

       Altman, Edward I,1968,Financial Ratios, Discriminant Analysis and the 
           Prediction of Corporate Bankruptcy, Journal of Finance,189 - 209.
       
.       Eidleman, Gregory J.,1995,Z-Scores - A Guide to Failure Prediction, 
           The CPA Journal Online, https://www.easycalculation.com/statistics/altman-z-score.php

//////////////////////////
"

.C31EXPLAIN6<-"Updating a monthly Excel data set and write an instruction 
//////////////////////////
First, let's download the Excel data set
     http://canisius.edu/~yany/data/monthlyYan.xlsx

The structure of this date set is very simple:
      Three columns: ID, Date and Value, see the first selvera lines below. 

    ID    date         value
    --    ---------    ------
    A     11/30/1999   38.96
    A     12/31/1999   71.39
    A     1/31/2000    61.12
    A     2/29/2000    95.91
    A     3/31/2000    96.03
    A     4/28/2000    81.83
    A     5/31/2000    67.98
    A     6/30/2000    68.1
    A     7/31/2000    37.63
    A     8/31/2000    56.33

  Note 
  (1) The frequency of the data set is monthly. 
  (2) \"A\" is the stock ticker 
  (3) For stocks, the last column called value 
      is the monthly adjusted price. 
  (3) for SMB (Fama-French factor), value is for factor, 
         i.e., return

  Do the following things:
     (a) find out all unique ID's
     (b) update the data set
     (c) write a 2-page manual on how to use this data set
         i) how to estimate monthly returns
         ii) how to estimate annual returns
         iii) how to generate a n-stock matrix, such as 5-stocks matrix

//////////////////////////
"

.C31EXPLAIN7<-"Momentum trading strategy 
//////////////////////////
We could use a simple phrase to summarize the so-called momentum trading strategy: 
      buy winners and sell losers. 

Here, we have an implied abetaumption: within a short-term (between 3 months 
     and 12 months), the winner will remain a winner while a loser would 
     continue to be a loser. Two related questions: 1) how to define a winner 
     from a loser? 2) how to conduct a test?

Objectives of this term project:
     1) learn how to download a few hundred stock data 
     2) Understand how to use Excel to retrieve and procebeta data 
     3) Prove or disapprove so-called momentum strategy 
        by replicating Table 1 of Jegadeesh and Titman (1993) 
        [They use all stocks, while you would use just a few hundred stocks]

  Prerequisites:  accebeta to an Excel ata set called monthlyYan.xlsx (I will supply this data set)
  Ba sic logic:   According to Jegadeesh and Titman (1993) it is a profitable trading 
                  strategy if we buy the past winners and sell the past losers.  

   Notations: 	Check the past K-month returns, and then form a portfolio for L months, 
     Where K=3,6,9 and 12 and L=3, 6, 9 and 12. Below we use K=L=6 as an example. 
     Trading strategy: Estimate all stocks' past 6- month returns and sort stocks 
      into 10 groups (deciles) according to their 6-month total returns. Long 
       the top decile (winners) and short the bottom decile (losers) for the next 6 months. 
   
   Procedure:
       Step 0: Starting month: January 1927
       Step 1: Retrieve CRSP data (PERMNO, DATE and RET)
       Step 2: Estimate past 6-month cumulative returns R_t^6month
       Step 3: Sort all stocks into deciles according to their cumulative 6-month returns
       Step 4: Long winners (best return group) and short losers for the next 6-month
       Step 5: Estimate portfolio returns
       Step 6: Move to the next month and repeat the above steps until the 
               last month 
 References
      Jegadeesh Narasimhan and Sheridan Titman, 1993, Returns to Buying Winners and 
           Selling Losers: Implications for Stock Market Efficiency, Journal of Finance 
           48 (1), 65-91.
 
     Appendix A: Table 1 from Jegadeesh and Titman (1993).

//////////////////////////
"

.C31EXPLAIN8<-"Replicate 52-week high trading strategy 
//////////////////////////////////////
George and Huang (2004) show that we could design a profitable trading 
   strategy based on the 52-Week High. First, they estimate a ratio by 
   dividing today's price by its 52-week high. Based on such a ratio, 
   all stocks are sorted from the highest to the lowest. The stocks 
   belong to the top (bottom) 30% are labeled as winners (losers). Again, 
   the trading strategy is to buy winners and sell losers. They demonstrate 
   that such a trading strategy is quite profitable with an average return 
   difference of 0.45% per month between the winner and loser portfolios. 

Several versions of this project:
   version #1: just test one or two stocks
   Version #2: test a few hundred
   Version #3: test all stocks  [you need a financial database called CRSP]

Objectives of this term project:
   1) Understand how to download daily data from Yahoo!Finance [see above versions #1 or #2]
   2) Understand how to use Excel to procebeta data 
   3) Prove or disapprove so-called 52-week High trading strategy 

 Time period: as long as pobetaible        [versions #1 or #2] 
              July 1963 to December 2001 [Version #3] 

 Basic logic: According to George and Huang (2004) it is a profitable 
              trading strategy if we based on the ratio of the current 
              stock price divided by its 52-week High

 Trading strategy: Estimate all stocks' 52-week high, estimate the ratio 
     of today's price over its 52-week High, sort them from the highest 
     to the lowest. Treat the top 30% as winners and bottom 30% as losers. 
     Buy winner and sell losers. 

Procedure for version #1:
  Step 0: formulate your trading strategy: 
             ratio > 0.8 you buy
             ratio < 0.3 you sell

                                     price - 52wLow
      Definition #1:  ratio  = ---------------
                                   (52wHigh - 52wlow)

                                  price
      Definition #2   ratio =   -----------
                                  52wHigh

Procedure for Version #1:
  Step 1: download one stock from Yahoo!finance as early as pobetaible 
  Step 2: estimate returns
  Step 3: sort data from the earlest to the latest
  Step 4: starting from 253 observation, estimate 52wHigh and 52wLow
  Step 5: calculate the ratio 
  Step 6: based on your trading strategy, you long or short for the next period
  Step 7: Generate a column for return for this trating strategy
  Step 8: test whether this is a profitable trading strategy 
          compared with the long-only strading strategy

Procedure for versions #2 and #3:
  Step 1: load data sets stockDaily and stockMonthly
  Step 2: Starting month: July 1963
  Step 3: Estimate  all stocks' 52-week High and estimate the ratio Price/52-week high  
  Step 4: Sort all stocks from highest to lowest 
  Step 5: choose top 30% as winners and bottom 30% as losers
  Step 6: estimate equal-weighted portfolios return for both winner and looser portfolios
  Step 7: Move to the next month and repeat the above steps until the last month (December 2001)
  Step 8: test 
  
 References
     George, Thomas J, and Chuan-Yang Huang, 2004, The 52-week High and Momentum 
           Investing, Journal of Finance 54, 5, 2145-2176.

//////////////////////////////////////
"

.C31EXPLAIN9<-"Replicate a so-called Max trading strategy 
//////////////////////////////////////
 Bali, Cakici and Whitelaw (2011) find that sorting stocks by their 
    maximum daily returns (MAX) in the previous month could produce a 
    monthly return difference of more than 1% between the lowest and 
    highest MAX deciles.  

    In addition, the alphas from running Fama-French-Carhart 4-factor
    model for those two extreme portfolios are significantly different. 
    Thus, we could design a profitable trading strategies based on stocks'
    last month extreme daily returns. 

There are several versions of this term project:
   version #1: just test 20 to 40 stocks
   Version #2: test a few hundred
   Version #3: test all stocks   [you need a financial database called CRSP]

Objectives of this term project (version #1):
   1) Understand how to download data from Yahoo!Finance
   2) Prove or disapprove so-called the max-trading strategy

Objectives of this term project (version s #2 and #3):
   1) Understand the CRSP database
   2) Understand how to use Excel or R to retrieve and procebeta data 
   3) Prove or disapprove so-called the max-trading strategy by 
        replicating Table 1 of Bali et al. (2011).

 Prerequisites (version #3):  stockDaily and stockMonthly.RData 
    Basic logic: According to Bali et al. (2011) some investors like stocks with 
              lottery-type payoffs which have big past returns with a small probability. 
    Period:	July 1962 to December 2005

 Trading strategy: Estimate all stocks' maximum returns in the last month, 
    sort stocks into 10 groups (deciles) according to their last month's 
    maximum daily returns. Long the top decile (winners) and short the 
    bottom decile (losers) for one month. 

Procedure (for versions #1): Abetaume that you have 40 stocks 
     Step 0: donwload daily/monthly price data for those stocks
     Step 1: estimate daily returns 
     Step 2: Using pivoTable to generte some thing below 
                           stock1   stock2  stock3 ..    stock40
                YYYYMM1    maxValue   x       x            x
                YYYYMM2     x         x       x            x 

             Note: maxValue is the maxium value for stock1 in the previous month. 

    Step 3: choose your portfolio: long 10% and short bottom 10%. 
            In other words, long 4 stocks with highest max returns in the previous month. 
            short 4 stocks with the lowest max returns in the previous
    Step 4: Eestimate portfolio returns of your long short portfolio 
    Step 6: move to the next month and repeat 
    Step 7: test your result. 

Procedure (for versions #3):
	Step 0: Starting month: July 1962
	Step 1: load stockDaily 
	Step 2: Estimate the maximum daily returns of the previous month, i.e., May 1962
	Step 3: Sort all stocks into deciles according to their maximum last month daily returns 
	Step 4: Long the top 10% and short the bottom 10%
	Step 5: load stockMonthly and estimate portfolio returns and their difference
      Step 6: Move to the next month and repeat the above steps until the last month (December, 2005)

  References
     Bali, Turan G., Nusret Cakici, and Robert F. Whitelaw, 2011, Maxing Out: 
        Stocks as Lotteries and the Crobeta-Section of Expected Returns, Journal 
        of Financial Economics 99 427-446.

//////////////////////////////////////
"

.C31EXPLAIN10<-"Spread estimation from daily price 
//////////////////////////////////////
  Spread is defined as the difference between ask and bid

  Generally, the difference between two prices or interest rates. In stock trading, 
    the difference between the current bid and ask prices for a stock (the bid/ask or 
    bid/offer spread). In futures trading, the price difference between delivery 
    months for the same commodity or abetaet. In bond trading, the difference between 
    yields of bonds with similar quality and different maturities, or of different 
    quality and the same maturity. In underwriting, the difference between what the 
    ibetauer receives from the underwriter and what the underwriter receives from the 
    public (underwriting spread).

         http://lexicon.ft.com/Term?term=spread

Roll (1984) designs a method to estimate the spreads by using the 
    first order covariance of price changes. 

       S=2 *sqrt(-cov(A, B) )                         (1)

          where A= deltaP(t-1)
                B= deltaPP(t)	

 Objectives for this term-project
      1) understad how to download and procebeta daily data from Yahoo!finance
      2) understand the logic behind the above forumla
      3) estimate Roll's spread for a dozen stocks 	
      4) comment on your results

   The first 6 stock symbols are given below. 
        Company name               Ticker Industry
        --------------             ----   ------
   1 Microsoft Corporation	   MSFT   Application software
   2 Apple Inc.                    AAPL   Personal Computer
   3 Citigroup Inc.                C      Money Center Banks
   4 Wal-Mart Stores, Inc.         WMT    Discount, Variety Stores
   5 Home Depot, Inc.              HD     Home improvement services
   6 ...                           ...    ...
   12 General Electric Corporation GE     Technology

//////////////////////////////////////
"

.C31EXPLAIN11<-"Event Study using Excel 
//////////////////////////////////////
 Based on Event Study, we test the impact of HSIC added to the S&P500 on March 18, 2015. 
 Source of data: http://canisius.edu/~yany/excel/eventStudy.xlsx
  
 The basic idea for Event Study is to test whether our AR (Abnormal Return) is 
     statistically significant. The definition of abnormal return is given below. 

           AP=realized return - expected return        (1)

  To estimate our expected return, we apply the following linear regrebetaion. 

	y = alpha + beta* x                           (2)

   where, y is the expected return and x is the market return on that day. 
      To estimate two parameters, a and beta, we run a linear regrebetaion or apply 
      related formulae by choosing an evaluation period of 252-day long, 
      starting the day before our event window counting backward, see below. 
             
             Estimation period                          Event-window
    |-------------------------------|-------------|----------|
	                   n days before      event-day   m-day after
 Here is the design. 
     i) The event day is 3/18/2015			
    ii) Our event window: 10 days before and 10 days after			
   iii) The estimation period: from 253 days before to one-day before our event window

 Thus, roughly we could download daily data from 2/1/2014 to 4/22/2015.
   Step 1: download daily price data from HSIC and S&P500 (^GSPC). 
   Step 2: Choose only adjusted price, see the left panel below.
             Then sort data from oldest to the latest, see the right panel below. 			
   Step 3: estimate daily returns, see the formula in D3.  				
   Step 4: Highlight our event day, a window around the event and the estimation period 
             For example, we could use red color for event day, 10-day before and 
             10-day after our event day. In addition, we could highlight our 
             estimation period green. 
   Step 5: Based on the estimation period, apply following formulae to estimate 
             intercept, slope, R2 and standard error				
             abetaume B column is for stock returns, C column is S&P500 returns
	    i) intercept      =intercept(B,C)
           ii) slope          =slope    (B,C)
          iii) R2             =rsq      (B,C)
           iv) standard error =steyx    (B,C)

    Step 6: Estimate, expected return, AR (abnormal return), 
            CAP (cumulative abnormal return) and T-AP (T-value for abnormal return)				

         Expected return            AP      CAR     T-value for AR
	  --------------            --      ---     --------------
			
	Expected return                        = intercept + slope * market			
	AR (abnormal return)                   = realized return - expected return			
	CAR (cumulative abnormal return)       = sum of all ARs up to today			
	T-value for AR                         = AR/standard error			

   Note: to make our spread sheet clean, we have two choices:
 	i) Hide many rows			
	ii) Copy above four output values to a place near our event window			

   Comment on your results. 			


 Source of S&P500 added and deleted
     https://en.wikipedia.org/wiki/List_of_S%26P_500_companies#Recent_changes_to_the_list_of_S&P_500_Components
     http://canisius.edu/~yan/excel/sp500added_deleted.xlsx

//////////////////////////////////////
"

.C31EXPLAIN12<-"Monte Carlo Simulation to mimic a slot machine
//////////////////////////////////////
Objectives:
     1) understand related statistics
     2) apply the Excel randbetween() function 
     3) learn to link picture to a cell and 
     4) using the vlookup() function to search a table of pictures 

Task #1: A simple case with just three numbers
     Abetaume that we have three objects: apple, banana and eggplant, see below. 
 
    We enter three numbers and try to output three corresponding fruits by using the Excel vlookup() function. 
 
   Q1: What is the probability of winning, defined as matching three?
   Q2: Abetaume the cost of one play is $1, what is the winning price if this is a fair game ?
   Q3: What is the expected value, if the cost of one play is $1 and our winning price is $7?


Task #2: Design a slot machine with 3 objects with pictures. 
   Step 1: generate the following entries. 
           Below, we use C16 for apple as an example. Searching online 
           to find a apple image. Right click the picture of apple, then choose \"format picture\". 
 	 
   Step 2: we manually enter three numbers in cells B3, C3 and D3, 
           Our objective is to search our picture table (fruit pictures) 
           to output corresponding three fruits. In this case, we expect 
           to see apple, apple and banana.
 
   Step 3: Click cell C16 (not apple but the cell), copy, then select 
           our destination cell, i.e., F3, then from Paste link to choose 
           \"Lined Picture (I)\", see the right image below. 
 	 
    Step 4: Click \"Formula\", \"Define Name\", see below, where X will 
            be our image column, i.e., C16:C18, Y is our indicator, B3, 
            Z is our number columns, i.e., B16:B18. Below, we define a 
            name called firstNumber.  
 	 
    Step 5: Click picture in F3 and we replace =$C$16 with =firstNumber 
           (or other name you defined), see the right image above. Repeat 
           the same procedure for other two cells. 

 Task 3: Build a slot machine with 10 different fruits and abetaume that 
         the machine would have a slight advantage to the owner of the 
         machine, such as for 1 million plays, the casino would have a profit of $100. 

  Q4: What is the winning price if we have three same pictures?
  Q5:  What is your result after playing 100 times? 

  References 
      http://en.wikipedia.org/wiki/Slot_machine

//////////////////////////////////////
"

.C31EXPLAIN13<-"Monte Carlo Simulation to mimic Black Jack 
//////////////////////////////////////
This is a 2-player game: a dealer and a player. Below, we abetaume 
     that you are the player. 

  Rule #1: cards 2 to 10 have their face value, while J, Q, and K 
            are worth 10 points and Ace is worth either 1 or 11 
            points (player's choice).
  Terminology:
    Blackjack          : one A plus any card worth 10 points. 
    Lose               : the player's bet is taken by the dealer.
    Win                : the player wins as much as he bet.
    Blackjack (natural): the player wins 1.5 times the bet.
    Push               : the player keeps his bet, neither winning nor losing money.

 Step 1: the dealer draw two cards, one face up, while the player draw two cards (face up) 

  Step 2: the player could draw the third card 

   Win or lose: if the sum of your cards is lebeta than 21 and 
         is bigger than dealer's, you win. 

    http://www.pagat.com/banking/blackjack.html

//////////////////////////////////////
"
.C31EXPLAIN14<-"Benford Law and accounting fraud detection
//////////////////////////////////////
 Benford Law is also called the First-Digit Law which gives different frequencies 
    for 9 first digits from 1 to 9.  Convention wisdom would conclude that each 
    (first) digit would have roughly the same frequency, i.e., 1/9=0.1111=11%.  
    
 However, according to the Benford Law, the lower is the value of a digit, 
    the higher is its probability. In other words, we will see more values 
    with leading digit of 1 than with the leading digit of 2. The probability 
    of each digit is given by the following formula. 

    Prob(d)=log10((d+1)/d)                          (1)

   where Prob() is the probability (frequency), d is the digit, and log10() 
      is the log function with a base of 10. For Excel, log10() is the same as log(). 

    Digit   Formula    probability
    ----    ----        ----
    1     =log10(2/1)   0.301
    2     =log(3/2)     0.176
    3     =log(4/3)     0.125
    4     =log(5/4)     0.097
    5     =log(6/5)     0.079
    6     =log(7/6)     0.067
    7     =log(8/7)     0.058
    8     =log(9/8)     0.051
    9     =log(10/9)    0.046
          ------------  -----
           Total        100%

 Objectives:
     1) understand Benford Law
     2) download about a dozen companies' annual reports
     3) estimate the distributions of the 1st digits
     4) report your results and discubeta

 Procedure:
    To download annual financial statements.
       Step 1: go to Yahoo!Finance  http://finance.yahoo.com/  
       Step 2: enter a ticker, such as IBM
       Step 3: find three types of financial statements. 
       Step 4: download those financial statements

   Note 1: the function to get the first digit is =left(cell, 1)
   Note 2: you could use the Excel countif() function. 

 References
    Accounting Web, 20 Ways You Can Detect Fraud, 2014, 
        http://www.accountingweb.com/aa/law-and-enforcement/20-ways-you-can-detect-fraud

    Sharma, Anuj, Prabin Kumar Panigrahi, 2012, A Review of Financial Accounting Fraud 
        Detection based on Data Mining Techniques, INternationla Journal of Computer 
        Aplication 39, 1, https://arxiv.org/ftp/arxiv/papers/1309/1309.3944.pdf

    MCGINTY, JO CRAVEN, 2014, Accountants Increasingly Use Data Analysis to Catch 
        Fraud, Auditors Wield Mathematical  Weapons to Detect Cheating,                 http://www.wsj.com/articles/accountants-increasingly-use-data-analysis-to-catch-fraud-1417804886

    Testing Benford Law, http://testingbenfordslaw.com/

    What is Benford Law,  https://en.wikipedia.org/wiki/Benford%27s_law#cite_note-Nigrini-19

//////////////////////////////////////
"

.C31EXPLAIN15<-"Readability of 10-K filings and firm's performance
//////////////////////////////////////
Objectives:
      1) Understand the usage of 10-K
      2) learn how to parse 10-K
      3) understand the Fog-index and learn how to calculate it for each 10-K filing
      4) Comments on your result

Source of data
      a) SEC EDGAR (Electronic Data Gathering , Analysis and Retrieval)
      b) I have all 10-K filings from Q1 1993 to Q2 2016 (the number of filings is 
           210,842 and the size is 440G)

Structure vs. unstructured data
    The unstructured information has a lion share of all information, 
    70% to 80% and it is reported that 80% of structured information 
    came from unstructured one. On the other-hand, SEC filings is an 
    important source of information (gold mine) since public companies, 
    certain insiders, and broker-dealers are required to make regular SEC filings. 

Text analysis
    Text is one of the most important informant belongs to unstructured 
       information. Text analysis, also called text mining, also referred 
       to as text data mining, roughly equivalent to text analytics, refers 
       to the procebeta of deriving high-quality information from text. 
       For example, we could look at the frequency of each words, keywords, 
       number of lines, sentences, frequency of positive words vs. negative, 
       tone of the speech etc. For example, let's look at the top used words 
       by Reagan in 1994 and Obama 2008, see below. Which one belongs to Obama?

 Text analysis for finance and accounting
      Applying text analysis to finance and accounting does not have a long history. 
      Li (2008) shows that the readability of 10-K filings has a statistically 
      significant impact on the performance of a firm's subsequent performance. 
      The readability measure used by Li (2008) is call Fog index defined below. 

              Fog index=0.4*(n+p)                  (1)  

    where, n is the average number of words per sentence, while p is  
           the percentage of complex words.  A complex word is a word has 
           more than two syllables.

    Because of defining and measuring readability in the context of financial 
       disclosures becomes important with the increasing use of textual analysis 
       and the SEC's plain English initiative, Lougran and McDonald (2015) show 
       that  the Fog Index - the most commonly applied readability measure - is poorly 
       specified in financial applications. Of Fog's two components, one is 
       mibetapecified and the other is difficult to measure. They suggest to use 
       the size of 10-K filing as a simple readability proxy and show that it 
       outperforms the Fog Index. Another added advantage is that it does not 
       require document parsing, thus facilitates replication. 

    According to Loughran and McDonald (2014), there are 632 different forms.  
       On the other hand, most researchers used only one or two forms, such 
       as 10-K. Thus, the SEC filings \"database\" is a gold mine waiting to 
       be explored. 

 Reference
       Li, Feng, 2008, Annual report readability, current earnings, and earnings 
           persistence, Journal of Accounting and Economics 45, 221 - 247.

   source(\"http://canisius.edu/~yany/textAnalysis.R\")

//////////////////////////////////////
"

.C31EXPLAIN16<-"businebeta cycle indicator
//////////////////////////////////////
There exist many profitable trading strategies, such as the individual stock 
momentum, first documented in Jegadeesh and Titman (1993), the industry momentum 
in Moskowitz and Grinblatt (1999), the effect of the 52-week high price in George 
and Hwang (2004), and the effect of the maximum daily return in a month in 
Bali et al. (2011). However, Yan and Zhang (2016) argue that those profitable 
trading strategies would not be profitable during difficult time. In other words, 
investors would change their behavior during a recebetaion. 

Objectives:
   1) understand the concept of businebeta cycle
   2) generate a businces cycle indicator
   3) if pobetaible run CAPM by including this indicator 

    Source of data: 
      1) Businebeta cycle data is from the National Bureau of Economic Research center. 
             The original starting date is June 1854.  
      2) stock data is from Yahoo!Finance. 

    Comments on your result

References
   Bali, Turan G., Nusret Cakici, and Robert F. Whitelaw, 2011, Maxing Out: 
         Stocks as Lotteries and the Crobeta-Section of Expected Returns, 
         Journal of Financial Economics 99 427-446.

   George, Thomas J, and Chuan-Yang Hwang, 2004, The 52-week High and Momentum 
         Investing, Journal of Finance 54, 5, 2145-2176.

   Grinblatt, Mark, and Bing Han, 2005, Prospect theory, mental accounting, 
         and momentum, Journal of Financial Economic 78, 311-339.

   Jegadeesh, N., and S. Titman, 1993, Returns to Buying Winners and Selling 
         Losers: Implications for Stock Market Efficiency, Journal of Finance 48, 65-91.

   Moskowitz, Tobias, and Mark Grinblatt, 1999, Do industries explain momentum? 
         Journal of Finance 54, 2017-2069.

   Yan, Yuxing and Shaojun Zhang, 2016, Businebeta cycle, investors' preferences 
         and trading strategies, Frontiers of Businebeta Research in China (forthcoming)  

  Table 1 from Yan and Zhang(2016)
        For a peak, we abetaign a positive 1 while for a trough, we abetaign a 
        negative 1. Any months between those peaks and troughs, we linearly 
        interpolate, see Panel B below. P for Peak and T for Trough. T(t-1) 
        is for the pervious Trough and P(t-1) is for the previous Peak. 

   Contraction        Expansion	cycle
     Peak (P)	      Trough (T)	P to T	T(t-1) to P  T(-1) to T    P(t-1) to P
  -----------         -----------------  ------  ----------  -----------   -----
  May 1923(II)        July 1924 (III)      14    22           36           40
  October 1926(III)   November 1927 (IV)   13    27           40           41
  August 1929(III)    March 1933 (I)       43    21           64           34
  May 1937(II)        June 1938 (II)       13    50           63           93
  February 1945(I)    October 1945 (IV)     8    80           88           93
  November 1948(IV)   October 1949 (IV)    11    37           48           45
  July 1953(II)       May 1954 (II)        10    45           55           56
  August 1957(III)    April 1958 (II)       8    39           47           49
  April 1960(II)      February 1961 (I)    10    24           34           32
  December 1969(IV)   November 1970 (IV)   11   106          117          116
  November 1973(IV)   March 1975 (I)       16    36           52           47
  January 1980(I)     July 1980 (III)       6    58           64           74
  July 1981(III)      November 1982 (IV)   16    12           28           18
  July 1990(III)      March 1991(I)         8    92          100          108
  March 2001(I)       November 2001 (IV)    8   120          128          128
  December 2007(IV)   June 2009 (II)       18    73           91           81

//////////////////////////////////////
"

.C31EXPLAIN17<-"illiquidity measure, Amihud (2002)
//////////////////////////////////////
Objective: estimate 12 stocks' illiquidity measures for each month in 2016. 
     Note: you choose the last 6 stock yourself. Comments on your findings

     6 stock symbols are given below. 
        Company name            Ticker	Industry
        ----------------------  ------  ------------------
   1	Microsoft Corporation   MSFT    Application software
   2	Apple Inc.              AAPL    Personal Computer
   3	Citigroup Inc.             C    Money Center Banks
   4	Wal-Mart Stores, Inc.    WMT    Discount, Variety Stores
   5	Home Depot, Inc.          HD    Home improvement services
   ..   .................       ...     ......
  12	General Electric Corp     GE	Technology

 Amihud (2002) illiquidity measure uses the absolute daily return over 
   its corresponding trading dollar volume. A monthly stock illiquidity 
   measure is the mean of daily illiquidity measure.  
                   1                |Ri|
       illiq(t)=  --- * sum (--------------- )      (1)
                   n             pi * Vi

   where illiq(t) is a monthly illiquidity measure, n is the number of 
         trading days within the month, Ri is daily return on day i, 
         Vi is the trading volume on day i and Pi is the closing 
         price of the underlying stock on day i. 

   The Amihud illiquidity measure includes two components: 
        spread and the impact of trading. Illiquidity is the 
        opposite of liquidity, i.e., a higher value indicates a low 
        liquidity and a small value indicates a higher liquidity level. Why?

   Step 1: download daily price data from Yahoo Finance 
   Step 2: estimate daily returns and dollar trading volume
   Step 3: estimate the ratio
   Step 4: estimate monthly illiquidity measures
 References
    Amihud,Yakov,2002,Illiquidity and Stock returns,
       Journal of Financial Markets 5, 31-56.

//////////////////////////////////////
"
.C31EXPLAIN18<-"liquidity measure, Pastor and Stambough (2003)
//////////////////////////////////////
Objectives: 
    1) Understand the logic of the measure
    2) Learn how to download and procebeta data from Yahoo!Finance
    3) estimate individual stock's liquidity 

  Basic logic:Pastor and Stambaugh (2003) design the following 
        regrebetaion to estimate individual stock's liquidity.  

            y(t)=alha +beta1*x1(t-1)+ beta2*x2(t-1)+error(t)           (1)

    where,y(t) is the excebeta stock return on day t, the excebeta return is 
          defined as R(t)-Rm(t),  R(t) is the stock return, Rm(t) is the 
          market return at time t; x1(t-1) is the lagged stock return, 
          i.e., R(t-1), X2(t-1) is the lagged dollar trading volume, i.e., 
          x2(t-1)=P(t-1)*V(t-1), P(t-1) is the daily closing price of the stock 
          at t-1 and V(t-1) is the daily trading volume at t-1. 
          
    The regrebetaion is based on the daily data within each month with a 
         minimum number of observations of 15. The liquidity measure for an 
         individual stock in each month is defined as:
 
            	liquidity measure=beta2       (2)

     For the first trial, we ignore other constraints.  The Market liquidity 
         is the equally weighted individual stock's liquidity and scaled by 
         the market capitalization.
Procedure:
	Step 1: Retrieve daily data
	Step 2: generate y, x1, x2 for each stocks 
	Step 3: Run regrebetaion (1) to estimate beta2 for each month
References
    Pastor, L. & Stambaugh, R., 2003, Liquidity risk and expected stock returns. 
    Journal of Political Economy 111, 642-685.

//////////////////////////////////////
"

.C31EXPLAIN19<-"Spread estimation from TAQ (Trade and Quote) high-frequency data 
//////////////////////////////////////
Objectives:
   1)  Understand the structure of TAQ database
   2)  Using Excel to retrieve data from one day's data sets
   3)  estimate the spread for 10 stocks

  High-Frequency trading has attracted lots of attention because of its 
  huge profits and because of  it is not clear whether it is fair to small 
  investors and its impact on the health of the stock market. According to 
  Investopedia, HFT (High-Frequency Trading) is defined as: A program trading 
  platform that uses powerful computers to transact a large number of orders 
  at very fast speeds. High-frequency trading uses complex algorithms to analyze 
  multiple markets and execute orders based on market conditions. Typically, the 
  traders with the fastest execution speeds will be more profitable than traders 
  with slower execution speeds. As of 2009, it is estimated more than 50% of exchange 
  volume comes from high-frequency trading orders.  To understand HFT, we have to 
  understand TAQ (Trade and Quote) database. 

  Data Sets: November 1, 2004 is randomly selected as our day, see its 4 
     data sets below. Two index files have an extension of \".idx\", while 
     two data files have an extension of \".bin\".
  
  12/01/2004  04:03 PM     1,800,548,334 Q200411a.bin
  12/01/2004  04:03 PM           182,424 Q200411a.idx
  12/01/2004  04:08 PM       184,899,853 T200411a.bin
  12/01/2004  04:08 PM           169,334 T200411a.idx
                4 File(s)  1,985,799,945 bytes
    References
   Philips, Matthew, What Michael Lewis Gets Wrong About High-Frequency Trading, 4/1/2014
   http://www.bloomberg.com/bw/articles/2014-04-01/what-michael-lewis-gets-wrong-about-high-frequency-trading

   Appendix A: first several lines from CQ (consolidated Quotes) from TAQ
   symbol	date	time	bid	ofr	bidsiz	ofrsiz	mode	EX	MMID
   A	20040401	8:00:02	30.62	32.64	1	1	12	P	 
   A	20040401	8:11:40	29.68	33.58	20	20	12	P	 
   A	20040401	8:12:56	30.7	33.58	2	20	12	P	 
   A	20040401	8:30:02	0	0	0	0	12	T	BRUT
   A	20040401	8:30:02	1	100	1	1	12	T	CAES
  A	20040401	8:30:02	0	0	0	0	12	T	DATA
  A	20040401	8:30:02	0	0	0	0	12	T	MADF

  Table 1: structure of a binary index file. The size (bit) of an index file is 22 with 4 variables.
   #	Name of the variable	Meaning	Size	Type
   1	Ticker	Stock symbol	10	Character
   2	Date	Trading date	4	Integer
   3	Begrec	Beginning record	4	Integer
   4	Endrec	Ending record	4	Integer

  Table 2: Structure of binary CT (Consolidated Trade) file. The size is 29 with 8 variables.
   #	Name of the variable	Meaning	Size	Type
   1	Time 	Trading time	4	Integer
   2	Price	Trading price	8	Float
   3	Tseq	Sequence number 	4	Integer
   4	Size	Trading size	4	Integer
   5	G127	G127 rule	2	Integer
   6	CORR	Correction 	2	Integer
   7	COND	Sale condition	4	Character
  8	Ex	Exchange	1	Character

  Table 3: Structure of a binary CQ (Consolidated Quote) file. The size is 39 with 9 variables.
  #	Name of the variable	Meaning	Size	Type
  1	Time 	Trading time	4	Integer
  2	Bid	Bid price	8	Float
  3	Ofr	Ask price  	8	Float
  4	Qseq	Sequence number	4	Integer
  5	Bidsiz	Bid size	4	Integer
  6	Asksiz	Ask size 	4	Integer
  7	MODE	quote condition  	2	Integer
  8	EX	Exchange	1	Character
  9	MMID	NASDAQ market maker	4	Character
 
//////////////////////////////////////
"
.C31EXPLAIN20<-"Reverse mortgage calculator
//////////////////////////////////////
EXAMPLE #1: John Bosworth, Age 68
            Home Value - $250,000
            Home Equity - $210,000
            Approximate Mortgage Balance - $40,000
 Challenge: John is a widower who lives at home alone. He would like to 
            keep his home, but is having trouble making payments and meeting expenses. 
            His monthly mortgage payment is $611. Even with both Social Security 
            income and pension, he is still short by $187 per month...
 Solution:  John takes out a tax free reverse mortgage for $142,496. He takes a 
            lump sum of $40,000 and applies it to his existing mortgage and the 
            balance in monthly payments of $681. After paying the mortgage off 
            entirely, John's monthly income rises to $1,291. That's $611 per 
            month for the mortgage payment, plus another $681 from the reverse mortgage.
EXAMPLE #2
    Craig Jenkins, Age 82, and Sylvia Jenkins, Age 79 (reverse mortgages are 
    calculated using the age of the youngest home owner)
  	Home Value - $375,000
 	Home Equity - $375,000
  Challenge:
      Craig and Sylvia both take medication to stay in good health. The cost 
      of monthly meds and treatments makes it difficult for them to find the 
      money needed to maintain the quality of life they once enjoyed.
  Solution:
     They take out a tax free reverse mortgage with the option of one lump sum 
     totaling $218,419, or a monthly income of $1,495. The extra cash flow from 
     their reverse mortgage more than covers their monthly cost for medication, 
     and allows Craig and Sylvia more freedom with much lebeta strebeta.

 EXAMPLE #3
    Kathy Tobias, Age 63, and Rinaldi Tobias, Age 71 (reverse mortgages are 
     calculated using the age of the youngest home owner)
         Home Value - $165,000
         Home Equity - $165,000
    Challenge:
       Kathy and Rinaldi would like to spend their retirement traveling around 
       the U.S. in their RV, but don't have extra money they would need to help  
       pay for rising gas prices and other added travel expenses.
    Solution:
      They take out a tax free reverse mortgage of $82,419. This will give them  
      an extra $519 per month which they can use any way they'd like, and more 
      than supplements their need for gas and RV maintenance. 
EXAMPLE #4
       Gordon Penilla, Age 62, and Joanne Penilla, Age 65 (reverse mortgages are 
       calculated using the age of the youngest home owner)
           Home Value - $850,000
           Home Equity - $850,000
    Challenge:
        Gordon and Joanne have no real debts, and their monthly income is  
        adequate for them to live life as planned, but they would like to 
        help out with the cost of college tuition for a grand child. For that, 
        their income monthly and savings do not suffice.
    Solution:
       Gordon and Joanne take out a tax free reverse mortgage credit line allowing 
       up to $265,411. Each grandparent can now bestow a monetary gift to the grandchild, 
       the amount being that which is currently allowed by law.

  Note 1: Reverse mortgage proceeds are based upon the current interest rates at the time the 
          loan closes, the age of the youngest borrower, and the equity in the home. The examples 
          above are based on an interest rate of 6.26%.
  Note 2: Borrowers can lock rates in for 60 days from the date of application to the closing. 
          All rates adjust weekly, and the rate for closing is determined by the weekly rate  
          set on Tuesdays of each week (excluding Federal Holidays) and stay valid until the following Monday.

  http://www.seacoastreversemortgage.com/loanOptions/Custom%20Pages/Scenario%20Examples/
  http://www.kiplinger.com/article/retirement/T035-C000-S001-reverse-mortgages-risky-for-boomers.html

//////////////////////////////////////
"
.C31EXPLAIN21<-"KMV model and default probability
//////////////////////////////////////
Objective: 
   1) Estimate market value and its volatility for KMV model
   2) estmate default point
   3) estimate default probablity 

 KMV stands for Kealhofer, McQuown and Vasicek who found a company focusing 
    on measuring default risk. KMV methodology is one of the most important 
    methods to estimate the probability of default for a given company by 
    using its balance sheet information and the equity market information.  

 The objective here is to estimate the market value of total abetaets (A) and 
    its corresponding volatility (sigmaA). The result will be used to estimate 
    default distance and default probability. 

 The basic idea is to treat the equity of a firm as a call option and the debt is 
    its strike price. Let us look at the following simplest example. For a firm, 
    if its debt is $80 and equity is $20 then the total abetaets will be $100. 

 Abetaume that the abetaets jump to $110 and the debt remains the same, the equity 
    increases to $30. On the other hand, if the abetaets drop to $90, the equity 
    will be only $10. Since the equity holders are the residual claimer, their 
    value has the following exprebetaion. 

           E  = max?(abetaets - debt,0)=max?(A-D,0)          (1)

    Recall for a call option, we have the following payoff function. 

       Payoff(call) = max?(sT-K,0)                        (2)

   This means that we could treat equity as a call option with debt as 
      our exercise price.  With appropriate notations, we will have the 
      following formulae for a firm's equity. KMV model is defined below. 

             E=A*N(d1 )-e^(-rT) N(d2)

               ln?(A/D)+(r+0.5*sigma^2 )T
        d1 =   ---------------------------               (3)
                   sigmaA * sqrt(T)
        d2 =d1- sigmaA *sqrt(T)                         

  On the other hand, the following relationship between the volatilities 
     of the equity and the total abetaets holds. In the following equation, 
     we have  delta=dE/(dVA )=N(d1 ). 

         sigmaE=A/E
                       N(d1)*A*sigmaA
        delta_sigmaA=   -------------                    (4)
                           E
   Since d1 and d2 are defined by the above equations, we have two equations 
      for two unknown (A and sgimaA), see below. Thus, we could use a 
      trial-and-error or simultaneous equation method to solve for those 
     two unknowns.  Eventually, we want to solve the following two equations for A and s_A.

                 E=A*N(d1)-e^(-rT) *N(d2 )
                           A
                 sigmaE=  --- * N(d1)*siamgA             (5)
                           E
   We should pay attention that the estimated A (Market value of total abetaets) 
      from Equation (5) is different from the summation of market value of abetaets 
      plus the book value of the debt. The usages of those two derived values 
      (A and sigmaA) will be used by Equations (6-8). 

   Here is a KMV example: E=110,688 (shares outstanding*price of stock), 
      D=64,062 (total debt), Rf=0.07 (risk-free rate), T=1 (1 year).  
      The result is A=170,558 sA=0.29.  Based on the following codes 
      we got A=170,393 and sigmaE=0.2615. The output is : A=170,393.78 
      and sigmaE is 0.2615. Please pay attention that the summation of 
      the book value of debt and the market value of equity is 174,750 (?170,558). 

  Distance to Default
     Distance to default (DD) is defined by the following formula, where A 
     is the market value of the total abetaets and sigmaA  is its risk. 
     The interpretation of this measure is clear, the higher DD, the safer is the firm. 

               A - Default Point 
       DD= -----------------------                      (6)
                  A *sigmaA                              

  In terms of Default Point, there is no theoretical fixed default point. 
     However, we could use all short-term debts plus the half of long-term 
     debts as our default point.  After we have the values of MV of abetaets 
     and its volatility, we could use the following equation to estimate the 
     Distance to Default. The A and s_A are from the output from Equation (5). 
     On the other hand, if the default point equals to E, we would have the following formula. 

                  ln(VA/D)+(r-0.5*sigmaA^2)T
          DD= -  -------------------------------        (7)
                    sigmaA*sqrt(T) 				

    Note that there is a negative sign in front of the ratio
    According to Black-Scholes model, the relationship between DD and Default Probability
           is given below. 
        DP(Default Probability) = N(-DD)                (8)

//////////////////////////////////////
"

.C31EXPLAIN22<-"Financial statement analysis
//////////////////////////////////////
Objective: 
   1) Understand the importance of financial statement analysis 
   2) understand the definitions of various ratios, such as
       Debt/equity ratio, ROE, ROA, DuPoint Identity
   3) Compare the performance of the firm with itself and with peers
   4) Given your recommendations 

   Note: If you could \"automate\" your procebeta, it will be more 
         meaningful. For example, you spend one day to finaish one company. 
         How long you would finish the next one or 10th one?

  Here are potential helps. 
        1) get financial statement easily, see type
           c28
        2) You can use some simple macro, such as record your operation
           c26
Procedure: 
   1) Download a compay's several years' financial statements 
   2) Conduct analysis such as ratio analysis
   3) Compare its performance with itself and with peers
   4) Write your comments and recommendation 

//////////////////////////////////////
"

.C31EXPLAIN23<-"Black and Litterman model (1992)
//////////////////////////////////////
Objective: 
----------
   1) Understand the shortcomings of our optimization model 
   2) understand the contributions of Black and Litterman (1992)
   3) using Excel to illustrate a few examples 
   4) Extension? 

Sources
-------
     blacklitterman.org   
         http://blacklitterman.org

     Black and Little example
         http://canisius.edu/~yany/excel/blacklitterman.xlsx

//////////////////////////////////////
"

.C31EXPLAIN24<-"Brandt, Santa-Clara and Valkanov model (2009)
//////////////////////////////////////
Objective: 
----------
   1) Understand the shortcomings and limitatons of the current optimization model 
   2) understand the contributions of Brandt et al. (2009)
   3) using Excel to illustrate a few examples 
   4) Extension? 

Sources
-------
    
//////////////////////////////////////
"

.C31EXPLAIN25<-"SEC filings 
//////////////////////////////////////
Objectives: 
----------
   1) Understand what is the usages of SEC filings 
   2) understand how to search SEC EDGAR platform
   3) download one quarterly file  and using Excel to explore 
      a) How many company
      b) how many CIK
      c) how many forms
      e) frequency of those forms
      f) others
   4) potential applications 

Sources
-------
   https://www.sec.gov/edgar.shtml
   https://www.sec.gov/forms
   https://www.sec.gov/Archives/edgar/full-index/

The first several lines from Q3 2017
-------------------------------------------
Description:           Master Index of EDGAR Dibetaemination Feed by Company Name
Last Data Received:    September 30, 2017
Comments:              webmaster@sec.gov
Anonymous FTP:         ftp://ftp.sec.gov/edgar/
 
 
 
 
Company Name                                                  Form Type   CIK         Date Filed  File Name
---------------------------------------------------------------------------------------------------------------------------------------------
(OurCrowd Investment in MST) L.P.                             D           1599496     2017-08-24  edgar/data/1599496/0001465818-17-000048.txt         
1 800 FLOWERS COM INC                                         10-K        1084869     2017-09-15  edgar/data/1084869/0001437749-17-015969.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028807.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028809.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028810.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028811.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028812.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028813.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028814.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028815.txt         
1 800 FLOWERS COM INC                                         3           1084869     2017-07-27  edgar/data/1084869/0001140361-17-028816.txt

Note: combine a) and b) below 
    a) https://www.sec.gov/Archives/

    b) 2017-08-24  edgar/data/1599496/0001465818-17-000048.txt 

   we have 
      https://www.sec.gov/Archives/edgar/data/1599496/0001465818-17-000048.txt
    
//////////////////////////////////////
"

.C31EXPLAIN26<-"TORQ database 
//////////////////////////////////////


//////////////////////////////////////
"

.C31EXPLAIN27<-"SEC 10-K: BS, IS or CF 
//////////////////////////////////////
 This is a very intereting projects. 
 If you could generate BS or IS, it will be more than enough. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 
 Step 2: unzip one and write a SAS program to retrive data 

 Step 3: work on one zip file 

 Step 4: write SAS programs to generate many 
         individual SAS data sets or generate 
         one big SAS data set, 

 Step 5: Generate your own BS
         Method I: download latest several years 
                   BS from Yahoo!Finance
                   replicate with your data 
              
         Method II: generate your own BS

  Advantage with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate industry means such as 
                           CA
            Quick Ratio ----------
                           CL 

              CA is the current abetaets
              CL is the current liability 
         d) you could generate some SAS, R or Python 
            data sets

//////////////////////////
"
.C31EXPLAIN28<-"SEC Forms 3, 4 and 5 
//////////////////////////////////////
What are Forms 3, 4, and 5?
.   Corporate insiders - meaning a company's officers and directors, and any beneficial owners 
   of more than ten percent of a clabeta of the company's equity securities registered under 
.   Section 12 of the Securities Exchange Act of 1934 - must file with the SEC a statement 
   of ownership regarding those securities. On August 27, 2002, the SEC adopted rules and 
   amendments to Section 16 of the Exchange Act, implementing the provisions of the 
   Sarbanes-Oxley Act of 2002 that accelerated the deadline for filing most insider 
   ownership reports.

   The initial filing is on Form 3. An insider of an ibetauer that is registering equity
   securities for the first time under Section 12 of the Exchange Act must file this 
   Form no later than the effective date of the registration statement. If the ibetauer 
   is already registered under Section 12, the insider must file a Form 3 within ten 
   days of becoming an officer, director, or beneficial owner.

  Changes in ownership are reported on Form 4 and must be reported to the SEC within 
  two businebeta days. You can find the limited categories of transactions not subject 
  to the two-day reporting requirement in the new rule.

  Insiders must file a Form 5 to report any transactions that should have been reported 
  earlier on a Form 4 or were eligible for deferred reporting. If a Form must be filed, 
  it is due 45 days after the end of the company's fiscal year.
 
  Today, the financial statement analysis has nothing to do with 
     insider trading. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 
 Step 2: unzip one and write a SAS program to retrive data 

 Step 3: work on one zip file 

 Step 4: write SAS programs to generate many 
         individual SAS data sets for Forms 3, 4 and 5 

 Step 5: Make your data sets quite user friendly 
              
  Advantages with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate all insiders trades  
        d) you could generate some SAS, R or Python data sets
  https://www.sec.gov/fast-answers/answersform345htm.html

//////////////////////////
"

.C31EXPLAIN29<-"SEC 10-K (13-f) 
//////////////////////////////////////
What is 13-f?
--------------
  Form 13F-?Reports Filed by Institutional Investment Managers
  An institutional investment manager that uses the U.S. mail (or other means
  or instrumentality of interstate commerce) in the course of its businebeta, 
  and exercises investment discretion over $100 million or more in Section 
  13(f) securities (explained below) must report its holdings on Form 13F 
  with the Securities and Exchange Commibetaion (SEC).

  In general, an institutional investment manager is: (1) an entity that 
  invests in, or buys and sells, securities for its own account; or (2) 
  a natural person or an entity that exercises investment discretion over
  the account of any other natural person or entity. Institutional 
  investment managers can include investment advisers, banks, insurance 
  companies, broker-dealers, pension funds, and corporations.

  Form 13F is required to be filed within 45 days of the end of a calendar 
  quarter. The Form 13F report requires disclosure of the name of the 
  institutional investment manager that files the report, and, with respect
  to each section 13(f) security over which it exercises investment discretion, 
  the name and clabeta, the CUSIP number, the number of shares as of the end of 
  the calendar quarter for which the report is filed, and the total market value.

  Today, the financial statement analysis does not consider the holdings
    of financial institutions. 

 Step 1: download all SEC Financial Statements by using 
         .dumpSECfinS function from 2009 to 2018
 Step 2: unzip one and write a SAS program to retrive data 
 Step 3: work on one zip file 
 Step 4: write SAS programs to generate many 
         individual SAS data sets for Forms 3, 4 and 5 
 Step 5: Make your data sets quite user friendly 
              
  Advantages with your data sets
        a) 10 years' data from 2009 to 2018
        b) next year, we will have one more year
        c) Easily estimate all insiders trades  
        d) you could generate some SAS, R or Python data sets
  https://www.sec.gov/fast-answers/answers-form13fhtm.html

//////////////////////////
"
.C31EXPLAIN30<-"SEC Mutual Fund Prospectus Risk/Return Summary Data Sets	
//////////////////////////
The Mutual Fund Prospectus Risk/Return Summary Data Sets provides text and
  numeric information extracted from the risk/return summary section of 
  mutual fund prospectuses. The data is extracted from exhibits to mutual 
  fund prospectuses tagged in eXtensible Businebeta Reporting Language (XBRL).
  The information is presented without change from the \"as filed\" submibetaions
  by each registrant as of the date of the submibetaion. The data is presented 
  in a flattened format to help users analyze and compare corporate disclosure 
  information over time and acrobeta registrants.

  The data sets will be updated quarterly. Data contained in documents filed 
  after 5:30PM Eastern on the last businebeta day of a quarter will be included
  in the subsequent quarterly posting.

  https://www.sec.gov/dera/data/mutual-fund-prospectus-risk-return-summary-data-sets

  The Mutual Fund Prospectus Risk-Return Summary Data Sets (PDF, 207 kb) 
  https://www.sec.gov/dera/data/rr1.pdf 
  provides documentation of scope, organization, file formats and table definitions.

//////////////////////////
"

.C31EXPLAIN31<-"Census Summary Form 1 (SF1)
//////////////////////////
What is SF 1?
  Summary File 1 (SF 1) contains the data compiled from the questions asked of 
  all people and about every housing unit. Population items include sex, age, 
  race, Hispanic or Latino origin, household relationship, household type, 
  household size, family type, family size, and group quarters. 

  Housing items include occupancy status, vacancy status, and tenure (whether 
  a housing unit is owner-occupied or renter-occupied).

  There are 177 population tables (identified with a \"P\") and 58 housing tables
  (identified with an \"H\") shown down to the block level; 82 population tables 
  (identified with a \"PCT\") and 4 housing tables (identified with an \"HCT\") 
  shown down to the census tract level; and 10 population tables (identified with 
  a \"PCO\") shown down to the county level, for a total of 331 tables. The SF 1 
  Urban/Rural Update added 2 PCT tables,increasing the total number to 333 tables. 
  There are 14 population tables and 4 housing tables shown down to the block level 
  and 5 population tables shown down to the census tract level that are repeated by
  the major race and Hispanic or Latino groups.
  
  SF 1 includes population and housing characteristics for the total population,
  population totals for an extensive list of race (American Indian and Alaska 
  Native tribes, Asian, and Native Hawaiian and Other Pacific Islander) and 
  Hispanic or Latino groups, and population and housing characteristics for 
  a limited list of race and Hispanic or Latino groups. Population and housing 
  items may be crobeta-tabulated. Selected aggregates and medians also are provided.

  A complete listing of subjects in this file is found in the \"Subject Locator\"  chapter.

  To download all data, type
     .dumpCensubetaF1   

  source of data: https://www2.census.gov/census_2010/04-Summary_File_1/
  Manual: https://www.census.gov/prod/cen2010/doc/sf1.pdf   

//////////////////////////
"

.C31EXPLAIN32<-"Census Summary Form 2 (SF2)
//////////////////////////
What is SF2?
   Summary File 2 (SF 2) contains the data compiled from the questions asked of 
   all people and about every housing unit. SF 2 includes population characteristics,
   such as sex, age, average household size, household type, and relationship to 
   householder such as nonrelative or child. The file includes housing characteristics,
   such as tenure (whether a housing unit is owner-occupied or renter-occupied), 
   age of householder, and household size for occupied housing units. 

  Selected aggregates and medians also are provided. A complete listing of 
  subjects in SF 2 is found in Chapter 3, Subject Locator. The layout of the 
  tables in SF 2 is similar to those in SF 1. 

  These data are presented in 47 population tables (identified with a \"PCT\") 
  and 14 housing tables (identified with an \"HCT\") shown down to the census 
  tract level; and 10 population tables (identified with a \"PCO\") shown 
  down to the county level, for a total of 71 tables. Each table is iterated 
  for 331 population groups: the total population, 75 race categories, 114 
  American Indian and Alaska Native categories (reflecting 60 tribal groupings), 
  47 Asian categories (reflecting 24 Asian groups), 43 Native Hawaiian and Other 
  Pacific Islander categories (reflecting 22 Native Hawaiian and Other Pacific
  Islander groups) and 51 Hispanic/not Hispanic groups. The presentation of SF 2 
  tables for any of the 331 population groups is subject to a population threshold 
  of 100 or more people. That is, if there are fewer than 100 people in a specific
  population group in a specific geographic area, their population and housing 
  characteristics data are not available for that geographic area in SF 2. 

  To download all data, type
     .dumpCensubetaF2   

  Source of data 
     https://www2.census.gov/census_2010/05-Summary_File_2/

  Manual 
     https://www.census.gov/prod/cen2010/doc/sf2.pdf

//////////////////////////
"

.C31EXPLAIN33<-"Census Demographic profile
//////////////////////////
A short intro 
-------------
   The Demographic Profile Summary File contains 100 percent data asked of 
   all people and about every housing unit on topics such as sex, age, race, 
   Hispanic or Latino origin, household relationship, household type, group 
   quarters population, housing occupancy, and housing tenure. 

   GEOGRAPHIC CONTENT
     The Demographic Profile Summary File is released as individual files for 
     the United States, each of the 50 states, the District of Columbia, and 
     Puerto Rico. The data items are identical for all files, but the geographic
    coverage differs.

    The summary level sequence chart outlines the hierarchical and geographic 
    summaries in their entirety. 
 
  To download all data, type
  ---------------------------
    .dumpCensusDemographicProfile

  Source of the data 
      https://www2.census.gov/census_2010/03-Demographic_Profile/
  Manual 
     https://www.census.gov/prod/cen2010/doc/dpsf.pdf
  Manual about the data structure 
     https://www2.census.gov/census_2010/03-Demographic_Profile/0README_DPSF.pdf

//////////////////////////
"
.C31EXPLAIN34<-"Census Redistribution
//////////////////////////
  To download all data, type
    .dumpCensusRedistribution

  source of data 
     https://www2.census.gov/census_2010/redistricting_file--pl_94-171/

//////////////////////////
"

.C31EXPLAIN35<-"Census Congrebetaional Districts113
//////////////////////////
 To download all data, type
    .dumpCensusCongrebetaionalDistricts113 

 Source of data 
     https://www2.census.gov/census_2010/08-SF1_Congrebetaional_Districts_113/

//////////////////////////
"

.C31EXPLAIN36<-"Census Congrebetaional Districts115
//////////////////////////
 To download all data, type
    .dumpCensusCongrebetaionalDistricts115 

 Source of data 
    https://www2.census.gov/census_2010/08-SF1_Congrebetaional_Districts_115/

//////////////////////////
"
.C31EXPLAIN37<-"Survey of Consumer Finances (SCF)
//////////////////////////
 To download all data, type
  .dumpSCF 

 Source of data 
    https://www.federalreserve.gov/econres/scfindex.htm

//////////////////////////
"

.C31EXPLAIN38<-"Extra high-frequency data 
//////////////////////////
  Extra high-frequency data 
    ftp://ftp.nyxdata.com/Historical%20Data%20Samples/

//////////////////////////
"
.C31EXPLAIN39<-"Build a slot machine
/////////////////////////
The logic of the game 
---------------------

    Our bet is $1. We randomly choose 3 numbers from 1 to 10. 
    if they are equal, we win $90. Otherwise, we loose our bet. 

  Step 1: choose a cell to enter =randbetween(1,10)
  Step 2: format it nicely 
          a) choose several cells around it, 
             click \"merge & Center \" on the menu bar
          b) Highlight those cells -> Click \"Conditional Formatting\"
             choose \"Color Scales\" -> choose 

  Step 3: Copy the cells to another two places 
  Step 4: choose a cell to calculate win or lobeta
          if three of them are equal, win 90, otherwise -1
  Step 5: find a cell we could enter our initial cash 
  Step 6: choose a cell to calculate the cumulative lobeta
          Abetaume that our cumulative lobeta cell is I3
          our win or lobeta is in cell  F3, see step 4

  Step 7: Click \"Developer\" -> View Code -> Copy that paste the following macro 

Sub games()
Range(\"I3\").Value = Range(\"I3\").Value + Range(\"F3\").Value
End Sub
  [Note: we need some value is I3 to make it work]
/////////////////////////
"

# .C31EXPLAIN40 is Chapter 30

.tp<-.termProjects
.chapter4<-function(i){
" i  Chapter 4: Capital budgeting     
  -  -------------------------------------
  1  Recap: definition of NPV (Net Present Value) 
  2  Recap: NPV rule 
  3  Recap: Excel NPV() function is a PV function 
  4  VBA 4 for a true NPV function 
  5  VBA 4 for a true NPV function (2)
  6  Definition of IRR (Internal Rate of Return)
  7  IRR rule 
  8  Excel IRR() function 
  9  Excel MIRR() function  
 10  IRR() function and Rate() function
 11  Definition of a 'normal' project'
 12  Draw a graph: Rc vs. NPV
 13  How to get multiple IRRs
 14  NPV rule dominates IRR rule 
 15  For small projects: IRR rule 
 16  Profitability index and related rule
 17  Profitability Example
 18  Payback period and payback period rule
 19  YouTube 
 20  Links

 Example #1:> .c4    # get the above list
 Example #2:> .c4(1) # see the first explanation

";.chapter4_(i)}

.n4chapter<-20

.chapter4_<-function(i){
    .printEachQ(4,i,.n4chapter)
}

.c4<-.chapter4


.C4EXPLAIN1<-"Recap: definition of NPV (Net Present Value) 
////////////////////////////////
Method I: 
           NPV = PV(all benefits) - pv(all costs)
Method II: 
          if cash outflow is defined as a negative value
             cash inflow  is defined as a positive value

          NPV = PV(all cash flows)

////////////////////////////////
"

.C4EXPLAIN2<-"Recap: NPV rule 
////////////////////////////////
  NPV Rule: for an independent project

        if NPV(Project) > 0 accept

        if NPV(Project) < 0 reject

////////////////////////////////
"
.C4EXPLAIN3<-"Excel npv() is actually a pv function
////////////////////////////////
Example 1: 
    If We invest $100 today and will get $120 at the end of year one. 
    if the discount rate is 10%, what is the NPV?

   1) Manually calculate the result =(120)/(1+0.1) -100 = 9.090909091
   2) Using the NPV function()
        we enter the following two values at A1 and A2
           -100
            120

           =NPV(0.1,A1:A2)   ==> 8.26 
     The correct formula should be 
           =NPV(0.1,A2)+A1   ==> 9.09 

Example 2: 
time cashflow
0   -100
1    40
2    30
3    40
4    20
5   -10

////////////////////////////////
"

.C4EXPLAIN4<-"VBA for a true NPV function 
////////////////////////////////
Function npvTRUE(rate As Double, cashFlows As Range) As Variant
    npvTRUE = Application.NPV(rate, cashFlows) * (1 + rate)
End Function

Function npvTrueHelp() As String
  npvTrueHelp = \"usage: =npvTrue(rate,cashflows)\"
End Function

////////////////////////////////
"

.C4EXPLAIN5<-"VBA 4 a true NPV function (2)
////////////////////////////////
Function NPVyan2(rate As Single, x As Range) As Variant
' Author yuxing.yan at canisius dot edu
' Date  : 10/23/2012
     Dim i, n, n2 As Integer, sum As Single
     sum = x(1, 1)
     i = 2
     n = x.Rows.Count
     n2 = x.Columns.Count
     If n > 1 Then
          Do While i <= n
              sum = sum + x(i, 1) / (1 + rate) ^ (i - 1)
              i = i + 1
          Loop
      Else
         Do While i <= n2
             sum = sum + x(1, i) / (1 + rate) ^ (i - 1)
              i = i + 1
          Loop
      End If
     NPVyan = sum
End Function

////////////////////////////////
"

.C4EXPLAIN6<-"Definition of IRR (Internal Rate of Return) 
////////////////////////////////
IRR is the discount rate makes NPV equal zero. 

////////////////////////////////
"

.C4EXPLAIN7<-"IRR Rule 
////////////////////////////////
  IRR rule:

        if IRR(project) > Rc  accept

        if IRR(project) < Rc  reject

   Rc is the cost of capital of the project

////////////////////////////////
"

.C4EXPLAIN8<-"Excel IRR() function 
////////////////////////////////

   =IRR(cash flows,[guebeta])

      Cash flows are our cash flows
      guebeta is an optional value 

////////////////////////////////
"

.C4EXPLAIN9<-"Excel MIRR() function  
////////////////////////////////
   =MIRR(values, finance_rate, reinvest_rate)

   For IRR, it abetaumes that the reinvest rate is the same as IRR. 

Abetaume that we have the following cash flows (in C2:C5)
-100
50
60
70

  =irr(C2:C5)             -> 0.3387

  =MIRR(C2:C5,0.1,0.08)   -> 0.2453


////////////////////////////////
"

.C4EXPLAIN10<-"IRR() function and Rate() function
////////////////////////////////
Concept 1: A normal project: cash outflow first, cash inflows later 

Concept 2: IRR rule is only apply to a normal project.

Concept 3: if the direction of cash flows change more than once
           we might have multiple IRRs

Generally speaking, we could use the Excel IRR() function to estimate IRR. 

time cashflow
0   -100
1    40
2    30
3    40
4    20

     =IRR(D5:D9)   ==>12.4164%

   For bonds, we could use the Excel Rate() function as well. 

   For a bond: face value $1,000, coupon rate is 4% per year.
       Maturity is 10 years. The coupon payments are twice per year. 
       If we spent $950 to buy the bond, what is the annual 
       rate of our investment?

   Here is the Excel rate function
      =rate(nper,pmt,pv,[fv],[type],[guebeta])
    
   Try to get the YTM by using both ways. 

////////////////////////////////
"


.C4EXPLAIN11<-"Definition of a 'normal' project 
////////////////////////////////

 A normal project: cash out flows first, then cash inflows

 For the NPV rule, whether a normal project or not, it is not important. 

  However, when applying IRR rule, it is very important. 

////////////////////////////////
"

.C4EXPLAIN12<-"Draw a graph: Rc vs. NPV
////////////////////////////////

Time 	cashflow
0	504
1	-432
2	-432
3	-432
4	832

given a set of discount rate

     Rate NPV
     0     x
     0.1   x

     1.0   x

////////////////////////////////
"

.C4EXPLAIN13<-"How to get multiple IRRs
////////////////////////////////
Abetaume that we have a set of cash flows. 
0	-100000
1	205000
2	-102000

 Step 1: Generate a column called R (Rate)
         such 
          -0.30
          -0.25
            .
            .
          0.55
          0.60

 Step 2: Generate another column called NPV

 Step 4: When the NPV change sign, use the nearby 
         rate as our guebeta in the IRR() formula. 

////////////////////////////////
"

.C4EXPLAIN14<-"NPV rule dominates IRR rule 
////////////////////////////////

 If NPV rule and IRR rules have different conclusions, 
   NPV Rule dominates 

////////////////////////////////
"

.C4EXPLAIN15<-"How to get multiple IRRs
////////////////////////////////
Example to find out all IRRs

Time 	cashflow
0	504
1	-432
2	-432
3	-432
4	832

Since the direction of cash flows change twice, we might 
have two different IRRs.

  Step 1: generate a column of rates, e.g., from 0 to 100%

  Step 2: generate a column of NPV corresponding to this rates

  Step 3: find two location where NPV chance directions

  Step 3: choose two rates then the NPV change sign as 
          our guebeta, see below. 

   =IRR(values, [guebeta])

   http://canisius.edu/~yany/excel/mutipleIRRs.xlsx

////////////////////////////////
"

.C4EXPLAIN16<-"Profitability index and related rule
////////////////////////////////
                            PV(future cash flows)
  Profitability index =   ------------------------
                           Original cost

  Profitability index rule   > 1 accept
                             < 1 reject 

////////////////////////////////
"
.C4EXPLAIN17<-"Profitability Example
////////////////////////////////
0	-100
1	40
2	30
3	40
4	20
5	-10

R=0.02

 What is Profitability Index?

////////////////////////////////
"

.C4EXPLAIN18<-"Payback period and payback period rule
////////////////////////////////
Payback period is defined as number of year to recover our initial investment. 

  Here is one simple example. 
     If we invest $100 today, we would receive $30 at the end of each 
        year for the next 5 years. Where is the payback of the project?

      =10/30= 3.33 year

  Payback period rule: 
      if T(project) < T(critical value) accept
      if T(project) > T(critical value) reject

      where T(project) is the payback period of our project. 
            T(critical) value is the maximum number of year, your company
            demands to recover the initial investment. 

      Abetaume for the same time of investments, the company requires 3 
            years to recover its initial investment, then the above project
            should be rejected. 

////////////////////////////////
"
.C4EXPLAIN19<-"Youtube
///////////////////////////////////////////////
 Coram,2011, Calculate IRR using Excel
     (v545k,s4k,t1:24)
     https://www.youtube.com/watch?v=Ug74NbL81CE

 Mursau, Allen, 2012, Internal Rate Of Return (Using Excel IRR Function)
    (v10l,s10k,t5:16)
     https://www.youtube.com/watch?v=tabGWMpNxxk

///////////////////////////////////////////////
"

.C4EXPLAIN20<-"Links
///////////////////////////////////////////////
 Excel IRR fuction 
     https://corporatefinanceinstitute.com/resources/excel/functions/irr-function/

 Excel IRR function
     https://exceljet.net/excel-functions/excel-irr-function

 Excel MIRR function 
     https://support.office.com/en-us/article/MIRR-function-B020F038-7492-4FB4-93C1-35C345B53524

///////////////////////////////////////////////
"
.chapter5<-function(i){
" i  Chapter 5:Interest rate and yield curve 
  -  ---------------------------------- 
  1  2-step to convert returns          
  2  They are all equal 
  3  Fisher effect                        
  4  Term structure of interest rate    
  5  Limited liability 
  6  Bond definition and notations
  7  Zero-coupon bond 
  8  Bond price formula/estimate bond price using Excel 
  9  YTM (Yield to maturity)/YTM using Excel functions
 10  Bond price and interest rate is negatively correlated
 11  yield() vs. rate() 
 12  Concept of duration 
 13  Duration of a zero-coupon bond  
 14  Duration: two future cash flows
 15  Generate formula for duration
 16  Formula for bond's duration
 17  Credit rating and bond spread
 18  VBA .durationYan
 19  Youtubes 
 20  Links       

 Example #1:>.c5    # see the above list 
 Example #2:>.c5(1) # see the first explanation

";.chapter5_(i)}

.n5chapter<-20
 
.chapter5_<-function(i){
      .printEachQ(5,i,.n5chapter)
}

.c5<-.chapter5


.C5EXPLAIN21<-"Concept of YTM 
/////////////////////////////////////
YTM is Yield to maturity. 

  If we hold our bond until its maturity, the realized 
     return would be our YTM. 

  Here we abetaume there is no default. 


"

.C5EXPLAIN1<-" A 2-step approach to convert rate (return)
/////////////////////////////////////
Step 1: Which effective rate is given?
	There is no rationality behind this since it is quoted this way by financial institutions. 

	Example # 1:  The annual rate is 10%, compounded semi-annually. 
	       The effective semi-annual rate is given, and its value is 5%, i.e., =0.10/2.

	Example # 2:  The annual rate is 10%, compounded monthly. 
   	       It means that the effective monthly rate is 0.833%, i.e., 0.10/12.

Step 2: From one effective rate to another effective rate
	If the effective semi-annual rate is 5%, what is the equivalent effective quarterly rate?

        a) draw a time line of one year, with two frequencies. On top, 
           we have the given effective rate and its frequency. In this case,
            5% and 2 periods (Rsemi=5% and  n1=2). 
	           5%	                   5%
		
	|-----------------------|-----------------------|

	|-----------|-----------|-----------|-----------|
            R             R           R           R
	On bottom, we have the effective rate we want to 
                    estimate and frequency (R and n2=4). 

	b) Apply FV=1*(1+R)^n twice with different R and n. 
			FV1=1*(1+R1)^(n1)  =  (1+0.05)^2 
			FV2=1*(1+R2)^(n2)  =  (1+R)^4

	Set them equal, i.e., we have (1+0.05)^2 = (1+R)^4
           Solve the equation, i.e., we have R=(1+0.05)^(2/4)-1
         > (1+0.05)^(2/4)-1
              [1] 0.02469508

	The effective quarterly rate is 2.469508%. 
        APR (compounded quarterly) =  R(effective quarterly rate)*4

just type
        > .explain2stepApproach()

/////////////////////////////////////
"

.C5EXPLAIN2<-"They are all equal
-----------------------------------------
Abetaume that you go to a bank to withdraw $100. 
   The following amounts are all equal. 
     Denomination       Count
     ------------      ------
            100           1
             50           2
             20           5
             10          10
              5          20
              2          50
              1         100
APR is 10% and compounded semi-annually. 
   The following 11 interest rates are all equal, where 
   APR is Annual Percentage Rate, m is the compounding 
   frequency within one year and NA is Not Applicable. 
-------------------------------------------

  Interest rate quotation    explanation                         m
  -----------------------    -------------------                 ----
  APR is 10%,                compounded semi-annually	         2
  APR is 10.25%,             compounded annually                 1
  APR is 9.87803063838397%,  compounded quarterly	         4
  APR is 9.79781526228125%,  compounded monthly	                12
  APR is 9.75933732280154%,  compounded daily 	               365
	
  Effective annual rate is                0.1025	        NA
  Effective semi-annually rate is         0.05	                NA
  Effective quarterly rate is             0.0246950765959599	NA
  Effective monthly rate is               0.00816484605190104	NA
  Effective daily rate is                 0.000267379104734289	NA
  Continuously compounded rate is         0.0975803283388641	NA

/////////////////////////////////////
"

.C5EXPLAIN3<-"What is Fisher effect?
/////////////////////////////////////
The Fisher effect is an economic theory proposed by economist Irving Fisher that 
describes the relationship between inflation and both real and nominal interest rates. 
The Fisher effect states that the real interest rate equals the nominal interest rate 
minus the expected inflation rate.

  real rate = nominal rate - inflation rate
  Exact formula
                      (nominal rate +1)
     real rate +1 = ------------------------
                      (inflation rate +1) 

    http://www.investopedia.com/terms/f/fishereffect.asp
/////////////////////////////////////
"

.C5EXPLAIN4<-"Term structure of interest rate 
/////////////////////////////////////
 The relationship between time (year) and (risk-free) interest rate 

  http://finance.yahoo.com/bonds

/////////////////////////////////////
"
.C5EXPLAIN5<-"Limited liability 
/////////////////////////////////////

  The maximum lobeta to an investor is his/her initial 
       investment. 

  What is a double liability?
/////////////////////////////////////
"

.C5EXPLAIN6<-"Bond definition and notations
/////////////////////
What is a 'Bond'
   A bond is a debt investment in which an investor loans 
   money to an entity (typically corporate or governmental) 
   which borrows the funds for a defined period of time at 
   a variable or fixed interest rate. Bonds are used by 
   companies, municipalities, states and sovereign governments 
   to raise money and finance a variety of projects and activities. 
   Owners of bonds are debtholders, or creditors, of the ibetauer.

  http://www.investopedia.com/terms/b/bond.asp
bond's notations and cash flows
----------------------------
Notaton for a bond: 
    face value
    maturity
    coupon rate
    frequency of coupon payment per year

  Abetaume that face value is 100
  Bond would mature in 3 years
  Coupon rate is 4%
  coupon will be paid twice per year. 
          2        2       2        2         2       100+2

  |-------|--------|-------|--------|---------|--------|
          0.5year  1       1.5      2         2.5      3
/////////////////////
"

.C5EXPLAIN7<-"zero-coupon bond
///////////////////// 
What is a 'Zero-Coupon Bond'

   A zero-coupon bond, also known as an \"accrual bond,\" 
   is a debt security that doesn't pay interest (a coupon) 
   but is traded at a deep discount, rendering profit at 
   maturity when the bond is redeemed for its full face value.

   Some zero-coupon bonds are ibetaued as such, while others 
   are bonds that have been stripped of their coupons by a 
   financial institution and then repackaged as zero-coupon 
   bonds. Because they offer the entire payment at maturity,
   zero-coupon bonds tend to fluctuate in price much more than coupon bonds.
       http://www.investopedia.com/terms/z/zero-couponbond.asp

Cash flow for a zero-coupon bond
             0        0       0     0         FV
    |--------|--------|-------|     |---------|
             1        2                      n year
                                    FV
  price of a zero-coupon bond = ------------
                                   (1+R)^n
/////////////////////
"
.C5EXPLAIN8<-"bond price formula/Estimate bond price using Excel 
/////////////////////
  General formula  pv() = pv(all cash flows)

   Price of a bond = pv( all coupon payments) + pv(face value)

                     c              1            FV
   Price of bond = ---- *( 1 - ----------) + ----------
                     R           (1+R)^n       (1+R)^n

Estimate bond price using Excel 
-----------------------------
 The Excel function used is called pv()
   =pv(rate,nper,pmt,[fv],[type])
  where rate is the effective rate
        nper is the number of period
        pmt  is coupon amount
        fv   is the face value
        type =0 paid at the end of each period
             =1 paid at the beginning of each period
     
 Example #1: Face value is 1,000, coupon rate is 5%, paid every year. 
             The discount rate is 0.1 and bond would mature in 5 years. 
        =pv(0.1,5,0.05*1000,1000)  => ($810.46)

 Example #2: Face value is 100, coupon rate is 3.5%, paid twice per year. 
             APR is 4%, compounded semiannually and bond would mature in 10 years. 
        =pv(0.04/2,10*2,0.035*100/2,100)  => ($95.91)

/////////////////////////////
"

.C5EXPLAIN9<-"YTM (Yield to maturity)/Estimate YTM using Excel functions 
/////////////////////////////
What is 'Yield To Maturity (YTM)'

 Yield to maturity (YTM) is the total return anticipated on a 
     bond if the bond is held until the end of its lifetime. 
     Yield to maturity is considered a long-term bond yield, 
     but is exprebetaed as an annual rate. In other words, it is 
     the internal rate of return of an investment in a bond if 
     the investor holds the bond until maturity and if all payments 
     are made as scheduled.

         http://www.investopedia.com/terms/y/yieldtomaturity.asp

 Estimate YTM using Excel functions 
 ----------------------------
    There are several ways to estimate YTM
      1) use =rate()
      2) use =ytm()

/////////////////////////////
"

.C5EXPLAIN10<-"Bond price and interest rate is negatively correlated
///////////////////// 
  Price of bond is the summation of 

           present value of the 1t  coupon payment, 
           present value of the 2nd coupon payment, 
            ...
           present value of the last coupon payment, 
           present value of the face value 

 Let's look at the following general formula. 
                  c         c         c               c       FV
  price(bond) =  ---  +  ------- +  ----- +   ... + ---- + ----- 
                (1+R)    (1+R)^2     (1+R)^3       (1+R)^n  (1+R)^n

 Since R is in the position of denominator, a bigger R will decrease present value. 
   Thus, R and price of the bond  is negatively correlated. 
    R increases, P(bond) falls
    R decreases, P(bond) increases

///////////////////// 
"
.C5EXPLAIN11<-"Comparison between yield() and rate() functions
/////////////////////////////
-------  Given information   -------------------		
	n=	18	  D1
 Coupon rate=	0.043	  D2
	price=	870	  D3
Face value=	1000	  D4
		 	 	
Method I: using rate() function 				
	0.054517	=RATE(D2,D3*D5,-D4,D5)
				
Method II: using yield() function 				
Note: pay attention to those red cells			
		
	settlement	2/2/2011   <=  randomly choose one date
	maturity date	2/2/2029    =DATE(YEAR(D16)+D4,MONTH(D16),DAY(D16))
	coupon rate 	0.043	
	selling price 	87	 <= % of face value
	par value	100	 <= % of par value (face value), i.e., always 100
		
	0.054517	=YIELD(D9,D10,D11,D12,D13,1)

/////////////////////////////
"

.C5EXPLAIN12<-"concept of duration
/////////////////////////////
What is 'Duration'

   Duration is a measure of the sensitivity of the price -- 
     the value of principal -- of a fixed-income investment 
     to a change in interest rates. Duration is exprebetaed as 
     a number of years. Bond prices are said to have an 
     inverse relationship with interest rates. Therefore, 
     rising interest rates indicate bond prices are likely 
     to fall, while declining interest rates indicate bond prices are likely to rise.

   http://www.investopedia.com/terms/d/duration.asp

 A simple definition:
   Duration is a weighted time, i.e., when you recover your initial investment. 

/////////////////////////////
"
.C5EXPLAIN13<-"Duration for a zero-coupon bond 
/////////////////////////////
 A simple definition:
   Duration is a weighted time, i.e., when you recover your initial investment. 

  Since for a zero coupon bond we only have one future cash inflow 
      when bond matures, the duration of a zero-coupon bond equals its maturity. 

     D(zero coupon)= T

   where T is the maturity (in years)

/////////////////////////////
"

.C5EXPLAIN14<-"A simple example for duration: only 2 future cash flows 
/////////////////////////////
Case #1:  Let's start with just one cash flow. 

  We invested today and will receive just one 
     future cash flow of $100 at the end of year 2. 
     Question: when we could recover our initial investment?
                                      100
   |-----------------|----------------|

  Obviously, D=2, i.e., we could recover our 
             investment at the end of year 2. 

Case #2: We invested today and will receive two 
     future cash flows of $100 at the end of years 1 and 2. 
     Question: when we could recover our initial investment?
                    100              100
   |-----------------|----------------|
   The first guebeta is 1.5 year since we get 100 at year 1 
      and another 100 at year 2. Thus, the average is (1+2)/2=1.5

 However, this guebeta ignores the time value of money. 
  > v1=100/(1+0.1)    =>     [1] 90.90909
  > v2=100/(1+0.1)^2  =>     [1] 82.64463
  > w1=v1/(v1+v2)     =>     [1] 0.5238095
  > w1*1+(1-w1)*2  => [1] 1.47619
    D=1.476
  For formula for two future cash flows
     D= W1 *T1 + W2*T2   =w1*T1 + (1-W1)*T2

/////////////////////////////
"

.C5EXPLAIN15<-"Generate formula for duratio 
/////////////////////////////
 Abetaume that we have the following cash flows. 
          c1       c2     c3                           cn

  |-------|--------|-------|--------|   ...... |--------|

          T1       T2      T3                          Tn
   
   Duration = w1*T1 + w2*T2 + .... + wn*Tn
            pv(c1)
    w1=---------------------------
       pv(c1)+pv(c2) + ...+pv(cn)

/////////////////////////////
"
.C5EXPLAIN16<-"formula for bond's duration  
/////////////////////////////
  =duration(settlement,maturity,coupon,yld,frequency,[basis])

    settlement : settlement date of the security (i.e. the date that the coupon is purchased).
    maturity   : maturity date of the security (i.e. the date that the coupon expires).
    coupon     : security's annual coupon rate.
     yld       : security's annual yield.
   frequency   : number of coupon payments per year. This must be one of the following:
                  1  is for annually
                  2  is for semi-Annually
                  4  is for quarterly
   [basis]     : specifies the financial day count basis:
                  Basis           Day Count Basis
                   ---            ---------------
                 0 (default)      US (NASD) 30/360
                 1	          actual/actual
                 2                actual/360
                 3                actual/365
                 4                European 30/360

 Example 1: A1 to B2, we have the following four entries
                A                 B
             ---------           -----
             Settlement Date     12/31/2005
             Maturity Date       12/31/2035

            =DURATION(B1,B2,0.1,0.08,4)   => 11.21665878

 Example 2: Data Management Ltd has ibetaued bonds with 15 years to maturity, 
            an 5% coupon rate with a face value of $1000. If your required 
            rate of return is 8% per year and the coupon payment is 						
            paid twice per year, what is the duration of the bond?

       choose any cell, e.g., D22, and type 
           =today()
        in D23
              =DATE(YEAR(D22)+15,MONTH(D22),DAY(D22))
       =duration(d22,d23,0.05,0.08,2)  => 9.929799749

/////////////////////////////
"

.C5EXPLAIN17<-"Credit rating and bond spread
/////////////////////
1) Spread based on credit rating
   .showCreditSpread(100)
          year1 year2 year3 year5 year7 year10 year30
Aaa/AAA       5     8    12    18    28     42     65
Aa1/AA+      10    18    25    34    42     54     77
Aa2/AA       14    29    38    50    57     65     89
Aa3/AA-      19    34    43    54    61     69     92
A1/A+        23    39    47    58    65     72     95
A2/A         24    39    49    61    69     77    103
A3/A-        32    49    59    72    80     89    117
Baa1/BBB+    38    61    75    92   103    115    151
Baa2/BBB     47    75    89   107   119    132    170
Baa3/BBB-    83   108   122   140   152    165    204
Ba1/BB+     157   182   198   217   232    248    286
Ba2/BB      231   256   274   295   312    330    367
Ba3/BB-     305   330   350   372   392    413    449
B1/B+       378   404   426   450   472    495    530
B2/B        452   478   502   527   552    578    612
B3/B-       526   552   578   604   632    660    693
Caa/CCC+    600   626   653   682   712    743    775
> 

2) Spread time series for BBB (credit rating)
    BofA Merrill Lynch US Corporate BBB Option-Adjusted Spread (BAMLC0A4CBBB)
        https://fred.stlouisfed.org/series/BAMLC0A4CBBB

/////////////////////////////
"

.C5EXPLAIN18<-"VBA 4 durationYan
///////////////////////////////////

Function durationYan(YTM As Double, CouponRate As Double, Frequency As Double, maturityYears As Double) As Variant
Dim i As Integer, rate As Double,coupon As Double, pv As Double, D As Double, bondPrice As Double
bondPrice = 0
D = 0
coupon = 1000*CouponRate / Frequency
rate = YTM / Frequency
For i = 1 To (Frequency * maturityYears)
           pv = coupon / (1 + rate) ^ i
           D = D + pv * 1 / Frequency * i
           bondPrice = bondPrice + pv
Next i
pv = 1000/(1 + rate) ^ (i - 1)
D = D + pv * 1 / Frequency * (i - 1)
bondPrice = bondPrice + pv
durationYan = D / bondPrice
End Function

Function durationYanHelp() As String
  durationYanHelp = \"usage: durationYan(YTM,CouponRate,Freq,maturityYears)\"
End Function

/////////////////////
"

.C5EXPLAIN19<-"Youtubes 
/////////////////////////////////////
   Edspira, 2015, Macaulay Duration 
     (v97k,s105k,t7:49)
     https://www.youtube.com/watch?v=F7XnR7sKWiE

   Killik & Co, 2014, Killik Explains: Duration - The word every bond investor should understand
      (v42k,s11k,t10:16)
      https://www.youtube.com/watch?v=TehOzsoBmXQ
    
   MithrilMoney,2013,Calculating Duration, Lecture 021, Securities Investment 101, Video 00024
    (v22k,s6k,t12:00)
      https://www.youtube.com/watch?v=hyxXFhyZriw
      
/////////////////////////////////////
"
.C5EXPLAIN20<-"Links 
/////////////////////////////////////
interest rate
-------------
   wikipedia
      https://en.wikipedia.org/wiki/Interest_rate
   What is interest rate?
      http://www.businebetadictionary.com/definition/interest-rate.html
   investpedia
      http://www.investopedia.com/terms/i/interestrate.asp
   mortegate today
      https://www.wellsfargo.com/mortgage/rates/
   Term Structure Of Interest Rates
      http://www.investopedia.com/terms/t/termstructure.asp
   The Term Structure of Interest Rates
      http://www.investopedia.com/exam-guide/cfa-level-1/fixed-income-investments/interest-rate-term-
          structure.asp
   The Term Structure of Interest Rates, Spot Rates,and Yield to Maturity
       http://finance.wharton.upenn.edu/~acmack/Chapter_05_app.pdf
   Yield curve
       https://en.wikipedia.org/wiki/Yield_curve
bond evaluation 
---------------
   Interest Rates And Your Bond Investments
       http://www.investopedia.com/articles/03/122203.asp
   Bond valuation 
       https://en.wikipedia.org/wiki/Bond_valuation
   Bond Valuation   
       http://www.investopedia.com/terms/b/bond-valuation.asp
   Bond calculator
       http://www.calculator.com/calcs/bondcalc.html

/////////////////////
"

.c7<-" Not available right now."
.chapter6<-function(i){
" i  Chapter 6: Uncertainty, default and risk  
  -  -------------------------------------
  1  Random variable/Excel rand() function 
  2  Expected value and a fair game 
  3  Expected value for a given set of probabilities
  4  Estimating variance/std when probability is given  
  5  VBA 4 meanGivenProb
  6  VBA 4 varGivenProb
  7  Risk neutral and Risk aversion 
  8  Risk-free rate 
  9  Default risk 
 10  Spread between YTM and a risk-free rate 
 11  Default premium, time premium, 
 12  Risk premium and imperfect market premiums
 13  Credit rating and default rates 
 14  Bond contract option features 
 15  Credit Default Swaps
 16  PV with outcome-contingent payoff table 
 17  Expected return vs. promised return 
 18  Debt vs. equity 
 19  Youtube and data 
 20  Links

 Example #1:>.c6    # see the above list 
 Example #2:>.c6(1) # see the first explanation

";.chapter6_(i)}

.n6chapter<-20

.chapter6_<-function(i){
      .printEachQ(6,i,.n6chapter)
}
.c6<-.chapter6

.C6EXPLAIN1<-"Random variable/Excel rand() function  
/////////////////////////////////////

 A random variable is  a number whose realization is 
     not yet known. 

 For Excel, we use =rand()

/////////////////////////////////////
"
.C6EXPLAIN2<-"Expected value and a fair game 
/////////////////////////////////////
What is an expected value?
-----------------------------
 The expected value is the average outcome if the random draw 
          is repeated infinitely often. 
 It need not be a pobetaible realization. 

A fair game
-----------
   the expected value is zero, i.e., breakeven. 

   For example, tobeta a game with 50% head and 50% tail. 
       If we bet $1, the payoff for a gain should $1 as well,
       shown below. 

      E(value) = 0.5*(-1) + 0.5*1=0
                 porb(we lose()* lost Bet + prob(win) * reward

  Abetaume that the coin has 60% head an 40% tail. 
     For a fair game, what is the payoff if we bet for a tail?
     Abetaume that we bet $1 as well. 

      E(value) = 0.6 *(-1) + 0.4 * x=0
               x=0.6/0.4  =1.5

/////////////////////////////////////
"

.C6EXPLAIN3<-"Expected value when probability is given  
/////////////////////////////////////

Abetaume that we have n pair of probabilities and values 

      p1, V1
      p2, V2
      .....
      .....
      pn, Vn

  Expected value will be

     E(value) = p1*V1 + p2*V2 + .... + pn*Vn

/////////////////////////////////////
"

.C6EXPLAIN4<-"Estimating variance/std when probability is given  
/////////////////////////////////////
Abetaume that we have n pair of probabilities and return 
   p1, R1, p2, R2, ..... (pn, Rn)

 Step 1: estimate expected return or mean
         Rmean=p1*R1 + p2*R2 + .... + pn*Rn

 Step 2:  calculate the first deviation 
            R1-Rmean
 Step 3: square it
            (R1-Rmean)^2
 Step 4: times its probability
           p1*(R1-Rmean)^2
 Step 5: repeat Steps 2 to 4 up to the last pair
 Step 6: summation will be variance
       var=p1(R1-mean)^2 + p2(R2-mean)^2 + ... + (Rn-mean)^2
       std=sqrt(var)

/////////////////////////////////////
"

.C6EXPLAIN5<-"VBA 4 meanGivenProb
///////////////////////////////////////////

Function meanGivenProb(prob As Range, returns As Range) As Variant
  'by yany@canisius.edu 8/31/2017, modified 11/1/2019
  Dim n, m, k, i As Integer, mean As Double
  n = returns.Rows.Count
  m = returns.Columns.Count
  k = Application.Max(m, n)
  mean = 0
  For i = 1 To k
        mean = mean + prob(i) * returns(i)
  Next
  meanGivenProb = mean
End Function

Function meanGivenProbHelp() As String
   meanGivenProbHelp= \"usage: =meanGivenProb(prob_vector,return_vector)\"
End Function

///////////////////////////////////////////
"

.C6EXPLAIN6<-"VBA 4 varGivenProb
////////////////////////////////

Function varGivenProb(prob As Range, returns As Range) As Variant
    'by yany@canisius.edu 8/31/2017, modified 11/1/2019 
     Dim n, m, k, i As Integer, mean, final As Double
     n = returns.Rows.Count
     m = returns.Columns.Count
     k = Application.Max(m, n)
     mean = 0
     For i = 1 To k
         mean = mean + prob(i) * returns(i)
     Next
     final = 0
     For i = 1 To k
         final = final + prob(i) * (returns(i) - mean) ^ 2
     Next
     varGivenProb = final
End Function

Function varGivenProbHelp() As String
      varGivenProbHelp= \"usage: =varGivenProb(prob_vector,return_vector)\"
End Function

///////////////////////////////////////////
"

.C6EXPLAIN7<-"Risk neutral 
/////////////////////////////////////
 What is Risk Neutral?
   Risk neutral is a concept used in both game theory 
   studies and in finance. It refers to a mindset where 
   an individual is indifferent to risk when making an 
   investment decision. 

   This mindset is not derived from  calculation or 
   rational deduction, but rather from an emotional 
   preference. A person with a risk-neutral approach 
   simply doesn't focus on the risk--regardlebeta of whether
   or not that is an ill-advised thing to do. This mindset 
   is often situational and can be dependent on price or other external factors.

  Source: https://www.investopedia.com/terms/r/riskneutral.asp

  Risk-neutral: care about the expected value 
  In other words: if a person is risk-neutral, 
     he/she would not consider risk.

/////////////////////////////////////
"

.C6EXPLAIN7<-"Risk aversion 
/////////////////////////////////////

  Risk aversion means that you would prefer the safe project. 

  Put differently, you would demand an extra reward to take 
      the riskier project instead. 

/////////////////////////////////////
"

.C6EXPLAIN8<-"risk-free rate 
/////////////////////////////////////
The risk-free rate of return is the theoretical rate of return 
   of an investment with zero risk. The risk-free rate represents 
   the interest an investor would expect from an absolutely 
   risk-free investment over a specified period of time.

In theory, the risk-free rate is the minimum return an investor 
   expects for any investment because he will not accept additional 
   risk unlebeta the potential rate of return is greater than the 
   risk-free rate.

In practice, however, the risk-free rate does not exist because even 
   the safest investments carry a very small amount of risk. Thus, 
   the interest rate on a three-month U.S. Treasury bill is often 
   used as the risk-free rate for U.S.-based investors.

    http://www.investopedia.com/terms/r/risk-freerate.asp

/////////////////////////////////////
"


.C6EXPLAIN9<-"Default premium 
/////////////////////////////////////
 Default premium: the difference between the promised rate 
  
  and the expected rate that you, the lender, would have to demand 
 
  just to berak even. 

/////////////////////////////////////
"

.C6EXPLAIN10<-"Spread beteen YTM and a riks-free rate 
/////////////////////////////////////

 For the same maurity, such as 10 year, the difference between 
 
     YTM offered by a company and the risk-free rate is the
  
     default risk premium. 

/////////////////////////////////////
"

.C6EXPLAIN11<-"Default premium, time premium, 
/////////////////////////////////////

  Default premium is the compensation for bearing default risk. 

  Time premium is the Time value of Money 

/////////////////////////////////////
"

.C6EXPLAIN12<-"Risk premium and imperfect market premiums
/////////////////////////////////////
  Risk premium is for bearing extra risk. 

  Imperfect market premiums: such as small-size premium etc. 

/////////////////////////////////////
"

.C6EXPLAIN13<-"Credit rating and default rates 
/////////////////////////////////////

 A better credit rating is abetaociated with a lower default risk. 

 This will lead to a lower spread. 

 In other words, the quality of credit is negatively 
    correlated with spread 

/////////////////////////////////////
"

.C6EXPLAIN14<-"Bond contract option features 
/////////////////////////////////////

  A bond might have a feature that the bond could be 'called', 
      i.e., retired early before it matures. Since this 
      feature will benefit the bond ibetauers, the YTM will be 
      higher, i.e., to compensate a bond buyer. 

  A bond might have a feature that the bond could be 
      converted to equity, i.e., a bond owner becomes 
      an equity owner. Since this feature will benefit 
      the bond buyers, the YTM will be 
      lower, i.e., cheaper for the ibetauer companies. 

/////////////////////////////////////
"

.C6EXPLAIN15<-"Credit Default Swaps
/////////////////////////////////////
What is a Credit Default Swap (CDS)?
    A credit default swap (CDS) is a financial derivative or contract
    that allows an investor to \"swap\" or offset his or her credit risk 
    with that of another investor. For example, if a lender is worried 
    that a borrower is going to default on a loan, the lender could use 
    a CDS to offset or swap that risk. To swap the risk of default, the 
    lender buys a CDS from another investor who agrees to reimburse the 
    lender in the case the borrower defaults. Most CDS will require an 
    ongoing premium payment to maintain the contract, which is like an
    insurance policy.

   Source: https://www.investopedia.com/terms/c/creditdefaultswap.asp

/////////////////////////////////////
"

.C6EXPLAIN16<-"PV with outcome-contingent payoff table 
/////////////////////////////////////
To estimate a present value, we need to replace
     1) the known value with the expected value 
     2) the known future rate of return with an expected rate of return 

Two methods
     Method I:  pv = discounted the expected value
     Method II: pv = expected present value of each scenario 

For Method I, we apply probability to estimate the expected future 
              value, then discount it. 

For Method II, we calculate present value for each case, 
               then apply probability to them. 

/////////////////////////////////////
"

.C6EXPLAIN17<-"Expected return vs. promised return 
/////////////////////////////////////
  Usually, bond ibetauers or borrowers offer a 
     promised return which might be quite different 
     from an expected return. 

   Event       prob     FV
   ----       ------    ----
   Rain        1/4       60
   Sunshine    3/4       100

  Abetaume that the appropriate expected return is 20%. 

  The promised return is 20%. 

                        1/4*60 + 3/4*100      90
  The expected value= -----------------   = ------  =75
                         (1+0.2)              1.2
              
/////////////////////////////////////
"

.C6EXPLAIN18<-"Debt vs. equity 
/////////////////////////////////////

  For a debt (bond) holder, he/she 
    1) does not own the company. 
    2) get paid first before the equity holder

  For a equity holder, he/she 
    1) owns a part of the company. 
    2) get paid after the bond holders get paid
  
/////////////////////////////////////
"
"
    https://fred.stlouisfed.org/series/UNRATE
"
.C6EXPLAIN19<-"Youtube and data 
/////////////////////////////////////
 Moy,Ronald, 2013, Utility and Risk Preferences Part 1 - Utility Function
   (v186k,s10k,t8:54)
   https://www.youtube.com/watch?v=tCreeXzCNRc

 Businebeta Tutorials, 2015,What is Risk Aversion 
   (v9k,s19k,t1:35)
   https://www.youtube.com/watch?v=xlrmxoOwIU4

 Moy, Ronald, 2013, Risk Aversion 
   (v45k,s10k,t10:28)
   https://www.youtube.com/watch?v=1kU4pvdIdT4

data:
     .showAaaYieldMonthly()
            DATE    YIELD
       1 1919-01-01 0.000535
       2 1919-02-01 0.000535

    .showBaaYieldMonthly()
  
   FRED, Moody's Seasoned Aaa Corporate Bond Yield (AAA)
      https://fred.stlouisfed.org/series/AAA
   FRED, Moody's Seasoned Aaa Corporate Bond Yield (BAA)
      https://fred.stlouisfed.org/series/BAA
/////////////////////////////////////
"

.C6EXPLAIN20<-"Links 
/////////////////////////////////////
 FRED, Moody's Seasoned Aaa Corporate Bond Yield (AAA)
      https://fred.stlouisfed.org/series/AAA

 FRED, Moody's Seasoned Aaa Corporate Bond Yield (BAA)
      https://fred.stlouisfed.org/series/BAA

 InvestorPedia, Definitions of risk (mathematical)
     https://www.investopedia.com/ask/answers/021915/how-standard-deviation-used-determine-risk.asp

 InvestorPdeia, Risk Neutral
     https://www.investopedia.com/terms/r/riskneutral.asp

 InvesorPedia, What is a Credit Default Swap (CDS)?
      https://www.investopedia.com/terms/c/creditdefaultswap.asp

 Wikipedia, Risk aversion 
      https://en.wikipedia.org/wiki/Risk_aversion

/////////////////////////////////////
"
.chapter7<-function(i){
" i  Chapter 7: A First Look at Investments  
  -  -------------------------------------
  1  Market capitalization 
  2  Historical values: stock, bond and cash 
  3  Arithmetic vs. geometric mean 
  4  Arithmetic vs. geometric mean for returns
  5  VBA 4 geometric mean 
  6  S&P500 and its constituents 
  7  What is a normal distribution 
  8  Formulae for a normal distribution 
  9  Properties of a normal distribution  
 10  Normality test 
 11  Do IBM's monthly returns follow a normal distribution?
 12  Rule of Thumb between (arithmetic and geometric means)
 13  Co-movement: covariance and correlation 
 14  Mathematic definition of covariance
 15  Mathematic definition of correlation 
 16  Causality/Grange Causality test
 17  Market risk: beta
 18  Mathematic definition of beta   
 19  Youtube 
 20  Links 
 
 Example #1:>.c7    # find out the above list 
 Example #2:>.c7(1) # find the 1st explanation

";.chapter7_(i)}

.n7chapter<-20

.chapter7_<-function(i){
    .printEachQ(7,i,.n7chapter)
}

.c7<-.chapter7

.C7EXPLAIN1<-"Market capitalization 
///////////////////////////////

  Market capitalization = number of shares * price

///////////////////////////////
"
.C7EXPLAIN2<-"Historical values: stock, bond and cash 
///////////////////////////////

  Cash: very liquid short-term securities
 
  bonds: debt

  equity: residual return claimers 

///////////////////////////////
"

.C7EXPLAIN3<-"Arithmetic vs. geometric means 
///////////////////////////////
Abetaume that we have three numbers: a, b, c

                          a + b + c
     Arithmetic mean = ---------------
                              3

     Geometric mean = (a * b * c) ^ (1/3)

For n values of x1, x2, ..., xn

                         x1 + x2 + ... + xn
     Arithmetic mean  = ---------------
                               n
   
     Geometric mean = (x1 *x2 *... *xn) ^ (1/n)

///////////////////////////////
"

.C7EXPLAIN4<-"Arithmetic vs. geometric means for returns
///////////////////////////////
Abetaume that we have three returns: R1,R2,R3

                         R1 + R2 + R3
     Arithmetic mean = ---------------
                              3

     Geometric mean = [(R1+1)*(R2+1)*(R3+1)] ^ (1/3) -1

For n returns of R1, R2, ..., Rn

                         R1 + R2 + ... + Rn
     Arithmetic mean  = ---------------
                               n
   
     Geometric mean = (R1 *R2 *... *Rn) ^ (1/n)

///////////////////////////////
"

.C7EXPLAIN5<-"VBA for geometric mean 
///////////////////////////////
Function GEOMEANyan(x As Range) As Variant
' author yuxing.yan at canisius dot edu 
' date : 2/4/2013
     Dim i, n, n2 As Integer, product As String
     product = x(1, 1) + 1
     i = 2
     n = x.Rows.Count
     n2 = x.Columns.Count
     If n > 1 Then
          Do While i <= n
              product = product * (x(i, 1) + 1)
              i = i + 1
          Loop
          product = (product) ^ (1 / n)
      Else
         Do While i <= n2
             product = product * (x(1, i) + 1)
              i = i + 1
          Loop
          product = (product) ^ (1 / n2)
      End If
     GEOMEANyan = product - 1
     'GEOMEANyan = n2
End Function

Function geomeanYanHelp() As String
  geomeanYanHelp= \"usage: =GEOMEANyan(range)\"
End Function

///////////////////////////////
"

.C7EXPLAIN6<-"S&P500 and its constituents 
///////////////////////////////
   S&P500 is for 500 largest stocks satisfying certain requirements. 

   Standard  & Poor's started it in 1923. 

///////////////////////////////
"

.C7EXPLAIN7<-"Normal Probability Distribution
/////////////////////////////////////
  The normal probability distribution is the most 
     important distribution for describing a continuous random variable.

  It is widely used in statistical inference.

  It has been used in a wide variety of applications including:
     * Heights of people
     * Amounts of rainfall
     * Test scores
     * Scientific measurements

  Abraham de Moivre, a French mathematician, published 
       The Doctrine of Chances in 1733.

  He derived the normal distribution

/////////////////////////////////////
"

.C7EXPLAIN8<-"Normal Probability Density Function
/////////////////////////////////////
  The density of a normal distribution 
               1                  1    x-mu
    f(x) =   ----------- * e ^ [- - *(------)^2 ]
             sqrt(2*pi)           2   sigma
     where:
           mu   = mean
           sigma= standard deviation
           pi   = 3.14159
           e    = 2.71828

  The density of a normal distribution 
               1                  1    x-mu
    f(x) =   ----------- * e ^ [- - *(------)^2 ]
             sqrt(2*pi)           2   sigma
     where:
           mu   = mean
           sigma= standard deviation
           pi   = 3.14159
           e    = 2.71828
/////////////////////////////////////
"

.C7EXPLAIN9<-"Normal distribution's characteristics
/////////////////////////////////////
Normal distribution: characteristics
-------------------------
   1) The distribution is symmetric
   2) its skewnebeta measure is zero
   3)  The entire family of normal probability distributions is defined 
       by its mean (mu) and its standard deviation s.
   4) The highest point on the normal curve is at the 
      mean, which is also the median and mode

     The mean can be any numerical value: negative, zero, or positive.
     The standard deviation determines the width of the
         curve: larger values result in wider, flatter curves.
     Probabilities for the normal random variable are given 
         by areas under the curve. The total area under the 
         curve is 1 (.5 to the left of the mean and .5 to the right).

/////////////////////////////////////
"

.C7EXPLAIN10<-"Normality test 
/////////////////////////////////////
Normality test: sum of the squared percentage 
                deviation follow a chisq distribution 

    Null Hypothesis H0: values following a normal distribution 

    Decision rule: if sum > chisq critical vale reject 
                   if sum < chisq critical vale accept

        chisq critical value = chisqinv(prob,df)
           prob is usually 5% or 1%
           df   is the degree of freedom, m-1
                m is the number of values for the bin column 

 Step 1: generate a set of random numbers from 
         a standard normal distribution 

 Step 2: generate a bin (column)
         -3, -2.75, ...., 2.73, 3

 Step 3: click 'Data' --> 'Data Analysis' -> histogram
         Click 'cumulative'

 Step 4: estimate true cumulative from a standard normal distribution
         =norm.s.dist(x,TRUE)

 Step 5: estimate squared percentage deviation
           =((a-b)/b)^2   
         where a is our cumulative distribution             
               b is from our target distribution (i.e., standrd normal distribution)

 Step 6: estimate sum of above
 Step 7: compare with chisq critical value
          =chisq.inv(0.05,df)
/////////////////////////////////////
"

.C7EXPLAIN11<-"Do IBM monthly returns follow a normal distribution? 
/////////////////////////////////////
 Step 1: Download IBM's monthly data
         estimate its mean and std 

 Step 2: standardize by applying the following formula
                Ri - mean
         xi = ------------- 
                  std
 Step 3: generate a bin (column)
         -3, -2.75, ...., 2.73, 3

 Step 4: click 'Data' --> 'Data Analysis' -> histogram
         Click 'cumulative'

 Step 5: estimate true cumulative from a standard normal distribution
         =norm.s.dist(x,TRUE)

 Step 6: eatimte squared percentage deviation
           =((a-b)/b)^2   
         where a is our cumulative distribution             
               b is from our target distribution (i.e., standard normal distribution)

 Step 7: estimate sum of above
 Step 8: compare with chisq critical value
          =chisq.inv(0.05,df)

/////////////////////////////////////
"

.C7EXPLAIN12<-"Rule of Thumb between (arithmetic and geometric means)
///////////////////////////////
  Rule of Thumb: If returns are approximately normal distributed, 
  
      then the arithmetic mean is higher than the geometric mean 
 
      by about half of the variance. 

///////////////////////////////
"

.C7EXPLAIN13<-"
///////////////////////////////

///////////////////////////////
"

.C7EXPLAIN14<-"Formulae for estimating covariance/correlation 
/////////////////////////////////////
Abetaume that we have n returns: R1, R2, ..., Rn
  We estimate their mean:
            R1 + R2 + ... + Rn
     Rm=  ----------------------              (1)
                  n

  Recall the formula to estimate variance
               (R1-Rm)^2 + ... + (Rn-Rm)^2    
   variance =   ------------------------       (2)
                         n-1

First, we have two sets of returns for two stocks
  For stock A:  R(A,1), R(A,2), ..., R(A,n)
  For stock B:  R(B,1), R(B,2), ..., R(B,n)

 same as before, we estimate means for both stocks
       Rm(A) and Rm(B)
  For covariance, we have the following formula

                   [R(A,1)-Rm(A)]*[R(B,1)-Rm(B)] + .... 
   covariance(A,B) = ------------------------------------
                             n-1
/////////////////////////////////////
"
.C7EXPLAIN15<-"Estimating correlation 
/////////////////////////////////////
In terms of diversification effect, correlation is a better 
   measure than covariance

 Formula for estimating correlation

                  cov(A,B)
    corr(A,B)=  -----------------
                  stdA * stdB
   where 

      corr(A,B) is the correlation between stocks A and B
      cov(A,B)  is the covariance between stocks A and B
      stdA      is the standard deviation of stock A
      stdB      is the standard deviation of stock B

 Why correlation is better?

 The reason is that correlation has a range of [-1, 1]

  When two stocks always move in the same direction, 
      their correlation is 1. This is called 
      \"perfectly positively correlated\".

  When two stocks always move in the opposite direction, 
      their correlation is 1. This is called 
      \"perfectly negatively correlated\".

/////////////////////////////////////
"


.C7EXPLAIN16<-"Order of data sets (in terms of date)
///////////////////////////////
Abetaume that we want to run Fama-French 3 factor model for IBM. 

 Step 1: download IBM's monthly price data from Yahoo!Finance

 STep 2: estimate IBM's monthly returns

 Step 3: download Fama-French 3 factors

 Step 4: merge those two data sets

 Step 5: run a linear regrebetaion 


 Note that for step 4, we have to pay attention to 
      how the data sets are sorted. 

 The data downloaded from Yahoo!Finance is sorted from the latest to oldest, see below. 
Date Open High Low Close Volume Adj Close
2017-01-03 167.00 169.919998 165.339996 166.809998 3933100 166.809998
2016-12-01 161.949997 169.949997 158.300003 165.990005 3395000 165.990005
2016-11-01 153.50 164.660004 151.00 162.220001 3822800 162.220001
2016-10-03 158.059998 158.529999 147.789993 153.690002 3899000 152.308258
2016-09-01 158.320007 165.00 153.210007 158.850006 3501600 157.421875
2016-08-01 160.649994 164.949997 157.850006 158.880005 3131700 157.451599
2016-07-01 151.779999 163.600006 149.919998 160.619995 3648600 157.812973
2016-06-01 153.00 155.479996 142.50 151.779999 3678500 149.127457
2016-05-02 146.559998 153.809998 142.899994 153.740005 3857300 151.053207


 while the data from Prof. French's data library is sorted the other way around, 
    i.e., from the oldest to newest, see below. 

   > .showff3Monthly()
           DATE MKT_RF    SMB     HML     RF
   1 1926-07-01 0.0296 -0.023 -0.0287 0.0022
   2 1926-08-01 0.0264 -0.014  0.0419 0.0025

   > .showff3Monthly(-2)
              DATE MKT_RF     SMB     HML    RF
   1090 2017-04-01 0.0109  0.0055 -0.0216 5e-04
   1091 2017-05-01 0.0105 -0.0255 -0.0371 6e-04

///////////////////////////////
"

.C7EXPLAIN17<-"What is beta?
///////////////////////////////

Beta of a stock is a measure of its market risk. 

Beta is a slope of a CAPM model 

  Total risk = market risk + firm's specific risk

///////////////////////////////
"


.C7EXPLAIN18<-"CAPM is a single-facto linear model
///////////////////////////////
The formula of CAPM is given below. 

  R(i,t) =  Rf(t) + beta(i) *[Rmkt(t) - Rf(t)]       (1)

         R(i,t) is the stock retun for i at t
 
         Rf(t)  is the risk-free rate at time t

         beta(i) is the beta for stock i

         Rmkt (t) is the return for stock market at time t

/////////////////////
"

.C7EXPLAIN19<-"Youtube 
///////////////////////////////

 MoneyWeek, 2012, What is beta?
    (v185k,s196k,t11:46)
    https://www.youtube.com/watch?v=etlv7qTQUSY

 Sasha Evdakov: Tradersfly, 2016, What is \"Beta\" [Stock Market Terms] + How to Use it for Trading Decisions
    (v48,s126k,t7:26)
    https://www.youtube.com/watch?v=jvk-Lkwd6S4

 Lambert, Ben, 2013, Covariance and correlation
    (v315k,s0,t5:55)
    https://www.youtube.com/watch?v=KDw3hC2YNFc
  
  Khan Academy, 2010, Covariance and the regrebetaion line
    (v327,s4.9m,t17:07)
    https://www.youtube.com/watch?v=ualmyZiPs9w

///////////////////////////////
"

.C7EXPLAIN20<-"Reference and links 
///////////////////////////////

 Wikipedia, List of S&P 500 companies
    https://en.wikipedia.org/wiki/List_of_S%26P_500_companies

 Yahoo!Finance,TOP 500 US STOCKS
    https://markets.businebetainsider.com/index/components/s&p_500/d

///////////////////////////////
"

.chapter8<-function(i){
" i  Chapter 8: Investor Choice: Risk and Return 
  -  -------------------------------------
  1  What is risk (a common sense definition)
  2  mathematical definition of risk
  3  formula 4 variance/standard deviation with probability
  4  Data set 
  5  VBA 4 meanGivenProb, VBA 4 varGivenProb
  6  formula 4 variance/standard deviation with historical returns 
  7  total risk vs. market risk 
  8  log function vs. exponential functions
  9  definition of returns
 10  continuously compounded returns (interest rate) 
 11  Rc to an effective rate or APR (annual percentage rates)
 12  Excel functions for natural log and log with other bases   
 13  Beta of a portfolio 
 14  Beta of a firm
 15  Average of beta of all stocks 
 16  Time-weighed vs. dollar-weighted
 17  Excel functions: var, stdev,covar,correl and slope
 18  risk-free rate 
 19  Youtubes
 20  Links

 Example #1:>.c8    # see the above list 
 Example #2:>.c8(1) # see the first explanation

";.chapter8_(i)}


.n8chapter<-20

.chapter8_<-function(i){
      .printEachQ(8,i,.n8chapter)
}
.c8<-.chapter8

.C8EXPLAIN1<-"What is risk (a common sense definition)
/////////////////////////////////////
  Risk could be defined by the following sentences. 

  1) now sure about future returns 

  2) we might have a different outcome

  3) the unexpected result might happen

  4) we might lose our initial investment 

  5) the bad thing could happen 

  6) we might win or lose 

  7) the worse-case scenery might happen 

  8) the firm might go to bankruptcy 

  9) the dispersion of the results is very high

  10) the future could not predicted 

 One word: uncertainty 

/////////////////////////////////////
"


.C8EXPLAIN2<-"mathematical definitions of risk
/////////////////////////////////////
For total risk, we use variance and standard deviation of stock 
   returns to represent risk. 

For a given set of returns, we have the following formulae 
    to estimate variance and standard deviation. 

 Abetaume that our a set of n returns: R1, R2, ... Rn
                     R1+ R2 + ... + Rn
    Step 1: mean= ------------------------
                            n

             (R1-mean)^2 + (R2-mean)^2 + ... + (Rn-mean)^2
    var = -------------------------------------------
                                  n-1
    std = sqrt(var)

  Note 1: usually, when the IBM's volatility is 0.2 means that its 
          annualized standard deviation of returns is 0.2.

  Note 2: we have the following formulae to convert variances 
          and standard deviations based on daily or monthly returns. 

   var(annual) = 252 * var(daily)
   var(annual) = 12  * var(monthly)

   std(annual) = sqrt(252) * std(daily)
   var(annual) = sqrt(12 ) * std(monthly)

/////////////////////////////////////
"

.C8EXPLAIN3<-"formula for variance and standard deviation when probability is given  
/////////////////////////////////////
Abetaume that we have n pair of probabilities and return 
   p1, R1, p2, R2, ..... (pn, Rn)

 Step 1: estimate expected return or mean

       Rmean=p1*R1 + p2*R2 + .... + pn*Rn

 Step 2:  calculate the first deviation 
            R1-Rmean

 Step 3: squore it
            (R1-Rmean)^2

 Step 4: times its probability

           p1*(R1-Rmean)^2

 Step 5: repeat STeps 2 to 4 up to the last pair

 Step 6: summation will be variance

       var=p1(R1-mean)^2 + p2(R2-mean)^2 + ... + (Rn-mean)^2

       std=sqrt(var)

/////////////////////////////////////
"

.C8EXPLAIN4<-"Data set 
///////////////////////////////////////////

M,-0.03,0.03,0.05,0.11
A,0.03,0.11,-0.03,0.05
B,0.05,-0.01,0.07,0.13
C,0.17,0.03,0.11,-0.07
F,0.01,0.01,0.01,0.01

/////////////////////////////////////
"
.C8EXPLAIN5<-"VBA 4 meanGivenProb
///////////////////////////////////////////
Function meanGivenProb(prob As Range, returns As Range) As Variant
'by yany@canisius.edu 8/31/2017
Dim n As Integer
Dim i As Integer
Dim mean As Double
n = returns.Rows.Count
mean = 0
For i = 1 To n
      mean = mean + prob(i) * returns(i)
Next
meanGivenProb = mean
End Function


Function varGivenProb(prob As Range, returns As Range) As Variant
'by yany@canisius.edu 8/31/2017
Dim n As Integer
Dim i As Integer
Dim mean As Double
Dim final As Double
n = returns.Rows.Count
mean = 0
For i = 1 To n
      mean = mean + prob(i) * returns(i)
Next
final = 0
For i = 1 To n
      final = final + prob(i) * (returns(i) - mean) ^ 2
Next
varGivenProb = final
End Function

///////////////////////////////////////////
"

#  4  formula for variance and standard deviation  when historical returns are given  

.C8EXPLAIN6<-"sample vs. population: stdev() stdev.p() and stdev.s()
/////////////////////////////////////
  To estimate standard deviation for n observations, we have two formulae:

   1) for a sample:

               (x1-mean)^2 + (x2-mean)^2 + ... + (xn-mean)^2
         var = -------------------------------------------
                                  n-1
         std=sqrt(var)

    2) for population:

               (x1-mean)^2 + (x2-mean)^2 + ... + (xn-mean)^2
         var = -------------------------------------------
                                   n
         std=sqrt(var)

    stdev.s()  is fora sample, while studev.p() is for a population.
    How about stdev()?

/////////////////////////////////////
"

.C8EXPLAIN7<-"total risk vs. market risk 
/////////////////////////////////////

   Total risk = market risk + firm specific risk

various names
---------------------------------------------

 Market risk,
        systematic risk
        undiversifiable risk
        common risk

 Firm specific risk
        unsystematic risk
        diversifiable risk
        unique risk

/////////////////////////////////////
"

.C8EXPLAIN8<-"log function vs. exponential function 
/////////////////////////////////////
Let's look at some simple pair

   + and - are a pair

    a+3 = b  ==>   a= b-3

    a*2 = b  ==>   a= b/2  

    10^a=b   ==>   a=log(b,10)

    e^a=b    ==>  a=ln(b)


/////////////////////////////////////
"

.C8EXPLAIN9<-"definition of returns
/////////////////////////////////////
Case #1: we buy a stock today at p0
         we sell it at t1 with a selling price of p1
                       p1-p0 + d1
     total return = --------------
                           p0

      total return has two components: capital gain yield + dividend yield

                       p1-p0       d1
     total return = ---------   + ----
                        p0         p0

Case #2: percentage return vs. log return 

        We have two prices of p0 and p1
                   p1-p0                     p1
       Return(%) = ------        logRet= ln( -- )
                    p0                       p0

The relationship between logRet and a percentage return. 

        logRet=ln(Ret+1)
        ret=exp(logRet)-1

Here is an example: percentage return is 10%. What is 
        its equivalent log return?
      =LN(0.1+1)         ==> 0.09531018
      verify
      =exp(0.09531018)   ==>   0.1

/////////////////////////////////////
"


.C8EXPLAIN10<-"Consciously compounded rate 
/////////////////////////////////////
Continuously compounded rate 

   First, we should understand what does it mean APR=10% compounded annually. 

   Then, APR=10%, compounded semi-annually. 

   Then, APR=10% compounded monthly 

   The final limit is compounded continuously. 

   We could image that it is compounded every minute (or every second)

/////////////////////////////////////
"

.C8EXPLAIN11<-"Rc vs. an effective rate, Rc vs. APR
/////////////////////////////////////
For a given effective rate, calculate Rc
-------------------

   Rc=m*ln(1+ Rm)^m

      where Rc is a continuously compounded rate
            Rm is a given effective rate
             m is the compounding frequency
               ,m=1, 2, 4, 12, 52, 365 for annual, semiannual
                  quarterly, weekly, daily frequency
          ln() is natural log function 

For a given Rc, calculate R effective   
------------------- 
  Rm=exp(Rc/m)-1


/////////////////////////////////////
"

.C8EXPLAIN12<-"Excel functions for natural log and log with other bases 
/////////////////////////////////////
log function based on 10

  =10^1                => 1

  =10^2.3              => 199.5262315

  =log(199.5262315,10) => 2.3

  =log10(199.5262315)  => 2.3

Natural log, i.e., ln()

  =exp(1)             => 2.718281828

  =ln(2.718281828)    => 1

  =ln(3)              => 1.098612289

  =LOG(3,2.718281828) => 1.098612289


/////////////////////////////////////
"

.C8EXPLAIN13<-"Beta of a portfolio 
/////////////////////////////////////

 Beta of a portfoio is the weighted beta of individual abetaet's beta. 

 Abetaume that we have n abetaets in our portfoio with beta1, beta2 and betan. 


   beta (portfolio) = w1 * beta1 + w2*beta2 + ... + wn*betan

       where w1    : the weight of abetaet 1
             beta1 : the beta of   abetaet 1

/////////////////////////////////////
"





.C8EXPLAIN14<-"Beta of a firm
/////////////////////////////////////
    beta (firm) = w_E* beta_equity + w_D * beta_debt

        The beta of a firm is its weighted beta. 
         W_E is the weight of equity,   

                        V_E
                W_E=  --------
                        V_firm

                        V_D
                W_D=  --------
                       V_firm

                V_firm=V_E + V_D

          beta_E is beta for equity 
          beta_D is beta for debt 

   Here is an example: beta_E=2.0, beta_D=0.1
   the capitcal strutrue is 60% of equity and 40% of debt

     Beta(firm) = 0.6*2 + 0.4 * 0.1

/////////////////////////////////////
"

 
.C8EXPLAIN15<-"Average of beta of all stocks 
/////////////////////////////////////

  The (value-weighted) average beta of all stocks
       in the market is 1 by definition. 

/////////////////////////////////////
"

.C8EXPLAIN16<-"Time-weighed vs. dollar-weighted
/////////////////////////////////////

 Time-weighted is the same as our geometric mean 


 Dollar weighted is the same as our IRR. 


/////////////////////////////////////
"

.C8EXPLAIN17<-"Excel functions: var, stdev,covar,correl and slope
/////////////////////////////////////
   var.p   calculate variance based on the entire population 
           (ignores logical values and text in the population)
   var.s   calculate variance based on a sample 
           (ignores logical values and text in the sample)
   var = var.s

   stdev.p calculate standard deviation based on the entire population 
           (ignores logical values and text in the population)

   stdev.s calculate standrd deviation based on a sample 
           (ignores logical values and text in the sample)

   stdev = stdev.s

   covariance.p  returns population covaraince, the average of the products 
                 of deviatin for each data point pair in two data sets. 
   covariance.s  returns sample covaraince, the average of the products 
                 of deviatin for each data point pair in two data sets. 
   covar

   slope         Returns the slope of the linear regrebetaion line
                     throught the given data points
  -----------------
    vara   calculate variance based on a sample including logical 
           values and text. Text and logical vaue FALSE have the value 0;
           the logical value TRUE has the value 1. 

/////////////////////////////////////
"

.C8EXPLAIN18<-"risk-free rate 
/////////////////////////////////////
The risk-free rate of return is the theoretical rate of return 
   of an investment with zero risk. The risk-free rate represents 
   the interest an investor would expect from an absolutely 
   risk-free investment over a specified period of time.

In theory, the risk-free rate is the minimum return an investor 
   expects for any investment because he will not accept additional 
   risk unlebeta the potential rate of return is greater than the 
   risk-free rate.

In practice, however, the risk-free rate does not exist because even 
   the safest investments carry a very small amount of risk. Thus, 
   the interest rate on a three-month U.S. Treasury bill is often 
   used as the risk-free rate for U.S.-based investors.

    http://www.investopedia.com/terms/r/risk-freerate.asp

/////////////////////////////////////
"

.C8EXPLAIN19<-"Youtube 
/////////////////////////////////////
  Evdakov,Sasha: Tradersfly,What is \"Beta\" [Stock Market Terms] + How to Use it for 
    Trading Decisions
    (v48k,s126k,t7:26)
    https://www.youtube.com/watch?v=jvk-Lkwd6S4&t=1s

 MondyWeek, 2012, MoneyWeek,  What is Beta? - MoneyWeek Investment Tutorials
    (v185k,s197k,t11:46)
    https://www.youtube.com/watch?v=etlv7qTQUSY&t=1s

/////////////////////////////////////
"

.C8EXPLAIN20<-"Links 
/////////////////////////////////////
Definitions of risk (common sense)
----------------------------------
   Webster
      https://www.merriam-webster.com/dictionary/risk

   Businebeta dictionary 
      http://www.businebetadictionary.com/definition/risk.html

   Wikipedia
      https://en.wikipedia.org/wiki/Risk

   Oxford dictionary 
      https://en.oxforddictionaries.com/definition/risk

   Economic Times
      https://economictimes.indiatimes.com/definition/risk

   Cambridge Dictionary 
      https://dictionary.cambridge.org/us/dictionary/english/risk

   InvestorPedia
      https://www.investopedia.com/ask/answers/021915/how-standard-deviation-used-determine-risk.asp

  Arithmetric vs. geometric means 
         https://www.investopedia.com/ask/answers/06/geometricmean.asp
/////////////////////////////////////
"
.chapter9<-function(i){
" i  Chapter 9: Benchmarked cost of capital  
  -  -------------------------------------
  1  Short-term vs. long-term 
  2  Debt vs. equity 
  3  Cost of capital 
  4  Opportunity of cost of capital 
  5  Risk-free rate
  6  Nominal rate vs. real rate 
  7  Risk premium
  8  Default premium/equity premium 
  9  Half-variance approximation  (between Amean and Gmean)
 10  Equity premius estimation 
 11  Equity premius estimation (2)
 12  Equity premium puzzle 
 13  Margin of error and 95% confidence range 
 14  Peso problem
 15  Historical values 
 16  Equity premium: Jazon Zweig Survey 
 17  Promised, actual and expected (rate of return) 
 18  Key points 
 19  Youtube
 20  Links 
 
 Example #1:>.c9    # find out the above list 
 Example #2:>.c9(1) # find the 1st explanation

";.chapter9_(i)}

.n9chapter<-20

.chapter9_<-function(i){
    .printEachQ(9,i,.n9chapter)
}

.c9<-.chapter9

.C9EXPLAIN1<-"Short-term vs. long-term 
///////////////////////////////

 The long-term investment should (usually) offer a higher 

     expected rate of return than the short-term investment 

     (just like Treasuries).

///////////////////////////////
"
.C9EXPLAIN2<-"Debt vs. equity 
///////////////////////////////
Debt and Equity Parts

Projects can be split into a safer debt and 
     a riskier equity component.

 The riskier part should offer a higher \"equity-type\" 
    expected rate of return than the safer \"debt-type\" part.

   ...notwithstanding some pathological curiosity cases

///////////////////////////////
"

.C9EXPLAIN3<-"Cost of capital 
///////////////////////////////
 You can weight costs of capital according to financing.

 The WACC is the weighted-average debt and equity cost 
   of capital.

 For example, if, given 50-50 financing, debt has a cost 
   of 5% and equity of 10%, then the project (abetaet) 
   cost of capital is 7.5%.

  WACC= 0.5*0.05 + 0.5 * 0.075

///////////////////////////////
"

.C9EXPLAIN4<-"Opportunity of cost of capital 
///////////////////////////////
 The opportunity cost of a product or service is the 
   revenue that could be earned by its alternative use. 
   
 In other words, opportunity cost is the cost of the next 
   best alternative of a product or service.

 For capital, the same rule/logic applies. 

///////////////////////////////
"

.C9EXPLAIN5<-"Risk-free rate
///////////////////////////////
   How can you obtain reasonable estimates for the risk-free rate?

   Which risk-free rate? Treasuries.

  Which Treasury? Match to project cash flow.

  Term Premium: Known in time!

  In 2017 (and historically), about 2%.

///////////////////////////////
"

.C9EXPLAIN6<-"Nominol rate vs. real rate 
///////////////////////////////
                 1 + R_nominal 
  Real rate =   -----------------
                  1 + i_rate

   R_real: real rate 

   R_nominal : is the norminal rate

   i_rate  : inflation rate 

  when the inflation rate is quite low, we
     have the following approximation 

     R_real = R_nominal - i_rate

///////////////////////////////
"
.C9EXPLAIN7<-"Risk premium
///////////////////////////////

 Risk premium is the extra retrun required to compensate 
     for bearing more risk. 

   Risk-premium = R(reqired) - Rf

///////////////////////////////
"

.C9EXPLAIN8<-"Default premium
///////////////////////////////

  Default premium is the extra return compensating pobetaible default risk. 

    Spread = R (YTM) - Rf

     Higher spread -- > higher default risk 

Equity risk premium
------------------

   Equity risk premium =  E(R) - Rf

///////////////////////////////
"

.C9EXPLAIN9<-"Half-variance approximation  (between Amean and Gmean)
///////////////////////////////
 When returns following a normal distribution 

   Gmean = Amean- 0.5*var

          Gmean :  geometric mean 

          Amean : arithmaic mean 

          var   : variance of returns 

     https://www.portfolioprobe.com/2013/05/06/the-half-variance-approximation-for-mean-returns/

///////////////////////////////
"
.C9EXPLAIN10<-"Equity premius estimation 
///////////////////////////////
 Unlike the term premium, the equity premium is not known,

  ...although finance models abetaume you do know it and 
    often ask you to provide it.

 There is no clear single consensus estimate. The experts disagree.

 Some for good reason, some for bad reason.

 Let's discubeta estimation methods.

///////////////////////////////
"

.C9EXPLAIN11<-"Equity premius estimation (2)
///////////////////////////////
 Method 1: Historical Averages
     Whatever the equity premium was in the past will
         also be the case in the future.
    But what sample period?
    And relative to long-term or short-term bonds?
    And relative to geometric or arithmetic average rates of return?

 Method 2: inverse historical averages: 
           high historical --> low future rates of return

 Method 3: current predictive ratios: 
           regrebetaion prediction of stock market

 Method 4: philosophical prediction: 
           where would one reasonably be indifferent?

 Method 5: consensus survey just ask the blind!

 Method 6: ICC: analysts' consensus earnings 
           projections with perpetuity model

///////////////////////////////
"

.C9EXPLAIN12<-"Equity premium puzzle 
///////////////////////////////
 The equity premium puzzle (EPP) is a phenomenon that describes
    the anomalously higher historical real returns of stocks over
    government bonds. 

  The equity premium, which is defined as equity returns minus 
     bond returns, has been approximately 6.4% on average over a 
     100+ year period in the U.S. 

  The premium is supposed to reflect the relative risk of stocks 
     compared to \"risk-free\" government bonds, but the puzzle 
     arises because this unexpectedly large percentage implies
     an unreasonably high level of risk aversion among investors.

  Source: https://www.investopedia.com/terms/e/epp.asp

///////////////////////////////
"
.C9EXPLAIN13<-"Margin of error and 95% confidence range 
///////////////////////////////
Abetaume that we have n observations. 
Step 1: Estimate their mean and std
         mean   =average()
         std    =stdev() 
         n      =count()    
                            std
Step 2: standard error = ---------
                           sqrt(n)

Step 3: choose a confidence level, such as 0.95
        t_critical_value = T.INV.2t(0.05,df)
            where df is degree of freedom = n-1
            For example, =T.INV.2T(0.05,100)  -> 1.983971519

Step 4: Margin of error 
          marginOfErr= t_critical * stdErr
                                     std
                     = t_critical * ---------
                                     sqrt(n)
Step 5: the range is: 
        [min, max]  =  [mean-marginOfErrr,  mean+ marginOfErr]

///////////////////////////////
"

.C9EXPLAIN14<-"Peso Problem
///////////////////////////////
 Peso Problem
    The phenomenon in which the market prices in (or takes into account 
    when determining the price) the small pobetaibility of a large change.

    The term especially refers to exchange rates of pegged currencies, which 
    may be slightly different from the official rates to account for the 
    probability that currencies will drop or change their pegs.
        Farlex Financial Dictionary.(c) 2012 Farlex, Inc. All Rights Reserved
        https://financial-dictionary.thefreedictionary.com/Peso+Problem

///////////////////////////////
"

.C9EXPLAIN15<-"Historical values 
///////////////////////////////
page 198 very confusing about the following information

   Arithmetric equity premium 1926 to 2015 over short-term T-bonds 8%
   -----------------------------------------------------------------
   Instead use later Sample period 1970 to 2015   -2%            (A)
   Instead use Long-term bonds                    -2%            (B) 
   instead use Geometric Returns                  -2%            (C)
   -------------------------------------------------------------
   Geomeric Equity Premium 1970-2015 over long-term bonds    2%

  For (A): it is clear. 
   Instead use later Sample period 1970 to 2015   -2%  
        <=>
   Arithmetric equity premium 1970 to 2015 over short-term T-bonds 2%

  For (B), it is not clear. 
       Instead use Long-term bonds  -2%
          <=> which one below
       Arithmetric equity premium 1926 to 2015 over Long-term T-bonds  -2%    (D)
       Arithmetric equity premium 1970 to 2015 over Long-term T-bonds  -2%    (E)

       If (D) is true, then the YTM of Long-term bond - short-term bonds should be 10%. ???
             x-S =  8%,               (1)
             x-L = -2%                (2)
             (1)-(2)   => L-S= 10%
       If (E) is true, then the YTM of Long-term bond - short-term bonds should be 0%.  ???
               x-S = -2%
               x-L = -%
  For (C) it is not clear. 
             instead use Geometric Returns -2%            (C)
                  <==> which one  
 Period: 1970- 2015
 ------------------
    Geometric   equity premium over Long-term Bonds     2%
 Period: 1926- 2015
 ------------------
    Arithmetric equity premium over short-term T-bonds 8%
    (T-bonds should be T-bills?) 
    Arithmetric equity premium over long-term T-bonds  -2%    ???
    Geometric   equity premium over short-term T-bonds -2%   ???

 Period: 1970- 2015
 ------------------
   Geometric   equity premium over Long-term Bonds     2%
///////////////////////////////
"

.C9EXPLAIN16<-"Equity premium: Jazon Zweig Survey 
///////////////////////////////

  https://www.cfosurvey.org/11q2/index.htm

  https://zweiggroup.myshopify.com/collections/frontpage

///////////////////////////////
"
.C9EXPLAIN17<-"Promised, actual and expected (rate of return)
///////////////////////////////
  Promised rate of return = Time premium + Default premium + Risk premium 

  Realized enarned return = Time premium + Default realization + Risk premium 

  Expected Rate of return = Time premium + Expected risk premium 

///////////////////////////////
"

.C9EXPLAIN18<-"Key points 
///////////////////////////////

 Your benchmarks should be thought of in terms of 
      expected rates of reurns. 

 If you use historical average retunrs, yu usually abetaume 
      that those averages are representative of expected 
      rates of returns

 The expected reurn is not a stated (promised, quoted) 
     return, becase if does ot include a default premium. 

 The probability of default must be handled in the NPV 
     numerator (through the expcted cash flow), and not 
     in the NPV denominator (throught the expected rate of 
     return)
///////////////////////////////
"

.C9EXPLAIN19<-"Youtube 
///////////////////////////////
  Dragonfly Statistics,2013, Introduction to Statistics : Geometric Mean
     (v81k,s7.7k,t3:02)
     https://www.youtube.com/watch?v=PKWVAIP17pw

  I Hate Math Group, Inc, 2013, How to find the Expected Return and Risk
     (v226k,s19k,t6:52)
     https://www.youtube.com/watch?v=h7Fqk529BP0

  patrickJMT,2011,The Geometric Mean
    (v343k,s1m,t3:34)
     https://www.youtube.com/watch?v=_UdGUULKN-E

  Spoon Feed Me,2014, Expected Return and Standard Deviation | Portfolio Management
   (v91k,s3.4k,t11:19)
     https://www.youtube.com/watch?v=lvOYpTTORQs

///////////////////////////////
"

.C9EXPLAIN20<-"Links 
///////////////////////////////
 Peso problem 
   https://breakingdownfinance.com/trading-strategies/peso-problem/

 Pat, 2013, The half variance approximation for mean returns
    https://www.portfolioprobe.com/2013/05/06/the-half-variance-approximation-for-mean-returns/

///////////////////////////////
"



.chapter3<-function(i){
" i  Chapter 3: Financial statement analysis 
  -  -------------------------------------
  1  Purposes of a financial statement analysis  
  2  A simple balance sheet
  3  A simple income statement
  4  Formula to generate cash flows
  5  manually download latest several years' financial statements (BS,IS,CF)
  6  download and save several years' Balance Sheets
  7  download and save several years' Income Statements
  8  download and save several years' Cash flow Statement
  9  download and save several quarters' Balance Sheets
 10  CIK (Central Index Key)
 11  Accebeta to SEC filings 
 12  Common-size financial statements
 13  What is the purpose for a ratio analysis
 14  several frequently used ratios
 15  A list of accounting ratios
 16  DuPont identity 
 17  How to find competitors industry ratios
 18  multiples and stock evaluation
 19  save financial statements easily 
 20  Links 

 Example #1:> .c3     # find out the list 
 Example #2:> .c3(1)  # see the first explanation 

";.chapter3_(i)

}

.n3chapter<-20

.chapter3_<-function(i){
    .printEachQ(3,i,.n3chapter)
}


.c3<-.chapter3



.EX3P1<-"Purposes of a financial statement analysis  
//////////////////////////

Objective #1: compare with company itself

              look at various ratios to see improvements 
               check performance and weaknebeta

Objective #2: compare with peers in the same industry

//////////////////////////
"

.EX3P2<-"A simple balance sheet
//////////////////////////

 A balance-sheet is snapshot for a company, 
    usually a quarter one or an annual one. 

Example

      Cash        = 0.2m
      Equipment   = 0.5m
      Other values= 0.3m
     -------------------
      Total abetaets= 1.0m

  Short-term debt =   0.1m 
  Long-term debt  =   0.3m
  Equity          =   0.6m
    ---------------------
  Total abetaets    =   1.0m

//////////////////////////
"


.EX3P3<-"A simple income statement
//////////////////////////

Basic format	                        
     Revenue
  -  Cost
  -  Interest payment
     ----------------
       EBT 
  -  Tax 
     ---------------
  =  Net Income	

Example
  ----------------------------------
  Revenue            =   100
  Cost               = -  50
  Interest payment   = -  10
  -----------------------------
   EBT               =     40
   Tax rate is 0.34  = -13.6
--------------------------------
   Net Income        =    26.4

//////////////////////////
"

.EX3P4<-"A simple cash flow statement 
//////////////////////////

  Free Cash Flow = NI + Depreciation - change in CapEx + change in NWC

      NI           is Net Income
  depreciation     is depreciation of the year
  change in CapEx  is change in capital expenditure
  change in NWC    is change in Net working capital 
  NWC              is net working capital defined as CA -CL
                      CA is the current abetaet
                      CL is the current liability

//////////////////////////
"

.EX3P5<-"manually download latest several years' financial statements (BS,IS,CF)
//////////////////////////

 step 1: go to http://finance.yahoo.com

 Step 2: enter a ticker, e.g., \"ibm\"

 Step 3: click \"Financials\"

 Step 4: choose Balance Sheet, Income statement or Cash flow

 Step 5: choose annual or quarterly

//////////////////////////
"


.EX3P6<-"download and save several years' Balance Sheets
//////////////////////////
There are two functions called .getBSannual()
                               .getBSquarterly()

  Type getBSannua to find its usage

       >.getBSannual

  Example #1
        >x=.getBSannual(\"ibm\")
          Annual Balance Sheet for ibm
        > .saveFinStatement(x,\"c:/temp/ibmBS.csv\")
          [1] \"Your saved file is ==>c:/temp/ibmBS.csv\"

//////////////////////////
"

.EX3P7<-"download and save several years' Income Statements
//////////////////////////
There are two functions called .getISannual()
                               .getISquarterly()

 Type .getISannua to find its usage

       >.getISannual

 Example #1
           >x=.getISannual(\"ibm\")
        
//////////////////////////
"

.EX3P8<-"download and save several years' Cash flow Statement
//////////////////////////

  >.getdata                # get a list of all related functions

  >.getBSannual            # find info

  >x=.getBSannual(\"ibm\") # get IBM's balance sheets
 
//////////////////////////
"

.EX3P9<-"An easy way to download and save BS, IS and Cash Flow statements
//////////////////////////
See all function
--------------
  >.getdata                    # get a list of all related functions

Balance sheet
------------
  >.getBSquarterly             # find info
  >x=.getBSquarterly(\"ibm\")  # get IBM's balance sheets

Balance sheet
------------
  >.getISquarterly             # find info
  >x=.getISquarterly(\"ibm\")  # get IBM's income statements

Balance sheet
------------
  >.getCFquarterly             # find info
  >x=.getCFquarterly(\"ibm\")  # get IBM's cash flow statements 

//////////////////////////
"

.EX3P10<-"Central Index Key (CIK)
//////////////////////////
The CIK is the unique numerical identifier abetaigned by the EDGAR 
system to filers when they sign up to make filings to the SEC. 
CIK numbers remain unique to the filer; they are not recycled.


 CIK-ticker mapping 
     http://rankandfiled.com/#/data/tickers

//////////////////////////
"

.EX3P11<-"Accebeta to SEC filings 
//////////////////////////

  https://www.sec.gov/edgar/searchedgar/accebetaing-edgar-data.htm

Given CIK, e.g., CIK=51143
   https://www.sec.gov/Archives/edgar/data/51143/
   https://www.sec.gov/Archives/edgar/data/51143/000104746917001061/

//////////////////////////
"


.EX3P12<-"Common-size financial statements
//////////////////////////
To compare the performance of a firm over several years or compare its 
   performance with other firms in the same industry, we use so-called 
   common size financial statements. For example, last year's Cash & 
   Equivalents was $1m and this year's corresponding value is $1.1m. 
   With those two values alone, it is difficult to figure out what the 
   impact of this specific data item. If we know further that the ratio 
   of this data item over total sales are a constant over two years, then 
   it is easier to interpret our results.

                       original data
  New Data Item= -----------------------
                       Reference data 

 For a balance-sheet

                       original data
  New Data Item= -----------------------
                       Total abetaet

 For an income statement: 

                       original data
  New Data Item= -----------------------
                       Total Sales 

//////////////////////////
"

.EX3P13<-"What is the purpose for a ratio analysis
//////////////////////////
Objective #1: compare with company itself

              look at various ratios to see improvements 
               check performance and weaknebeta

Objective #2: compare with peers in the same industry

//////////////////////////
"

.EX3P14<-"several frequently used ratios
//////////////////////////
Short-term liquidity
--------------------
                     CA
 current ratio = ----------------
                     CL

  CA: current abetaet 
  CL: current liability

                   CA - inventory
  quick ratio   = ----------
                       CL

                    Cash + short-term securities
  cash ratio ==  ---------------------------
                            CL
leverage ratios
--------------------
                            D
   Debt to Total abetaets  = ---
                            A
                                    LT debt
   long-term debt to total abetaet=   -----
                                      A
                              D
    Debt to equity ratio =   ----
                              E
Probability 
--------------------

         NI
   ROA = ---
         A

         NI
   ROE = ---
         E

           
//////////////////////////
"

.EX3P15<-"A list of accounting ratios
//////////////////////////
Profitability Ratios
--------------------
   Grobeta Profit Rate = Grobeta Profit / Net Sales
         Evaluates how much grobeta profit is generated from sales. 
         Grobeta profit is equal to net sales (sales minus sales 
         returns, discounts, and allowances) minus cost of sales.

   Return on Sales = Net Income / Net Sales
         Also known as \"net profit margin\" or \"net profit rate\",
         it measures the percentage of income derived from dollar 
         sales. Generally, the higher the ROS the better.

   Return on Abetaets = Net Income / Average Total Abetaets
         In financial analysis, it is the measure of the return on 
         investment. ROA is used in evaluating management's efficiency 
         in using abetaets to generate income.

  Return on Stockholders' Equity = Net Income / Average Stockholders' Equity
          Measures the percentage of income derived for every dollar of owners' equity.

Liquidity Ratios
--------------------
  Current Ratio = Current Abetaets / Current Liabilities
          Evaluates the ability of a company to pay short-term obligations 
          using current abetaets (cash, marketable securities, current 
          receivables, inventory, and prepayments).

  Acid Test Ratio = Quick Abetaets / Current Liabilities
          Also known as \"quick ratio\", it measures the ability of a 
          company to pay short-term obligations using the more liquid
          types of current abetaets or \"quick abetaets\" (cash, marketable 
          securities, and current receivables).

  Cash Ratio = ( Cash + Marketable Securities ) / Current Liabilities
          Measures the ability of a company to pay its current liabilities 
          using cash and marketable securities. Marketable securities are 
          short-term debt instruments that are as good as cash.

  Net Working Capital = Current Abetaets - Current Liabilities
          Determines if a company can meet its current obligations with 
          its current abetaets; and how much excebeta or deficiency there is.

Management Efficiency Ratios
--------------------
  Receivable Turnover = Net Credit Sales / Average Accounts Receivable
          Measures the efficiency of extending credit and collecting 
          the same. It indicates the average number of times in a year 
          a company collects its open accounts. A high ratio implies efficient credit and collection procebeta.

  Days Sales Outstanding = 360 Days / Receivable Turnover
          Also known as \"receivable turnover in days\", \"collection period\". 
          It measures the average number of days it takes a company to collect 
          a receivable. The shorter the DSO, the better. Take note that some 
          use 365 days instead of 360.

  Inventory Turnover = Cost of Sales / Average Inventory
          Represents the number of times inventory is sold and replaced. 
          Take note that some authors use Sales in lieu of Cost of Sales 
          in the above formula. A high ratio indicates that the company is 
          efficient in managing its inventories.

  Days Inventory Outstanding = 360 Days / Inventory Turnover
          Also known as \"inventory turnover in days\". It represents the 
          number of days inventory sits in the warehouse. In other words, 
          it measures the number of days from purchase of inventory to the 
          sale of the same. Like DSO, the shorter the DIO the better.

  Accounts Payable Turnover = Net Credit Purchases / Ave. Accounts Payable
          Represents the number of times a company pays its accounts payable 
          during a period. A low ratio is favored because it is better to 
          delay payments as much as pobetaible so that the money can be used 
          for more productive purposes.

  Days Payable Outstanding = 360 Days / Accounts Payable Turnover
          Also known as \"accounts payable turnover in days\", \"payment period\".
          It measures the average number of days spent before paying obligations 
          to suppliers. Unlike DSO and DIO, the longer the DPO the better 
          (as explained above).

  Operating Cycle = Days Inventory Outstanding + Days Sales Outstanding
          Measures the number of days a company makes 1 complete operating 
          cycle, i.e. purchase merchandise, sell them, and collect the amount 
          due. A shorter operating cycle means that the company generates sales 
          and collects cash faster.

  Cash Conversion Cycle = Operating Cycle - Days Payable Outstanding
          CCC measures how fast a company converts cash into more cash.
          It represents the number of days a company pays for purchases, 
          sells them, and collects the amount due. Generally, like operating
          cycle, the shorter the CCC the better.

  Total Abetaet Turnover = Net Sales / Average Total Abetaets
          Measures overall efficiency of a company in generating sales 
          using its abetaets. The formula is similar to ROA, except that 
          net sales is used instead of net income.

Leverage Ratios
--------------------
  Debt Ratio = Total Liabilities / Total Abetaets
         Measures the portion of company abetaets that is financed by debt 
         (obligations to third parties). Debt ratio can also be computed 
         using the formula: 1 minus Equity Ratio.

  Equity Ratio = Total Equity / Total Abetaets
        Determines the portion of total abetaets provided by equity (i.e. 
        owners' contributions and the company's accumulated profits). 
        Equity ratio can also be computed using the formula: 1 minus Debt Ratio.
        The reciprocal of equity ratio is known as equity multiplier, which is 
        equal to total abetaets divided by total equity.

  Debt-Equity Ratio = Total Liabilities / Total Equity
        Evaluates the capital structure of a company. A D/E ratio of more 
        than 1 implies that the company is a leveraged firm; lebeta than 1 
        implies that it is a conservative one.

  Times Interest Earned = EBIT / Interest Expense
        Measures the number of times interest expense is converted to income,
        and if the company can pay its interest expense using the profits 
        generated. EBIT is earnings before interest and taxes.

Valuation and Growth Ratios
--------------------
  Earnings per Share = ( Net Income - Preferred Dividends ) / Average Common Shares Outstanding
        EPS shows the rate of earnings per share of common stock. Preferred 
        dividends is deducted from net income to get the earnings available 
        to common stockholders.

  Price-Earnings Ratio = Market Price per Share / Earnings per Share
        Used to evaluate if a stock is over- or underpriced. A relatively 
        low P/E ratio could indicate that the company is underpriced. 
        Conversely, investors expect high growth rate from companies with 
        high P/E ratio.

  Dividend Pay-out Ratio = Dividend per Share / Earnings per Share
        Determines the portion of net income that is distributed to owners. 
        Not all income is distributed since a significant portion is retained
        for the next year's operations.

  Dividend Yield Ratio = Dividend per Share / Market Price per Share
        Measures the percentage of return through dividends when compared 
        to the price paid for the stock. A high yield is attractive to 
        investors who are after dividends rather than long-term capital 
        appreciation.

  Book Value per Share = Common SHE / Average Common Shares
        Indicates the value of stock based on historical cost. The value of 
        common shareholders' equity in the books of the company is divided 
        by the average common shares outstanding.

 Source: 
    http://www.accountingverse.com/managerial-accounting/fs-analysis/financial-ratios.html
//////////////////////////
"

.EX3P16<-"DuPont identity 
//////////////////////////
                          Net Income
 ROE is defined as   = ----------------
                           Equity 
             NI
       ROE= ---                      (1)
             E

 Let times equation (1) by Sales and divide sales 

             NI   Sales
       ROE= --- * ---                (2)
             E    sales  

 Let times equation (2) by total abetaets and divide it by the same value 

             NI    S    A
       ROE= --- * --- * ---           (3)
             E     s    A

  Now, let's reorganize terms

             NI    S    A
       ROE= --- * --- * ---           (4)
             S     A    E

     ROE=(net income/sales)*(sales/total abetaets)*(total abetaets/equity)

     ROE = Net Profit Margin * Abetaet Turnover * Equity Multiplier

//////////////////////////
"

.EX3P17<-"How to find competitors and industry ratios
//////////////////////////
             current price
 PE ratio = ------------
               EPS

   EPS is the earnings per share 
          
//////////////////////////
"

.EX3P18<-"multiples and stock evaluation
//////////////////////////
Many multiples, such as PE ratio, could be 
   used to evaluation a stock's performance. 

//////////////////////////
"

.EX3P19<-"saveFinStatement() function 
///////////////////////////////
The function used to save various financial statements is 
    called saveFinStatement

  Step 1: Type getData
          >.getdata

  Step 2: type function name to find its usage
          >.saveFinStatement

 Example #1:> x=.getCFannual(\"ibm\")
              Annual Cash Flow Statement for ibm
            > .saveFinStatement(x,\"c:/temp/ibm.csv\")
              [1] \"Your saved file is ==>c:/temp/ibm.csv\"

 Example #2:> y=.getBSannual(\"msft\")
                Annual Balance Sheet for msft
            > .saveFinStatement(y)
             [1] \"Your saved file is ==>C:/Users/yany/Documents/test.csv\"

             Note: the data is saved under the current working directory
                   with a default name of test.csv

/////////////////////////////////
"

.EX3P20<-"useful links 
///////////////////////////////
Source of information:

 Yahoo!Finance
     http://finance.yahoo.com/

 Google finance
     https://www.google.com/finance

 Markte Watch
     http://www.marketwatch.com/

 SEC filings
     https://www.sec.gov/edgar.shtml

 SEC EGDAR Company filings
     https://www.sec.gov/edgar/searchedgar/companysearch.html

 SEC quarterly index
     https://www.sec.gov/Archives/edgar/full-index/

 CIK (Central Index Key)
     https://en.wikipedia.org/wiki/Central_Index_Key

 CIK-ticker mapping 
     http://rankandfiled.com/#/data/tickers

 SEC filing examples
     https://www.sec.gov/Archives/edgar/data/1599496/000146581817000048/0001465818-17-000048.txt
              edgar/data/1599496/0001465818-17-000048.txt
              edgar/data/1084869/0001140361-17-028809.txt
              edgar/1084869/0001140361-17-028809.txt
              edgar/data/1307969/0001683168-16-000379.txt
    https://www.sec.gov/Archives/edgar/data/1599496/000146581817000048/0001465818-17-000048.txt
 
 Financial ratios
     http://www.accountingverse.com/managerial-accounting/fs-analysis/financial-ratios.html

 6 Basic Financial Ratios And What They Reveal (YouTube,2m3s)
     http://www.investopedia.com/financial-edge/0910/6-basic-financial-ratios-and-what-they-tell-you.aspx

 Cash Flow statements
     http://harbert.auburn.edu/~colqull/FINC3610/Chap9notes.pdf

 Compustat
     https://en.wikipedia.org/wiki/Compustat
 
 Understanding the COMPUSTAT (North America) Database 
     http://web.utk.edu/~prdaves/Computerhelp/COMPUSTAT/Compustat_manuals/user_02.pdf

 CRSP/Compustat Merged Database
    http://www.crsp.com/products/research-products/crspcompustat-merged-database

/////////////////////////////////
"


